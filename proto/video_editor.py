#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘ç¼–è¾‘è½¯ä»¶ - ä¸»ç¨‹åº
æ”¯æŒè§†é¢‘åŠ è½½ã€é¢„è§ˆã€å‰ªè¾‘ã€å¯¼å‡ºç­‰åŠŸèƒ½
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import os
import threading
import time
from pathlib import Path
import math
from datetime import datetime, timedelta, timezone
import bisect
import subprocess
import shutil
import xml.dom.minidom
import struct
import tempfile
import json
import re

# å°è¯•å¯¼å…¥numpyç”¨äºé”™è¯¯å¤„ç†
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    print("è­¦å‘Š: æœªå®‰è£… numpyï¼ŒæŸäº›åŠŸèƒ½å°†å—é™ã€‚è¯·è¿è¡Œ: pip install numpy")

# å°è¯•å¯¼å…¥è§†é¢‘å¤„ç†åº“
try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    print("è­¦å‘Š: æœªå®‰è£… opencv-pythonï¼Œè§†é¢‘æ’­æ”¾åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install opencv-python")

try:
    from PIL import Image, ImageTk
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("è­¦å‘Š: æœªå®‰è£… Pillowï¼Œè§†é¢‘æ˜¾ç¤ºåŠŸèƒ½å°†å—é™ã€‚è¯·è¿è¡Œ: pip install Pillow")

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
import platform
if platform.system() == 'Windows':
    import tkinter.font as tkFont
    default_font = ('Microsoft YaHei', 9)
elif platform.system() == 'Darwin':  # macOS
    default_font = ('PingFang SC', 11)
else:  # Linux
    default_font = ('WenQuanYi Micro Hei', 10)


class VideoEditorApp:
    """è§†é¢‘ç¼–è¾‘å™¨ä¸»åº”ç”¨ç±»"""
    
    def __init__(self, root):
        self.root = root
        self.root.title("è§†é¢‘ç¼–è¾‘å™¨")
        self.root.geometry("1200x800")
        self.root.minsize(800, 600)
        
        # è§†é¢‘ç›¸å…³å˜é‡
        self.video_path = None
        self.video_info = {}
        self.video_creation_time = None # è§†é¢‘åˆ›å»ºæ—¶é—´
        self.clips = []  # å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
        
        # GPX æ•°æ®
        self.gpx_data = None  # æ ¼å¼: {'segments': [(start_time, end_time, speed), ...]}
        self.gpx_offset = 0.0  # GPXæ—¶é—´åç§»ï¼ˆç§’ï¼‰
        self.track_thumbnail = None # è½¨è¿¹ç¼©ç•¥å›¾
        self.track_transform = None # åæ ‡è½¬æ¢å‚æ•°
        
        # è°ƒè¯•ä¿¡æ¯
        self.debug_info = {}
        
        # æ’­æ”¾ç›¸å…³å˜é‡
        self.cap = None  # OpenCV VideoCapture å¯¹è±¡
        self.playing = False  # æ˜¯å¦æ­£åœ¨æ’­æ”¾
        self.current_frame_pos = 0  # å½“å‰å¸§ä½ç½®
        self.total_frames = 0  # æ€»å¸§æ•°
        self.current_frame_image = None  # å½“å‰å¸§å›¾åƒ
        self.play_thread = None  # æ’­æ”¾çº¿ç¨‹
        self.audio_proc = None
        
        # æ‹–æ‹½çŠ¶æ€å˜é‡
        self.is_dragging_progress = False
        self.was_playing_before_drag = False
        
        # æ–°å¢ï¼šæ’­æ”¾æ§åˆ¶å¢å¼º
        self.playback_speed = 1.0  # æ’­æ”¾é€Ÿåº¦
        self.volume = 1.0  # éŸ³é‡
        self.is_muted = False  # æ˜¯å¦é™éŸ³
        self.loop_playback = False  # æ˜¯å¦å¾ªç¯æ’­æ”¾
        self.fullscreen_mode = False  # æ˜¯å¦å…¨å±æ¨¡å¼
        
        # åˆ›å»ºGUI
        self.create_menu()
        self.create_toolbar()
        self.create_main_panel()
        self.create_timeline()
        self.create_status_bar()
        
        # è®¾ç½®æ ·å¼
        self.setup_styles()
        
        # ç»‘å®šçª—å£å…³é—­äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        
        # ç»‘å®šGPXåç§»è°ƒæ•´å¿«æ·é”®
        self.root.bind('[', self.decrease_offset)
        self.root.bind(']', self.increase_offset)
        self.root.bind('{', self.decrease_offset_fine) # Shift+[
        self.root.bind('}', self.increase_offset_fine) # Shift+]
    
    def _get_ffprobe_cmd(self):
        """è·å–ffprobeå‘½ä»¤è·¯å¾„"""
        # 1. æ£€æŸ¥ç³»ç»ŸPATH
        if shutil.which('ffprobe'):
            return ['ffprobe']
            
        # 2. æ£€æŸ¥å½“å‰ç›®å½•
        if os.path.exists('ffprobe.exe'):
            return [os.path.abspath('ffprobe.exe')]
            
        if os.path.exists('ffprobe'):
            return [os.path.abspath('ffprobe')]
            
        # 3. æ£€æŸ¥å¸¸è§å­ç›®å½•
        common_paths = [
            os.path.join('ffmpeg', 'bin', 'ffprobe.exe'),
            os.path.join('bin', 'ffprobe.exe'),
            os.path.join('tools', 'ffprobe.exe'),
        ]
        
        for p in common_paths:
            if os.path.exists(p):
                return [os.path.abspath(p)]
                
        return None

    def setup_styles(self):
        """è®¾ç½®ç•Œé¢æ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
    
    def create_menu(self):
        """åˆ›å»ºèœå•æ """
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # æ–‡ä»¶èœå•
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ–‡ä»¶", menu=file_menu)
        file_menu.add_command(label="æ‰“å¼€è§†é¢‘...", command=self.open_video, accelerator="Ctrl+O")
        file_menu.add_command(label="å¯¼å…¥è§†é¢‘...", command=self.import_video)
        file_menu.add_command(label="å¯¼å…¥GPX...", command=self.import_gpx)
        file_menu.add_separator()
        file_menu.add_command(label="ä¿å­˜é¡¹ç›®...", command=self.save_project, accelerator="Ctrl+S")
        file_menu.add_command(label="æ‰“å¼€é¡¹ç›®...", command=self.open_project, accelerator="Ctrl+Shift+O")
        file_menu.add_separator()
        file_menu.add_command(label="å¯¼å‡ºè§†é¢‘...", command=self.export_video, accelerator="Ctrl+E")
        file_menu.add_separator()
        file_menu.add_command(label="é€€å‡º", command=self.root.quit, accelerator="Ctrl+Q")
        
        # ç¼–è¾‘èœå•
        edit_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="ç¼–è¾‘", menu=edit_menu)
        edit_menu.add_command(label="æ’¤é”€", command=self.undo, accelerator="Ctrl+Z", state="disabled")
        edit_menu.add_command(label="é‡åš", command=self.redo, accelerator="Ctrl+Y", state="disabled")
        edit_menu.add_separator()
        edit_menu.add_command(label="å‰ªåˆ‡", command=self.cut_clip, accelerator="Ctrl+X")
        edit_menu.add_command(label="å¤åˆ¶", command=self.copy_clip, accelerator="Ctrl+C")
        edit_menu.add_command(label="ç²˜è´´", command=self.paste_clip, accelerator="Ctrl+V")
        edit_menu.add_separator()
        edit_menu.add_command(label="åˆ é™¤", command=self.delete_clip, accelerator="Del")
        
        # å‰ªè¾‘èœå•
        clip_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å‰ªè¾‘", menu=clip_menu)
        clip_menu.add_command(label="åˆ†å‰²", command=self.split_clip, accelerator="S")
        clip_menu.add_command(label="åˆå¹¶", command=self.merge_clips, accelerator="M")
        clip_menu.add_separator()
        clip_menu.add_command(label="è®¾ç½®å…¥ç‚¹", command=self.set_in_point, accelerator="I")
        clip_menu.add_command(label="è®¾ç½®å‡ºç‚¹", command=self.set_out_point, accelerator="O")
        clip_menu.add_separator()
        clip_menu.add_command(label="æ·»åŠ è½¬åœºæ•ˆæœ...", command=self.add_transition, state="disabled")
        clip_menu.add_command(label="æ·»åŠ æ»¤é•œ...", command=self.add_filter, state="disabled")
        
        # æ’­æ”¾èœå•
        play_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ’­æ”¾", menu=play_menu)
        play_menu.add_command(label="æ’­æ”¾/æš‚åœ", command=self.toggle_play, accelerator="Space")
        play_menu.add_command(label="åœæ­¢", command=self.stop_play, accelerator="K")
        play_menu.add_separator()
        play_menu.add_command(label="ä¸Šä¸€å¸§", command=self.prev_frame, accelerator="â†")
        play_menu.add_command(label="ä¸‹ä¸€å¸§", command=self.next_frame, accelerator="â†’")
        play_menu.add_separator()
        play_menu.add_command(label="è·³è½¬åˆ°å¼€å§‹", command=self.jump_to_start, accelerator="Home")
        play_menu.add_command(label="è·³è½¬åˆ°ç»“æŸ", command=self.jump_to_end, accelerator="End")
        play_menu.add_separator()
        play_menu.add_checkbutton(label="å¾ªç¯æ’­æ”¾", command=self.toggle_loop, 
                                 variable=tk.BooleanVar(value=self.loop_playback))

        # å·¥å…·èœå•
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å·¥å…·", menu=tools_menu)
        tools_menu.add_command(label="æ‰‹åŠ¨è®¾ç½®GPXåç§»", command=self.set_manual_offset)
        
        # å¸®åŠ©èœå•
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å¸®åŠ©", menu=help_menu)
        help_menu.add_command(label="ä½¿ç”¨è¯´æ˜", command=self.show_help)
        help_menu.add_command(label="å…³äº", command=self.show_about)
        
        # ç»‘å®šå¿«æ·é”®
        self.root.bind('<Control-o>', lambda e: self.open_video())
        self.root.bind('<Control-s>', lambda e: self.save_project())
        self.root.bind('<Control-e>', lambda e: self.export_video())
        self.root.bind('<space>', lambda e: self.toggle_play())
        self.root.bind('<k>', lambda e: self.stop_play())
        
        # æ–°å¢å¿«æ·é”®
        self.root.bind('<Left>', lambda e: self.prev_frame())
        self.root.bind('<Right>', lambda e: self.next_frame())
        self.root.bind('<Shift-Left>', lambda e: self.rewind_5s())
        self.root.bind('<Shift-Right>', lambda e: self.forward_5s())
        self.root.bind('<Home>', lambda e: self.jump_to_start())
        self.root.bind('<End>', lambda e: self.jump_to_end())
        self.root.bind('<Delete>', lambda e: self.delete_clip())
        self.root.bind('<s>', lambda e: self.split_clip())
        self.root.bind('<m>', lambda e: self.merge_clips())
        self.root.bind('<i>', lambda e: self.set_in_point())
        self.root.bind('<o>', lambda e: self.set_out_point())
        self.root.bind('<m>', lambda e: self.toggle_mute())
    
    def create_toolbar(self):
        """åˆ›å»ºå·¥å…·æ """
        toolbar = ttk.Frame(self.root, relief=tk.RAISED, borderwidth=1)
        toolbar.pack(side=tk.TOP, fill=tk.X, padx=2, pady=2)
        
        # æ–‡ä»¶æ“ä½œæŒ‰é’®
        ttk.Button(toolbar, text="æ‰“å¼€è§†é¢‘", command=self.open_video, width=12).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="å¯¼å…¥è§†é¢‘", command=self.import_video, width=12).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="å¯¼å…¥GPX", command=self.import_gpx, width=12).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="å¯¼å‡ºè§†é¢‘", command=self.export_video, width=12).pack(side=tk.LEFT, padx=2)
        
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=5)
        
        # æ’­æ”¾æ§åˆ¶æŒ‰é’®
        self.play_btn = ttk.Button(toolbar, text="â–¶ æ’­æ”¾", command=self.toggle_play, width=10)
        self.play_btn.pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="â¹ åœæ­¢", command=self.stop_play, width=10).pack(side=tk.LEFT, padx=2)
        
        # æ–°å¢ï¼šå¿«é€Ÿè·³è½¬æŒ‰é’®
        ttk.Button(toolbar, text="â®", command=self.jump_to_start, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(toolbar, text="âª", command=self.rewind_5s, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(toolbar, text="â©", command=self.forward_5s, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(toolbar, text="â­", command=self.jump_to_end, width=3).pack(side=tk.LEFT, padx=1)
        
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=5)
        
        # å‰ªè¾‘æ“ä½œæŒ‰é’®
        ttk.Button(toolbar, text="åˆ†å‰²", command=self.split_clip, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="åˆ é™¤", command=self.delete_clip, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="åˆå¹¶", command=self.merge_clips, width=8).pack(side=tk.LEFT, padx=2)
        
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=5)
        
        # ç¼©æ”¾æ§åˆ¶
        ttk.Label(toolbar, text="ç¼©æ”¾:").pack(side=tk.LEFT, padx=2)
        self.zoom_var = tk.StringVar(value="100%")
        zoom_combo = ttk.Combobox(toolbar, textvariable=self.zoom_var, width=8, 
                                  values=["25%", "50%", "75%", "100%", "125%", "150%", "200%"],
                                  state="readonly")
        zoom_combo.pack(side=tk.LEFT, padx=2)
        zoom_combo.bind('<<ComboboxSelected>>', self.on_zoom_change)
    
    def create_main_panel(self):
        """åˆ›å»ºä¸»é¢æ¿ï¼ˆé¢„è§ˆçª—å£å’Œæ§åˆ¶é¢æ¿ï¼‰"""
        main_container = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_container.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # å·¦ä¾§ï¼šè§†é¢‘é¢„è§ˆåŒºåŸŸ
        preview_frame = ttk.LabelFrame(main_container, text="è§†é¢‘é¢„è§ˆ", padding=10)
        main_container.add(preview_frame, weight=2)
        
        # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        self.video_canvas = tk.Canvas(preview_frame, bg="#000000", width=640, height=360,
                                      highlightthickness=0, bd=0)
        self.video_canvas.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # é¢„è§ˆä¿¡æ¯æ ‡ç­¾
        self.preview_label = ttk.Label(preview_frame, text="ğŸ“¹ æœªåŠ è½½è§†é¢‘\n\nç‚¹å‡» æ–‡ä»¶ -> æ‰“å¼€è§†é¢‘ æ¥åŠ è½½è§†é¢‘æ–‡ä»¶", 
                                       font=default_font, foreground="gray", justify=tk.CENTER)
        self.preview_label.place(relx=0.5, rely=0.5, anchor=tk.CENTER)
        
        # æ’­æ”¾æ§åˆ¶é¢æ¿
        control_frame = ttk.Frame(preview_frame)
        control_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ’­æ”¾è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar()
        self.progress_scale = ttk.Scale(control_frame, from_=0, to=100, 
                                        variable=self.progress_var, orient=tk.HORIZONTAL,
                                        command=self.on_progress_change)
        self.progress_scale.pack(fill=tk.X, padx=5, pady=2)
        
        # ç»‘å®šé¼ æ ‡äº‹ä»¶ä»¥æ”¯æŒæ‹–æ‹½è·³è½¬
        self.progress_scale.bind("<ButtonPress-1>", self.on_progress_press)
        self.progress_scale.bind("<ButtonRelease-1>", self.on_progress_release)
        
        # æ—¶é—´æ˜¾ç¤ºå’Œæ’­æ”¾æ§åˆ¶
        time_frame = ttk.Frame(control_frame)
        time_frame.pack(fill=tk.X, padx=5)
        
        self.time_label = ttk.Label(time_frame, text="00:00:00 / 00:00:00", font=default_font)
        self.time_label.pack(side=tk.LEFT)
        
        # æ’­æ”¾æ§åˆ¶æŒ‰é’®ç»„
        control_buttons_frame = ttk.Frame(time_frame)
        control_buttons_frame.pack(side=tk.LEFT, padx=20)
        
        # æ’­æ”¾æ§åˆ¶æŒ‰é’®
        ttk.Button(control_buttons_frame, text="â®", command=self.jump_to_start, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(control_buttons_frame, text="âª", command=self.rewind_5s, width=3).pack(side=tk.LEFT, padx=1)
        self.play_btn = ttk.Button(control_buttons_frame, text="â–¶", command=self.toggle_play, width=3)
        self.play_btn.pack(side=tk.LEFT, padx=1)
        ttk.Button(control_buttons_frame, text="â©", command=self.forward_5s, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(control_buttons_frame, text="â­", command=self.jump_to_end, width=3).pack(side=tk.LEFT, padx=1)
        
        # éŸ³é‡æ§åˆ¶
        volume_frame = ttk.Frame(time_frame)
        volume_frame.pack(side=tk.RIGHT, padx=5)
        
        self.mute_btn = ttk.Button(volume_frame, text="ğŸ”Š", command=self.toggle_mute, width=3)
        self.mute_btn.pack(side=tk.LEFT, padx=1)
        
        self.volume_scale = ttk.Scale(volume_frame, from_=0, to=100, orient=tk.HORIZONTAL,
                                     command=self.on_volume_change, length=80)
        self.volume_scale.set(100)
        self.volume_scale.pack(side=tk.LEFT, padx=2)
        
        # æ’­æ”¾é€Ÿåº¦æ§åˆ¶
        speed_frame = ttk.Frame(time_frame)
        speed_frame.pack(side=tk.RIGHT, padx=10)
        
        ttk.Label(speed_frame, text="é€Ÿåº¦:", font=default_font).pack(side=tk.LEFT, padx=2)
        self.speed_var = tk.StringVar(value="1.0x")
        speed_combo = ttk.Combobox(speed_frame, textvariable=self.speed_var, width=6,
                                   values=["0.25x", "0.5x", "0.75x", "1.0x", "1.25x", "1.5x", "2.0x"],
                                   state="readonly")
        speed_combo.pack(side=tk.LEFT, padx=2)
        speed_combo.bind('<<ComboboxSelected>>', self.on_speed_change)
        
        # å³ä¾§ï¼šå±æ€§é¢æ¿
        property_frame = ttk.LabelFrame(main_container, text="å±æ€§", padding=10, width=250)
        main_container.add(property_frame, weight=1)
        
        # åˆ›å»ºå±æ€§é¢æ¿å†…å®¹
        self.create_property_panel(property_frame)
    
    def create_property_panel(self, parent):
        """åˆ›å»ºå±æ€§é¢æ¿"""
        # è§†é¢‘ç¼©ç•¥å›¾é¢„è§ˆ
        thumbnail_frame = ttk.LabelFrame(parent, text="è§†é¢‘ç¼©ç•¥å›¾", padding=5)
        thumbnail_frame.pack(fill=tk.X, pady=5)
        
        self.thumbnail_canvas = tk.Canvas(thumbnail_frame, bg="#2B2B2B", height=120, width=160,
                                          highlightthickness=0, bd=0)
        self.thumbnail_canvas.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # è§†é¢‘ä¿¡æ¯
        info_frame = ttk.LabelFrame(parent, text="è§†é¢‘ä¿¡æ¯", padding=5)
        info_frame.pack(fill=tk.X, pady=5)
        
        self.info_text = tk.Text(info_frame, height=8, wrap=tk.WORD, font=default_font,
                                 state=tk.DISABLED, relief=tk.FLAT)
        self.info_text.pack(fill=tk.BOTH, expand=True)
        
        # å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
        clip_frame = ttk.LabelFrame(parent, text="å‰ªè¾‘ç‰‡æ®µ", padding=5)
        clip_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # ç‰‡æ®µåˆ—è¡¨æ ‘å½¢è§†å›¾
        columns = ('åç§°', 'å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´', 'æ—¶é•¿')
        self.clip_tree = ttk.Treeview(clip_frame, columns=columns, show='tree headings', height=10)
        
        self.clip_tree.heading('#0', text='#')
        self.clip_tree.heading('åç§°', text='åç§°')
        self.clip_tree.heading('å¼€å§‹æ—¶é—´', text='å¼€å§‹æ—¶é—´')
        self.clip_tree.heading('ç»“æŸæ—¶é—´', text='ç»“æŸæ—¶é—´')
        self.clip_tree.heading('æ—¶é•¿', text='æ—¶é•¿')
        
        self.clip_tree.column('#0', width=40)
        self.clip_tree.column('åç§°', width=100)
        self.clip_tree.column('å¼€å§‹æ—¶é—´', width=80)
        self.clip_tree.column('ç»“æŸæ—¶é—´', width=80)
        self.clip_tree.column('æ—¶é•¿', width=80)
        
        scrollbar = ttk.Scrollbar(clip_frame, orient=tk.VERTICAL, command=self.clip_tree.yview)
        self.clip_tree.configure(yscrollcommand=scrollbar.set)
        
        self.clip_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        self.clip_tree.bind('<Double-1>', self.on_clip_select)
    
    def create_timeline(self):
        """åˆ›å»ºæ—¶é—´è½´"""
        timeline_frame = ttk.LabelFrame(self.root, text="æ—¶é—´è½´", padding=5)
        timeline_frame.pack(fill=tk.BOTH, expand=False, padx=5, pady=5, side=tk.BOTTOM)
        
        # åˆ›å»ºæ»šåŠ¨æ¡
        timeline_scroll = ttk.Scrollbar(timeline_frame, orient=tk.HORIZONTAL)
        timeline_scroll.pack(side=tk.BOTTOM, fill=tk.X)
        
        # å®šä¹‰åŒæ­¥æ»šåŠ¨å‡½æ•°
        def sync_scroll(*args):
            self.ruler_canvas.xview(*args)
            self.timeline_canvas.xview(*args)
            
        timeline_scroll.config(command=sync_scroll)
        
        # æ—¶é—´æ ‡å°º
        ruler_frame = ttk.Frame(timeline_frame, height=30)
        ruler_frame.pack(fill=tk.X, pady=2)
        
        self.ruler_canvas = tk.Canvas(ruler_frame, height=25, bg="#F0F0F0",
                                      xscrollcommand=timeline_scroll.set)
        self.ruler_canvas.pack(fill=tk.BOTH, expand=True)
        
        # æ—¶é—´è½´è½¨é“
        track_container = ttk.Frame(timeline_frame)
        track_container.pack(fill=tk.BOTH, expand=True)
        
        # æ—¶é—´è½´ç”»å¸ƒ
        self.timeline_canvas = tk.Canvas(track_container, bg="#2B2B2B", height=150,
                                         xscrollcommand=timeline_scroll.set)
        self.timeline_canvas.pack(fill=tk.BOTH, expand=True)
        
        # ç»‘å®šäº‹ä»¶
        self.timeline_canvas.bind("<Button-1>", self.on_timeline_click)
        self.timeline_canvas.bind("<B1-Motion>", self.on_timeline_click)
        self.ruler_canvas.bind("<Button-1>", self.on_timeline_click)
        self.ruler_canvas.bind("<B1-Motion>", self.on_timeline_click)
        
        # æ—¶é—´è½´æ§åˆ¶
        timeline_control = ttk.Frame(timeline_frame)
        timeline_control.pack(fill=tk.X, pady=2)
        
        ttk.Button(timeline_control, text="æ”¾å¤§", command=self.timeline_zoom_in, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(timeline_control, text="ç¼©å°", command=self.timeline_zoom_out, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(timeline_control, text="é€‚åº”", command=self.timeline_fit, width=8).pack(side=tk.LEFT, padx=2)
        
        # æ—¶é—´è½´ç¼©æ”¾å˜é‡
        self.timeline_scale = 1.0  # åƒç´ /ç§’
    
    def create_status_bar(self):
        """åˆ›å»ºçŠ¶æ€æ """
        self.status_bar = ttk.Frame(self.root, relief=tk.SUNKEN)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)
        
        self.status_label = ttk.Label(self.status_bar, text="å°±ç»ª", font=default_font)
        self.status_label.pack(side=tk.LEFT, padx=5)
        
        # åˆ†è¾¨ç‡æ˜¾ç¤º
        self.resolution_label = ttk.Label(self.status_bar, text="", font=default_font)
        self.resolution_label.pack(side=tk.RIGHT, padx=5)
        
        # å¸§ç‡æ˜¾ç¤º
        self.fps_label = ttk.Label(self.status_bar, text="", font=default_font)
        self.fps_label.pack(side=tk.RIGHT, padx=5)
    
    # ============ èœå•åŠŸèƒ½å®ç° ============
    
    def open_video(self):
        """æ‰“å¼€è§†é¢‘æ–‡ä»¶"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            filetypes=[
                ("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv *.m4v"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if file_path:
            self.load_video(file_path)
    
    def _parse_iso8601(self, time_str):
        """è§£æISO8601æ—¶é—´å­—ç¬¦ä¸²"""
        try:
            # å¤„ç† '2023-10-01T12:00:00.000000Z'
            if time_str.endswith('Z'):
                time_str = time_str[:-1]
            # å¤„ç†å¯èƒ½çš„æ¯«ç§’
            if '.' in time_str:
                # æˆªæ–­åˆ°6ä½å¾®ç§’ï¼Œå› ä¸ºPythonåªæ”¯æŒ6ä½
                main, frac = time_str.split('.')
                frac = frac[:6]
                time_str = f"{main}.{frac}"
            return datetime.fromisoformat(time_str)
        except Exception as e:
            print(f"æ—¶é—´è§£æé”™è¯¯: {time_str}, {e}")
            return None

    def load_video(self, video_path):
        """åŠ è½½è§†é¢‘"""
        if not HAS_CV2:
            messagebox.showerror("é”™è¯¯", "æœªå®‰è£… opencv-pythonï¼\nè¯·è¿è¡Œ: pip install opencv-python")
            return
        
        # å…³é—­ä¹‹å‰æ‰“å¼€çš„è§†é¢‘
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        
        self.video_path = video_path
        # è·å–è§†é¢‘åˆ›å»ºæ—¶é—´
        self.video_creation_time, _ = self._get_video_creation_time(video_path)
        self.update_status(f"æ­£åœ¨åŠ è½½è§†é¢‘: {os.path.basename(video_path)}...")
        
        try:
            # ä½¿ç”¨ OpenCV åŠ è½½è§†é¢‘
            self.cap = cv2.VideoCapture(video_path)
            
            if not self.cap.isOpened():
                raise Exception("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            
            # è·å–ç¼–è§£ç å™¨ä¿¡æ¯
            fourcc = int(self.cap.get(cv2.CAP_PROP_FOURCC))
            codec = "".join([chr((fourcc >> 8 * i) & 0xFF) for i in range(4)])
            
            self.video_info = {
                'path': video_path,
                'name': os.path.basename(video_path),
                'duration': duration,
                'fps': fps,
                'width': width,
                'height': height,
                'codec': codec if codec.strip() else 'Unknown',
                'frame_count': frame_count
            }
            
            self.total_frames = frame_count
            self.current_frame_pos = 0
            
            # æ›´æ–°ç•Œé¢
            self.update_video_info()
            self.update_preview_label("")
            
            # æ˜¾ç¤ºç¬¬ä¸€å¸§
            self.seek_to_frame(0)
            
            # ç”Ÿæˆç¼©ç•¥å›¾
            self.generate_thumbnail()
            
            self.update_status(f"è§†é¢‘åŠ è½½æˆåŠŸ: {self.video_info['name']} ({width}x{height}, {fps:.2f}fps)")
            
            # åˆå§‹åŒ–å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
            self.clips = [{
                'id': 'clip_0',
                'name': 'åˆå§‹ç‰‡æ®µ',
                'start_frame': 0,
                'end_frame': self.total_frames,
                'source': self.video_path
            }]
            self.update_clip_list()
            
            # åˆå§‹åŒ–æ—¶é—´è½´
            self.timeline_fit()
            
            # ä¼˜å…ˆæ£€æŸ¥GoPro GPSæ•°æ® (GPMD)
            # å¦‚æœå­˜åœ¨GPMDæµï¼Œç›´æ¥ä½¿ç”¨å®ƒï¼Œä¸å†å°è¯•åŠ è½½å¤–éƒ¨GPXæ–‡ä»¶
            # è¿™æ ·å¯ä»¥ä¿è¯æœ€ä½³çš„æ—¶é—´åŒæ­¥
            gpmd_info = self.get_gpmd_stream_index(video_path)
            
            if gpmd_info is not None:
                self.update_status("æ£€æµ‹åˆ°GoPro GPSæ•°æ®ï¼Œæ­£åœ¨è‡ªåŠ¨å¯¼å…¥...")
                # è‡ªåŠ¨å¯¼å…¥ï¼Œä¸è¯¢é—®ç”¨æˆ·
                self.import_gopro_gps(auto=True)
            else:
                # å¦åˆ™å°è¯•åŠ è½½å¤–éƒ¨GPXæ–‡ä»¶
                self.load_gpx_data(video_path)
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½è§†é¢‘å¤±è´¥:\n{str(e)}")
            self.update_status(f"åŠ è½½å¤±è´¥: {str(e)}")
            if self.cap is not None:
                self.cap.release()
                self.cap = None
    
    def set_manual_offset(self):
        """æ‰‹åŠ¨è®¾ç½®æ—¶é—´åç§»"""
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¯¹è¯æ¡†
        offset_str = simpledialog.askstring("æ‰‹åŠ¨åŒæ­¥", f"å½“å‰åç§»: {self.gpx_offset:.2f}ç§’\nè¯·è¾“å…¥æ–°çš„åç§»é‡ (ç§’):", initialvalue=str(self.gpx_offset))
        if offset_str:
            try:
                self.gpx_offset = float(offset_str)
                self.update_status(f"æ‰‹åŠ¨è®¾ç½®åç§»: {self.gpx_offset:.2f}ç§’")
                if not self.playing:
                    self.seek_to_frame(self.current_frame_pos)
            except ValueError:
                messagebox.showerror("é”™è¯¯", "æ— æ•ˆçš„æ•°å­—æ ¼å¼")

    def import_gopro_gps(self, auto=False):
        """å¯¼å…¥GoPro GPSæ•°æ®
        :param auto: æ˜¯å¦ä¸ºè‡ªåŠ¨å¯¼å…¥ï¼ˆä¸æ˜¾ç¤ºæˆåŠŸå¼¹çª—ï¼‰
        """
        if not self.video_path:
            messagebox.showinfo("æç¤º", "è¯·å…ˆæ‰“å¼€ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
            return
            
        stream_info = self.get_gpmd_stream_index(self.video_path)
        if stream_info is None:
            messagebox.showinfo("æç¤º", "æœªåœ¨è§†é¢‘ä¸­æ‰¾åˆ°GoPro GPSæ•°æ® (GPMDæµ)")
            return
            
        stream_index, start_time = stream_info
            
        self.update_status("æ­£åœ¨æå–GoPro GPSæ•°æ®...")
        
        def _process():
            try:
                raw_data = self.extract_gpmd_data(self.video_path, stream_index)
                if not raw_data:
                    self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "æå–æ•°æ®å¤±è´¥"))
                    return
                    
                points = self.parse_gpmd_structure(raw_data)
                
                if not points:
                    self.root.after(0, lambda: messagebox.showinfo("æç¤º", "æœªè§£æåˆ°æœ‰æ•ˆçš„GPSç‚¹"))
                    return
                
                # Normalize time_offset by subtracting stream start time if available
                # This handles cases where pts_time is absolute or offset by start_time
                if start_time is not None and start_time > 0:
                    for p in points:
                        p['time_offset'] -= start_time
                
                # Assign timestamps based on GPMD timing
                # Use the time_offset (derived from pts_time) to set the datetime
                if self.video_creation_time:
                    for p in points:
                        # Ensure time_offset is non-negative for datetime calculation?
                        # Actually if pts < start_time, it might be negative.
                        # But usually pts >= start_time.
                        offset = max(0, p['time_offset'])
                        p['time'] = self.video_creation_time + timedelta(seconds=offset)
                else:
                    # Fallback if no video creation time
                    for p in points:
                        p['time'] = datetime.utcfromtimestamp(max(0, p['time_offset']))
                
                # Update data
                self.gpx_data = points
                self.gpx_start_time = points[0]['time']
                self.gpx_end_time = points[-1]['time']
                self.gpx_offset = 0.0 # Perfectly synced by definition
                
                # Recalculate speeds
                self._calculate_speeds_from_points(points)
                
                # Update UI
                self.root.after(0, lambda: self.update_status(f"å·²å¯¼å…¥GoPro GPSæ•°æ® ({len(points)}ç‚¹)"))
                self.root.after(0, self.draw_track_thumbnail)
                
                if not auto:
                    self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸå¯¼å…¥ {len(points)} ä¸ªGPSç‚¹\nå·²è‡ªåŠ¨åŒæ­¥"))
                
            except Exception as e:
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"è§£æå¤±è´¥: {str(e)}"))

        threading.Thread(target=_process).start()

    def check_and_import_gopro_gps(self):
        """æ£€æŸ¥å¹¶å¯¼å…¥GoPro GPSæ•°æ®ï¼ˆæ‰‹åŠ¨èœå•è°ƒç”¨ï¼‰"""
        stream_info = self.get_gpmd_stream_index(self.video_path)
        if stream_info is not None:
            if messagebox.askyesno("GoPro GPS", "æ£€æµ‹åˆ°è§†é¢‘åŒ…å«GoPro GPSæ•°æ®ï¼Œæ˜¯å¦å¯¼å…¥ï¼Ÿ\n(è¿™å°†è¦†ç›–å½“å‰çš„GPXæ•°æ®)"):
                self.import_gopro_gps()
        else:
            messagebox.showinfo("æç¤º", "æœªæ£€æµ‹åˆ°GoPro GPSæ•°æ®æµ")

    def _calculate_speeds_from_points(self, points):
        """Recalculate speeds and distances for internal point structure"""
        if not points or len(points) < 2:
            return

        for i in range(len(points) - 1):
            p1 = points[i]
            p2 = points[i+1]
            
            # Calculate distance
            dist = self._haversine_distance(p1['lat'], p1['lon'], p2['lat'], p2['lon'])
            
            # Calculate time diff
            t1 = p1['time']
            t2 = p2['time']
            dt = (t2 - t1).total_seconds()
            
            speed = 0.0
            if dt > 0:
                speed = (dist / 1000.0) / (dt / 3600.0) # km/h
                
            p1['speed'] = speed
            p1['dist_to_next'] = dist
            
        # Last point speed same as previous
        points[-1]['speed'] = points[-2]['speed']
        points[-1]['dist_to_next'] = 0.0

    def draw_track_thumbnail(self):
        """Draw track thumbnail for internal points"""
        if not hasattr(self, 'gpx_data') or not self.gpx_data:
            return
            
        # Extract lat/lon list
        points = []
        if isinstance(self.gpx_data, list):
            # Internal point structure
            points = [(p['lat'], p['lon']) for p in self.gpx_data]
        elif isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data:
            # Old segment structure
            seg_points = []
            for s in self.gpx_data['segments']:
                seg_points.append((s['lat_start'], s['lon_start']))
            if self.gpx_data['segments']:
                 last = self.gpx_data['segments'][-1]
                 seg_points.append((last['lat_end'], last['lon_end']))
            points = seg_points
            
        if not points:
            return

        # Generate thumbnail
        
        # Calculate bounds
        lats = [p[0] for p in points]
        lons = [p[1] for p in points]
        min_lat, max_lat = min(lats), max(lats)
        min_lon, max_lon = min(lons), max(lons)
        
        # Create image
        w, h = 200, 150
        padding = 10
        img = Image.new('RGBA', (w, h), (0, 0, 0, 128)) # Semi-transparent background
        from PIL import ImageDraw
        draw = ImageDraw.Draw(img)
        
        # Scale
        lat_range = max_lat - min_lat
        lon_range = max_lon - min_lon
        
        if lat_range == 0 or lon_range == 0:
            return
            
        scale_x = (w - 2 * padding) / lon_range
        scale_y = (h - 2 * padding) / lat_range
        scale = min(scale_x, scale_y)
        
        # Transform function
        def transform(lat, lon):
            x = padding + (lon - min_lon) * scale
            y = h - (padding + (lat - min_lat) * scale) # Invert Y for screen coords
            return x, y
            
        # Draw track
        screen_points = [transform(lat, lon) for lat, lon in points]
        draw.line(screen_points, fill=(0, 255, 0, 255), width=2)
        
        # Store for overlay (Tkinter)
        self.track_thumbnail_img = ImageTk.PhotoImage(img)
        self.track_transform_func = transform
        self.track_bounds = (min_lat, max_lat, min_lon, max_lon)
        
        # Store for overlay (OpenCV)
        # Convert PIL RGBA to numpy array
        pil_array = np.array(img)
        # Convert RGBA to BGRA for OpenCV
        if HAS_CV2:
            self.track_thumbnail = cv2.cvtColor(pil_array, cv2.COLOR_RGBA2BGRA)
            # Store transform parameters for _draw_overlay_on_frame
            # Format: (min_lat, min_lon, scale, h, padding, lon_correction=1.0)
            self.track_transform = (min_lat, min_lon, scale, h, padding, 1.0)
        
    def get_gpmd_stream_index(self, video_path):
        """è·å–GoPro GPMDæµç´¢å¼•
        :return: (index, start_time) or None
        """
        ffprobe_cmd = self._get_ffprobe_cmd()
        if not ffprobe_cmd:
            return None

        try:
            cmd = ffprobe_cmd + [
                '-v', 'quiet',
                '-print_format', 'json',
                '-show_streams',
                video_path
            ]
            
            startupinfo = None
            if platform.system() == 'Windows':
                startupinfo = subprocess.STARTUPINFO()
                startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                
            output = subprocess.check_output(cmd, startupinfo=startupinfo).decode('utf-8')
            data = json.loads(output)
            
            for stream in data.get('streams', []):
                # æ£€æŸ¥ codec_tag_string æˆ– handler_name
                is_gpmd = False
                if stream.get('codec_tag_string') == 'gpmd':
                    is_gpmd = True
                
                tags = stream.get('tags', {})
                if 'GoPro MET' in tags.get('handler_name', ''):
                    is_gpmd = True
                
                if is_gpmd:
                    index = stream['index']
                    start_time = None
                    if 'start_time' in stream:
                        try:
                            start_time = float(stream['start_time'])
                        except:
                            pass
                    return index, start_time
                    
        except Exception as e:
            print(f"æŸ¥æ‰¾GPMDæµå¤±è´¥: {e}")
        return None

    def extract_gpmd_data(self, video_path, stream_index):
        """æå–GPMDæ•°æ®åŒ…"""
        ffprobe_cmd = self._get_ffprobe_cmd()
        if not ffprobe_cmd:
            return None

        try:
            # ä½¿ç”¨ ffprobe è·å–åŒ…å«æ•°æ®çš„åŒ…ä¿¡æ¯
            cmd = ffprobe_cmd + [
                '-v', 'quiet',
                '-select_streams', str(stream_index),
                '-show_packets',
                '-show_data',
                '-print_format', 'json',
                video_path
            ]
            
            startupinfo = None
            if platform.system() == 'Windows':
                startupinfo = subprocess.STARTUPINFO()
                startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                
            # æ³¨æ„ï¼šå¯¹äºå¤§æ–‡ä»¶ï¼Œè¿™å¯èƒ½ä¼šäº§ç”Ÿå¤§é‡è¾“å‡º
            # æˆ‘ä»¬å¯èƒ½éœ€è¦é™åˆ¶è¯»å–é‡ï¼Œæˆ–è€…åˆ†å—è¯»å–
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=startupinfo)
            stdout, stderr = process.communicate()
            
            if process.returncode != 0:
                print(f"æå–GPMDæ•°æ®å¤±è´¥: {stderr}")
                return None
                
            return json.loads(stdout.decode('utf-8'))
        except Exception as e:
            print(f"æå–GPMDæ•°æ®å¼‚å¸¸: {e}")
            return None

    def parse_gpmd_structure(self, packet_data):
        """è§£æGPMDæ•°æ®ç»“æ„"""
        if not packet_data or 'packets' not in packet_data:
            return []
            
        points = []
        
        for packet in packet_data['packets']:
            if 'data' not in packet or 'pts_time' not in packet:
                continue
                
            pts_time = float(packet['pts_time'])
            hex_data = packet['data'].strip()
            
            try:
                # å°† hex è½¬æ¢ä¸º bytes
                data = bytes.fromhex(hex_data)
            except:
                continue
                
            # è§£æ payload
            offset = 0
            length = len(data)
            
            while offset < length - 8:
                try:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ GPS5
                    if data[offset:offset+4] == b'GPS5':
                        count = struct.unpack('>H', data[offset+6:offset+8])[0]
                        data_start = offset + 8
                        
                        # GPS5 åŒ…å« 5 ä¸ª int32: lat, lon, alt, speed2d, speed3d
                        num_samples = count // 5
                        if num_samples > 0:
                            fmt = f'>{count}i'
                            try:
                                values = struct.unpack(fmt, data[data_start:data_start + count*4])
                                
                                for i in range(num_samples):
                                    idx = i * 5
                                    lat = values[idx] / 10000000.0
                                    lon = values[idx+1] / 10000000.0
                                    alt = values[idx+2] / 1000.0
                                    # speed3d = values[idx+4] / 1000.0 
                                    
                                    # è®¡ç®—è¯¥ç‚¹çš„æ—¶é—´
                                    # å‡è®¾ 18Hz é‡‡æ ·ç‡ (GoPro æ ‡å‡†)
                                    point_time = pts_time + i * (1.0/18.0)
                                    
                                    points.append({
                                        'lat': lat,
                                        'lon': lon,
                                        'ele': alt,
                                        'speed': 0, # å°†ç”± _calculate_speeds_from_points è®¡ç®—
                                        'time': datetime.utcfromtimestamp(point_time),
                                        'time_offset': point_time
                                    })
                            except struct.error:
                                pass
                                
                        # è·³è¿‡å·²å¤„ç†çš„å— (4å­—èŠ‚å¯¹é½)
                        block_size = 8 + count * 4
                        if block_size % 4 != 0:
                            block_size += (4 - (block_size % 4))
                        offset += block_size
                    else:
                        offset += 4
                except Exception:
                    offset += 1
                    
        return points

    def _haversine_distance(self, lat1, lon1, lat2, lon2):
        """Calculate haversine distance between two points in meters"""
        R = 6371000 # Earth radius in meters
        phi1, phi2 = math.radians(lat1), math.radians(lat2)
        dphi = math.radians(lat2 - lat1)
        dlambda = math.radians(lon2 - lon1)
        
        a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2) * math.sin(dlambda/2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        return R * c

    def import_video(self):
        """å¯¼å…¥è§†é¢‘ï¼ˆæ·»åŠ åˆ°æ—¶é—´è½´ï¼‰"""
        file_path = filedialog.askopenfilename(
            title="å¯¼å…¥è§†é¢‘",
            filetypes=[("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv *.m4v")]
        )
        
        if file_path:
            # TODO: æ·»åŠ åˆ°å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
            self.update_status(f"å¯¼å…¥è§†é¢‘: {os.path.basename(file_path)}")
    
    def import_gpx(self):
        """å¯¼å…¥GPXæ–‡ä»¶"""
        if not self.video_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return

        file_path = filedialog.askopenfilename(
            title="å¯¼å…¥GPXæ–‡ä»¶",
            filetypes=[("GPXæ–‡ä»¶", "*.gpx"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            self.load_gpx_data(self.video_path, gpx_path=file_path)

    def load_gpx_data(self, video_path, gpx_path=None):
        """åŠ è½½å¯¹åº”çš„GPXæ•°æ®"""
        try:
            if not gpx_path:
                # å¯»æ‰¾åŒåGPXæ–‡ä»¶æˆ–ride.gpx
                video_dir = os.path.dirname(video_path)
                
                # 1. å°è¯• ride.gpx (ä¼˜å…ˆçº§æœ€é«˜)
                check_path = os.path.join(video_dir, 'ride.gpx')
                if os.path.exists(check_path):
                    gpx_path = check_path
                
                # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å½“å‰ç›®å½•ä¸‹çš„ ride.gpx
                if not gpx_path and os.path.exists('ride.gpx'):
                    gpx_path = 'ride.gpx'
                
                # 3. å°è¯•åŒåGPX
                if not gpx_path:
                    base_name = os.path.splitext(os.path.basename(video_path))[0]
                    check_path = os.path.join(video_dir, f"{base_name}.gpx")
                    if os.path.exists(check_path):
                        gpx_path = check_path
                
            if not gpx_path:
                return

            points, name, gpx_start_time = self._parse_gpx_file(gpx_path)
            
            if not points:
                return

            speeds = self._calculate_speeds(points)
            
            # å¤„ç†æ—¶é—´å¹¶å»ºç«‹æŸ¥è¯¢ç»“æ„
            segments = []
            
            # å°è¯•è·å–è§†é¢‘å¼€å§‹æ—¶é—´ä»¥è¿›è¡ŒåŒæ­¥
            video_start_time, method = self._get_video_creation_time(video_path)
            
            # è®¡ç®—åˆå§‹åç§»é‡
            if video_start_time and gpx_start_time:
                # åç§»é‡ = è§†é¢‘å¼€å§‹æ—¶é—´ - GPXå¼€å§‹æ—¶é—´
                initial_offset = (video_start_time - gpx_start_time).total_seconds()
                self.gpx_offset = initial_offset
                
                msg = f"è‡ªåŠ¨åŒæ­¥GPX: åç§» {self.gpx_offset:.2f}ç§’\nè§†é¢‘æ—¶é—´: {video_start_time} ({method})\nGPXæ—¶é—´: {gpx_start_time}"
                self.update_status(msg)
                print(msg)
                
                # å¼¹å‡ºæç¤ºè®©ç”¨æˆ·ç¡®è®¤æ—¶é—´
                messagebox.showinfo("æ—¶é—´åŒæ­¥ä¿¡æ¯", msg)
            else:
                self.gpx_offset = 0.0
                
            for i in range(len(speeds)):
                p1 = points[i]
                p2 = points[i+1]
                t1 = p1[3]
                t2 = p2[3]
                
                if t1 and t2:
                    # è®¡ç®—ç›¸å¯¹äºGPXèµ·ç‚¹çš„ç§’æ•°
                    rel_t1 = (t1 - gpx_start_time).total_seconds()
                    rel_t2 = (t2 - gpx_start_time).total_seconds()
                    
                    # è·å–è¯¥æ®µçš„å¿ƒç‡ï¼ˆå–èµ·ç‚¹çš„å¿ƒç‡ï¼‰
                    hr = points[i][4] if len(points[i]) > 4 else 0
                    
                    segments.append({
                        'start': rel_t1,
                        'end': rel_t2,
                        'speed': speeds[i],
                        'hr': hr,
                        'lat_start': points[i][0],
                        'lon_start': points[i][1],
                        'lat_end': points[i+1][0],
                        'lon_end': points[i+1][1]
                    })
            
            self.gpx_data = {'segments': segments, 'name': name, 'start_time': gpx_start_time}
            
            # ç”Ÿæˆå…¨é‡è½¨è¿¹ç¼©ç•¥å›¾ (å§‹ç»ˆæ˜¾ç¤ºå®Œæ•´è½¨è¿¹)
            all_points = []
            for seg in segments:
                all_points.append((seg['lat_start'], seg['lon_start']))
            # æ·»åŠ æœ€åä¸€ç‚¹
            if segments:
                all_points.append((segments[-1]['lat_end'], segments[-1]['lon_end']))
                
            self.track_thumbnail, self.track_transform = self.generate_track_thumbnail(all_points)
            
            self.update_status(f"å·²åŠ è½½GPXæ•°æ®: {name}")
            
            # å¦‚æœæš‚åœçŠ¶æ€ï¼Œåˆ·æ–°å½“å‰å¸§ä»¥æ˜¾ç¤ºå åŠ å±‚
            if not self.playing and self.cap:
                self.seek_to_frame(self.current_frame_pos)
            
        except Exception as e:
            print(f"GPXåŠ è½½å¤±è´¥: {e}")
            self.update_status(f"GPXåŠ è½½å¤±è´¥: {e}")

    def _parse_gpx_file(self, gpx_path):
        """è§£æGPXæ–‡ä»¶"""
        try:
            dom = xml.dom.minidom.parse(gpx_path)
            gpx = dom.documentElement
            
            # è·å–åç§°
            name = "Unknown"
            trk = gpx.getElementsByTagName('trk')
            if trk:
                name_nodes = trk[0].getElementsByTagName('name')
                if name_nodes and name_nodes[0].firstChild:
                    name = name_nodes[0].firstChild.data
            
            points = []
            
            # è§£æè½¨è¿¹ç‚¹
            trkpts = gpx.getElementsByTagName('trkpt')
            for trkpt in trkpts:
                lat = float(trkpt.getAttribute('lat'))
                lon = float(trkpt.getAttribute('lon'))
                
                ele = 0.0
                ele_nodes = trkpt.getElementsByTagName('ele')
                if ele_nodes and ele_nodes[0].firstChild:
                    ele = float(ele_nodes[0].firstChild.data)
                
                time_obj = None
                time_nodes = trkpt.getElementsByTagName('time')
                if time_nodes and time_nodes[0].firstChild:
                    time_str = time_nodes[0].firstChild.data
                    time_obj = self._parse_time(time_str)
                
                hr = 0
                # å°è¯•è·å–å¿ƒç‡
                extensions = trkpt.getElementsByTagName('extensions')
                if extensions:
                    # å°è¯•å¤šç§å¸¸è§çš„å‘½åç©ºé—´
                    for tag in ['gpxtpx:hr', 'ns3:hr', 'hr']:
                        hr_nodes = extensions[0].getElementsByTagName(tag)
                        if hr_nodes and hr_nodes[0].firstChild:
                            hr = int(hr_nodes[0].firstChild.data)
                            break
                
                points.append((lat, lon, ele, time_obj, hr))
            
            if not points:
                return None, None, None
                
            # è¿‡æ»¤æ‰æ— æ•ˆæ—¶é—´ç‚¹
            points = [p for p in points if p[3] is not None]
            
            if not points:
                return None, None, None

            start_time = points[0][3]
            return points, name, start_time
            
        except Exception as e:
            print(f"è§£æGPXå‡ºé”™: {e}")
            return None, None, None

    def _parse_time(self, t_str):
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼Œç»Ÿä¸€è¿”å› UTC datetime"""
        if not t_str: return None
        
        # ç»Ÿä¸€å¤„ç† Z å’Œ T
        t_str = t_str.replace('Z', '').replace('T', ' ')
        
        # å¤„ç†æ—¶åŒºåç§» (ç®€å•å»æ‰ +08:00 ç­‰ï¼Œå‡å®šä¸º UTC)
        if '+' in t_str:
            t_str = t_str.split('+')[0]
        
        dt = None
        try:
            if '.' in t_str:
                main_part, frac_part = t_str.split('.')
                if len(frac_part) > 6:
                    frac_part = frac_part[:6]
                t_str = f"{main_part}.{frac_part}"
                dt = datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S.%f')
            else:
                dt = datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S')
        except:
            try:
                 dt = datetime.strptime(t_str.split('.')[0], '%Y-%m-%d %H:%M:%S')
            except:
                return None
        
        # å‡å®šè§£æå‡ºæ¥çš„æ˜¯ UTC æ—¶é—´ (naive)
        return dt

    def _calculate_speeds(self, points):
        """è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„é€Ÿåº¦ (km/h)"""
        speeds = []
        # ç®€å•è®¡ç®—æ¯ä¸¤ç‚¹é—´çš„é€Ÿåº¦
        raw_speeds = []
        for i in range(len(points) - 1):
            p1 = points[i]
            p2 = points[i+1]
            
            dist = self._haversine_distance(p1[0], p1[1], p2[0], p2[1])
            time_diff = (p2[3] - p1[3]).total_seconds()
            
            if time_diff > 0:
                speed_kph = (dist / time_diff) * 3.6
            else:
                speed_kph = 0
            raw_speeds.append(speed_kph)
        
        # å¹³æ»‘å¤„ç† (ç§»åŠ¨å¹³å‡)
        if len(raw_speeds) > 0:
            window_size = 5
            for i in range(len(raw_speeds)):
                start = max(0, i - window_size // 2)
                end = min(len(raw_speeds), i + window_size // 2 + 1)
                speeds.append(sum(raw_speeds[start:end]) / (end - start))
            return speeds
            
        return []

    def _haversine_distance(self, lat1, lon1, lat2, lon2):
        """è®¡ç®—ä¸¤ç‚¹é—´çš„è·ç¦» (ç±³)"""
        R = 6371000
        phi1 = math.radians(lat1)
        phi2 = math.radians(lat2)
        delta_phi = math.radians(lat2 - lat1)
        delta_lambda = math.radians(lon2 - lon1)
        
        a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
        return R * c

    def _get_video_creation_time(self, video_path):
        """è·å–è§†é¢‘åˆ›å»ºæ—¶é—´ (å°è¯•è¿”å› UTC æ—¶é—´)"""
        creation_time = None
        method = "Unknown"
        
        # 1. å°è¯•ä½¿ç”¨ ffprobe è·å–å…ƒæ•°æ® (JSON)
        ffprobe_cmd = self._get_ffprobe_cmd()
        if ffprobe_cmd:
            try:
                cmd = ffprobe_cmd + [
                    '-v', 'quiet',
                    '-print_format', 'json',
                    '-show_format',
                    '-show_streams',
                    video_path
                ]
                
                startupinfo = None
                if platform.system() == 'Windows':
                    startupinfo = subprocess.STARTUPINFO()
                    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                    
                output = subprocess.check_output(cmd, startupinfo=startupinfo).decode('utf-8')
                data = json.loads(output)
                
                # Check format tags
                if 'format' in data and 'tags' in data['format']:
                    tags = data['format']['tags']
                    if 'creation_time' in tags:
                        creation_time = self._parse_iso8601(tags['creation_time'])
                        if creation_time:
                            method = "FFprobe Metadata (JSON)"
                
                # Check stream tags (first video stream) if not found yet
                if not creation_time:
                    for stream in data.get('streams', []):
                        if stream.get('codec_type') == 'video':
                            if 'tags' in stream and 'creation_time' in stream['tags']:
                                 creation_time = self._parse_iso8601(stream['tags']['creation_time'])
                                 if creation_time:
                                     method = "FFprobe Stream Metadata (JSON)"
                                     break
            except Exception as e:
                print(f"ffprobe JSONè·å–æ—¶é—´å¤±è´¥: {e}")

        # 2. å¦‚æœå…ƒæ•°æ®è·å–å¤±è´¥ï¼Œå›é€€åˆ°æ–‡ä»¶ç³»ç»Ÿæ—¶é—´
        if not creation_time:
            try:
                # ä¼˜å…ˆä½¿ç”¨ä¿®æ”¹æ—¶é—´ (mtime)ï¼Œå› ä¸ºå®ƒåœ¨å¤åˆ¶æ—¶é€šå¸¸ä¿æŒä¸å˜
                mtime = os.path.getmtime(video_path)
                # è½¬æ¢ä¸º UTC æ—¶é—´ (Naive)
                # datetime.utcfromtimestamp is deprecated
                creation_time = datetime.fromtimestamp(mtime, timezone.utc).replace(tzinfo=None)
                method = "File System MTime (UTC)"
            except:
                pass
            
        print(f"è§†é¢‘æ—¶é—´æ£€æµ‹ç»“æœ: {creation_time} (Method: {method})")
        return creation_time, method

    def generate_track_thumbnail(self, points):
        """ç”Ÿæˆè½¨è¿¹ç¼©ç•¥å›¾"""
        if not points:
            return None, None
            
        lats = np.array([p[0] for p in points])
        lons = np.array([p[1] for p in points])
        
        # æ•°æ®å¹³æ»‘ (ç§»åŠ¨å¹³å‡)
        if len(points) > 10:
            window_size = min(len(points) // 5, 20) # åŠ¨æ€çª—å£å¤§å°ï¼Œæœ€å¤§20
            if window_size > 2:
                kernel = np.ones(window_size) / window_size
                # ä½¿ç”¨ 'valid' æ¨¡å¼ä¼šå‡å°‘ç‚¹æ•°ï¼Œä½¿ç”¨ 'same' æ¨¡å¼è¾¹ç¼˜ä¼šæœ‰è¯¯å·®
                # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ pad æ¨¡å¼æ¥ä¿æŒç‚¹æ•°å¹¶å‡å°‘è¾¹ç¼˜æ•ˆåº”
                lats = np.convolve(np.pad(lats, (window_size//2, window_size//2), mode='edge'), kernel, mode='valid')
                lons = np.convolve(np.pad(lons, (window_size//2, window_size//2), mode='edge'), kernel, mode='valid')
        
        min_lat, max_lat = np.min(lats), np.max(lats)
        min_lon, max_lon = np.min(lons), np.max(lons)
        
        # ç¼©ç•¥å›¾å°ºå¯¸
        w, h = 200, 150
        padding = 10
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ (å¼•å…¥åœ°ç†æ ¡æ­£)
        mid_lat = np.radians((min_lat + max_lat) / 2)
        lon_correction = np.cos(mid_lat)
        
        lat_range = max_lat - min_lat
        lon_range = (max_lon - min_lon) * lon_correction
        
        if lat_range == 0 or lon_range == 0:
            return None, None
            
        # ä¿æŒæ¯”ä¾‹
        scale_x = (w - 2 * padding) / lon_range
        scale_y = (h - 2 * padding) / lat_range
        scale = min(scale_x, scale_y)
        
        # åˆ›å»ºç©ºç™½å›¾åƒ (BGRA) - ä½¿ç”¨é€æ˜èƒŒæ™¯
        thumbnail = np.zeros((h, w, 4), dtype=np.uint8)
        # åŠé€æ˜èƒŒæ™¯ (ç°è‰², alpha=100)
        thumbnail[:] = [50, 50, 50, 100]
        
        # è½¬æ¢åæ ‡ç‚¹
        pts = []
        for lat, lon in zip(lats, lons):
            x = int(padding + (lon - min_lon) * lon_correction * scale)
            y = int(h - padding - (lat - min_lat) * scale) # çº¬åº¦è¶Šé«˜yè¶Šå°
            pts.append([x, y])
            
        pts = np.array(pts, np.int32)
        pts = pts.reshape((-1, 1, 2))
        
        # ç»˜åˆ¶è½¨è¿¹ (ç™½è‰²)
        cv2.polylines(thumbnail, [pts], False, (255, 255, 255, 255), 2, cv2.LINE_AA)
        
        # ç»˜åˆ¶èµ·ç‚¹(ç»¿è‰²)å’Œç»ˆç‚¹(çº¢è‰²)
        start_pt = tuple(pts[0][0])
        end_pt = tuple(pts[-1][0])
        cv2.circle(thumbnail, start_pt, 4, (0, 255, 0, 255), -1)
        cv2.circle(thumbnail, end_pt, 4, (0, 0, 255, 255), -1)
        
        return thumbnail, (min_lat, min_lon, scale, h, padding, lon_correction)

    def update_track_thumbnail_by_offset(self):
        """ä¸å†æ ¹æ®offsetæ›´æ–°ç¼©ç•¥å›¾ï¼Œæ”¹ä¸ºå§‹ç»ˆæ˜¾ç¤ºå…¨é‡è½¨è¿¹"""
        # å·²æ”¹ä¸ºåœ¨ load_gpx_data ä¸­ç”Ÿæˆå…¨é‡è½¨è¿¹ç¼©ç•¥å›¾
        pass


    def draw_speed_gauge(self, frame, speed, max_speed=60, center=None, radius=60):
        """ç»˜åˆ¶æ¨¡æ‹Ÿé€Ÿåº¦è¡¨ç›˜"""
        if center is None:
            h, w = frame.shape[:2]
            center = (w - radius - 30, h - radius - 30)
        
        x, y = center
        
        # 1. ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.circle(overlay, center, radius, (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)
        
        # 2. ç»˜åˆ¶å¤–åœˆ (ä»135åº¦åˆ°405åº¦ï¼Œå…±270åº¦)
        start_angle = 135
        end_angle = 405
        total_angle = 270
        
        # ç»˜åˆ¶åˆ»åº¦
        # å¤§åˆ»åº¦ï¼šæ¯10km/hä¸€ä¸ª
        for i in range(0, max_speed + 1, 10):
            angle = start_angle + (i / max_speed) * total_angle
            angle_rad = math.radians(angle)
            
            # å¤§åˆ»åº¦çº¿
            p1_x = int(x + (radius - 15) * math.cos(angle_rad))
            p1_y = int(y + (radius - 15) * math.sin(angle_rad))
            p2_x = int(x + radius * math.cos(angle_rad))
            p2_y = int(y + radius * math.sin(angle_rad))
            
            cv2.line(frame, (p1_x, p1_y), (p2_x, p2_y), (255, 255, 255), 2)
            
            # æ•°å­—
            if i % 20 == 0: # æ¯20æ˜¾ç¤ºæ•°å­—
                text_x = int(x + (radius - 30) * math.cos(angle_rad))
                text_y = int(y + (radius - 30) * math.sin(angle_rad))
                
                # ç®€å•åç§»ä¿®æ­£æ–‡å­—å±…ä¸­
                text_x -= 8
                text_y += 5
                
                cv2.putText(frame, str(i), (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

        # 3. ç»˜åˆ¶æŒ‡é’ˆ
        # é™åˆ¶é€Ÿåº¦åœ¨0-max_speedä¹‹é—´
        disp_speed = max(0, min(speed, max_speed))
        needle_angle = start_angle + (disp_speed / max_speed) * total_angle
        needle_rad = math.radians(needle_angle)
        
        needle_len = radius - 10
        needle_x = int(x + needle_len * math.cos(needle_rad))
        needle_y = int(y + needle_len * math.sin(needle_rad))
        
        cv2.line(frame, center, (needle_x, needle_y), (0, 0, 255), 3)
        
        # 4. ä¸­å¿ƒåœ†ç‚¹
        cv2.circle(frame, center, 5, (255, 0, 0), -1)
        cv2.circle(frame, center, 3, (200, 200, 200), -1)
        
        # 5. æ˜¾ç¤ºå½“å‰æ•°å­—é€Ÿåº¦ (åœ¨ä¸‹æ–¹)
        text_speed = f"{speed:.1f}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        text_size = cv2.getTextSize(text_speed, font, 0.8, 2)[0]
        
        # åœ¨è¡¨ç›˜ä¸‹æ–¹ä¸­å¿ƒ
        tx = x - text_size[0] // 2
        ty = y + radius // 2 + 10
        
        cv2.putText(frame, text_speed, (tx, ty), font, 0.8, (255, 255, 255), 2)
        
        # å•ä½
        cv2.putText(frame, "km/h", (x - 15, y + radius // 2 + 25), font, 0.4, (200, 200, 200), 1)

    def get_data_at_time(self, current_seconds):
        """è·å–æŒ‡å®šæ—¶é—´ç‚¹çš„GPXæ•°æ®ï¼ˆé€Ÿåº¦ã€å¿ƒç‡ã€ç»åº¦ã€çº¬åº¦ï¼‰"""
        if not self.gpx_data:
            self.debug_info = {'status': 'No Data'}
            return 0.0, 0, None, None
            
        # 1. å¤„ç† GPMD æ ¼å¼ (åˆ—è¡¨)
        if isinstance(self.gpx_data, list):
            points = self.gpx_data
            if not points:
                return 0.0, 0, None, None
                
            target_time = current_seconds + self.gpx_offset
            
            # æ‰‹åŠ¨äºŒåˆ†æŸ¥æ‰¾ (points sorted by time_offset)
            low = 0
            high = len(points) - 1
            
            # è¾¹ç•Œæ£€æŸ¥
            if target_time < points[0]['time_offset']:
                p = points[0]
                return p['speed'], 0, p['lat'], p['lon']
            if target_time > points[-1]['time_offset']:
                p = points[-1]
                return p['speed'], 0, p['lat'], p['lon']
            
            while low <= high:
                mid = (low + high) // 2
                p = points[mid]
                p_time = p['time_offset']
                
                if p_time <= target_time:
                    if mid == len(points) - 1 or points[mid+1]['time_offset'] > target_time:
                        # Found the interval [mid, mid+1]
                        # Interpolate
                        p1 = points[mid]
                        if mid == len(points) - 1:
                            return p1['speed'], 0, p1['lat'], p1['lon']
                            
                        p2 = points[mid+1]
                        t1 = p1['time_offset']
                        t2 = p2['time_offset']
                        
                        ratio = 0.0
                        if t2 > t1:
                            ratio = (target_time - t1) / (t2 - t1)
                            
                        lat = p1['lat'] + (p2['lat'] - p1['lat']) * ratio
                        lon = p1['lon'] + (p2['lon'] - p1['lon']) * ratio
                        speed = p1['speed'] + (p2['speed'] - p1['speed']) * ratio
                        
                        return speed, 0, lat, lon
                    else:
                        low = mid + 1
                else:
                    high = mid - 1
            
            return 0.0, 0, None, None

        # 2. å¤„ç† GPX æ ¼å¼ (å­—å…¸)
        elif isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data:
            segments = self.gpx_data['segments']
            if not segments:
                return 0.0, 0, None, None
            
            # åº”ç”¨æ—¶é—´åç§»
            target_time = current_seconds + self.gpx_offset
            
            self.debug_info['target_time'] = target_time
            self.debug_info['offset'] = self.gpx_offset
            
            # äºŒåˆ†æŸ¥æ‰¾
            low = 0
            high = len(segments) - 1
            
            while low <= high:
                mid = (low + high) // 2
                seg = segments[mid]
                if seg['start'] <= target_time <= seg['end']:
                    # çº¿æ€§æ’å€¼è®¡ç®—åæ ‡
                    duration = seg['end'] - seg['start']
                    ratio = 0.0
                    if duration > 0.001:
                        ratio = (target_time - seg['start']) / duration
                        lat = seg['lat_start'] + (seg['lat_end'] - seg['lat_start']) * ratio
                        lon = seg['lon_start'] + (seg['lon_end'] - seg['lon_start']) * ratio
                    else:
                        lat = seg['lat_start']
                        lon = seg['lon_start']
                    
                    self.debug_info['seg_idx'] = mid
                    self.debug_info['seg_start'] = seg['start']
                    self.debug_info['seg_end'] = seg['end']
                    self.debug_info['ratio'] = ratio
                    self.debug_info['lat'] = lat
                    self.debug_info['lon'] = lon
                    
                    return seg['speed'], seg.get('hr', 0), lat, lon
                elif seg['start'] > target_time:
                    high = mid - 1
                else:
                    low = mid + 1
                    
            # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œè¿”å›æœ€è¿‘çš„æ•°æ®æˆ–è€…é»˜è®¤å€¼
            if target_time < segments[0]['start']:
                s = segments[0]
                self.debug_info['status'] = 'Before Start'
                self.debug_info['seg_idx'] = 0
                self.debug_info['lat'] = s.get('lat_start')
                return s['speed'], s.get('hr', 0), s.get('lat_start'), s.get('lon_start')
            if target_time > segments[-1]['end']:
                s = segments[-1]
                self.debug_info['status'] = 'After End'
                self.debug_info['seg_idx'] = len(segments) - 1
                self.debug_info['lat'] = s.get('lat_end')
                return s['speed'], s.get('hr', 0), s.get('lat_end'), s.get('lon_end')
                
            self.debug_info['status'] = 'Not Found'
            return 0.0, 0, None, None
            
        return 0.0, 0, None, None

    def decrease_offset(self, event=None):
        """å‡å°‘GPXæ—¶é—´åç§»"""
        self.gpx_offset -= 1.0
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        # æ›´æ–°ç¼©ç•¥å›¾
        self.update_track_thumbnail_by_offset()
        # åˆ·æ–°å½“å‰å¸§ä»¥æ›´æ–°æ˜¾ç¤º
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)
            
    def increase_offset(self, event=None):
        """å¢åŠ GPXæ—¶é—´åç§»"""
        self.gpx_offset += 1.0
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        # æ›´æ–°ç¼©ç•¥å›¾
        self.update_track_thumbnail_by_offset()
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)

    def decrease_offset_fine(self, event=None):
        """å‡å°‘GPXæ—¶é—´åç§» (0.1s)"""
        self.gpx_offset -= 0.1
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        self.update_track_thumbnail_by_offset()
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)

    def increase_offset_fine(self, event=None):
        """å¢åŠ GPXæ—¶é—´åç§» (0.1s)"""
        self.gpx_offset += 0.1
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        self.update_track_thumbnail_by_offset()
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)

    def save_project(self):
        """ä¿å­˜é¡¹ç›®"""
        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜é¡¹ç›®",
            defaultextension=".veproj",
            filetypes=[("è§†é¢‘ç¼–è¾‘é¡¹ç›®", "*.veproj"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            # TODO: ä¿å­˜é¡¹ç›®æ–‡ä»¶
            self.update_status(f"é¡¹ç›®å·²ä¿å­˜: {file_path}")
            messagebox.showinfo("ä¿å­˜æˆåŠŸ", f"é¡¹ç›®å·²ä¿å­˜åˆ°:\n{file_path}")
    
    def open_project(self):
        """æ‰“å¼€é¡¹ç›®"""
        file_path = filedialog.askopenfilename(
            title="æ‰“å¼€é¡¹ç›®",
            filetypes=[("è§†é¢‘ç¼–è¾‘é¡¹ç›®", "*.veproj"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            # TODO: åŠ è½½é¡¹ç›®æ–‡ä»¶
            self.update_status(f"é¡¹ç›®å·²æ‰“å¼€: {file_path}")
    
    def export_video(self):
        """å¯¼å‡ºè§†é¢‘"""
        if not self.video_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="å¯¼å‡ºè§†é¢‘",
            defaultextension=".mp4",
            filetypes=[
                ("MP4è§†é¢‘", "*.mp4"),
                ("AVIè§†é¢‘", "*.avi"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if file_path:
            # ç¦ç”¨ç•Œé¢äº¤äº’
            self.root.config(cursor="watch")
            self.update_status(f"æ­£åœ¨å¯¼å‡ºè§†é¢‘: {file_path}...")
            
            # å¯åŠ¨å¯¼å‡ºçº¿ç¨‹
            threading.Thread(target=self._export_video_worker, args=(file_path,), daemon=True).start()

    def _export_video_worker(self, output_path):
        """è§†é¢‘å¯¼å‡ºå·¥ä½œçº¿ç¨‹"""
        try:
            cap = cv2.VideoCapture(self.video_path)
            if not cap.isOpened():
                raise Exception("æ— æ³•æ‰“å¼€æºè§†é¢‘")
            
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å­˜å‚¨æ— éŸ³é¢‘è§†é¢‘
            temp_video_path = output_path + ".temp.mp4"
            
            # æ ¹æ®æ‰©å±•åé€‰æ‹©ç¼–ç å™¨
            ext = os.path.splitext(output_path)[1].lower()
            if ext == '.avi':
                fourcc = cv2.VideoWriter_fourcc(*'MJPG')
            else:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            
            out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
            
            if not out.isOpened():
                raise Exception("æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘æµ")
            
            processed_frames = 0
            last_update_time = time.time()
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # å åŠ GPX
                if self.gpx_data:
                    current_seconds = processed_frames / fps if fps > 0 else 0
                    self._draw_overlay_on_frame(frame, current_seconds)
                
                out.write(frame)
                
                processed_frames += 1
                
                # æ›´æ–°è¿›åº¦ (æ¯0.5ç§’)
                if time.time() - last_update_time > 0.5:
                    progress = (processed_frames / total_frames) * 100
                    self.root.after(0, self.update_status, f"å¯¼å‡ºä¸­: {progress:.1f}%")
                    last_update_time = time.time()
            
            cap.release()
            out.release()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ ffmpeg
            has_ffmpeg = shutil.which('ffmpeg') is not None
            
            # åˆå¹¶éŸ³é¢‘
            if has_ffmpeg: 
                self.root.after(0, self.update_status, "æ­£åœ¨åˆå¹¶éŸ³é¢‘...")
                try:
                    # ffmpeg -i temp.mp4 -i source.mp4 -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 output.mp4
                    cmd = [
                        'ffmpeg', '-y', '-v', 'error',
                        '-i', temp_video_path,
                        '-i', self.video_path,
                        '-c:v', 'copy',
                        '-c:a', 'aac',
                        '-map', '0:v:0',
                        '-map', '1:a:0',
                        output_path
                    ]
                    
                    startupinfo = None
                    if platform.system() == 'Windows':
                        startupinfo = subprocess.STARTUPINFO()
                        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                        
                    subprocess.check_call(cmd, startupinfo=startupinfo)
                    
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_video_path):
                        os.remove(temp_video_path)
                        
                except Exception as e:
                    print(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
                    # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬
                    if os.path.exists(output_path):
                        os.remove(output_path)
                    os.rename(temp_video_path, output_path)
                    self.root.after(0, messagebox.showwarning, "è­¦å‘Š", f"éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå¯¼å‡ºçš„è§†é¢‘å°†æ²¡æœ‰å£°éŸ³ã€‚\né”™è¯¯: {e}")
            else:
                # æ²¡æœ‰ffmpegï¼Œç›´æ¥é‡å‘½å
                if os.path.exists(output_path):
                    os.remove(output_path)
                os.rename(temp_video_path, output_path)
                self.root.after(0, messagebox.showinfo, "æç¤º", "æœªæ£€æµ‹åˆ°FFmpegï¼Œå¯¼å‡ºçš„è§†é¢‘å°†æ²¡æœ‰å£°éŸ³ã€‚")

            self.root.after(0, self.update_status, f"å¯¼å‡ºå®Œæˆ: {output_path}")
            self.root.after(0, messagebox.showinfo, "æˆåŠŸ", "è§†é¢‘å¯¼å‡ºæˆåŠŸï¼")
            
        except Exception as e:
            self.root.after(0, self.update_status, f"å¯¼å‡ºå¤±è´¥: {e}")
            self.root.after(0, messagebox.showerror, "é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
        finally:
            self.root.after(0, self.root.config, {"cursor": ""})
    
    # ============ ç¼–è¾‘åŠŸèƒ½ ============
    
    def undo(self):
        """æ’¤é”€"""
        self.update_status("æ’¤é”€æ“ä½œ")
    
    def redo(self):
        """é‡åš"""
        self.update_status("é‡åšæ“ä½œ")
    
    def cut_clip(self):
        """å‰ªåˆ‡ç‰‡æ®µ"""
        self.update_status("å‰ªåˆ‡ç‰‡æ®µ")
    
    def copy_clip(self):
        """å¤åˆ¶ç‰‡æ®µ"""
        self.update_status("å¤åˆ¶ç‰‡æ®µ")
    
    def paste_clip(self):
        """ç²˜è´´ç‰‡æ®µ"""
        self.update_status("ç²˜è´´ç‰‡æ®µ")
    
    def delete_clip(self):
        """åˆ é™¤ç‰‡æ®µ"""
        selected = self.clip_tree.selection()
        if selected:
            self.clip_tree.delete(selected)
            self.update_status("åˆ é™¤ç‰‡æ®µ")
        else:
            messagebox.showinfo("æç¤º", "è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„ç‰‡æ®µ")
    
    # ============ å‰ªè¾‘åŠŸèƒ½ ============
    
    def split_clip(self):
        """åˆ†å‰²ç‰‡æ®µ"""
        if not self.video_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return
        
        current_time = self.progress_var.get()
        self.update_status(f"åœ¨ {self.format_time(current_time)} å¤„åˆ†å‰²")
        messagebox.showinfo("åˆ†å‰²", "è§†é¢‘åˆ†å‰²åŠŸèƒ½å¾…å®ç°")
    
    def merge_clips(self):
        """åˆå¹¶ç‰‡æ®µ"""
        selected = self.clip_tree.selection()
        if len(selected) < 2:
            messagebox.showinfo("æç¤º", "è¯·è‡³å°‘é€‰æ‹©ä¸¤ä¸ªç‰‡æ®µè¿›è¡Œåˆå¹¶")
            return
        
        self.update_status("åˆå¹¶ç‰‡æ®µ")
        messagebox.showinfo("åˆå¹¶", "ç‰‡æ®µåˆå¹¶åŠŸèƒ½å¾…å®ç°")
    
    def set_in_point(self):
        """è®¾ç½®å…¥ç‚¹"""
        current_time = self.progress_var.get()
        self.update_status(f"è®¾ç½®å…¥ç‚¹: {self.format_time(current_time)}")
    
    def set_out_point(self):
        """è®¾ç½®å‡ºç‚¹"""
        current_time = self.progress_var.get()
        self.update_status(f"è®¾ç½®å‡ºç‚¹: {self.format_time(current_time)}")
    
    def add_transition(self):
        """æ·»åŠ è½¬åœºæ•ˆæœ"""
        messagebox.showinfo("è½¬åœº", "è½¬åœºæ•ˆæœåŠŸèƒ½å¾…å®ç°")
    
    def add_filter(self):
        """æ·»åŠ æ»¤é•œ"""
        messagebox.showinfo("æ»¤é•œ", "æ»¤é•œåŠŸèƒ½å¾…å®ç°")
    
    # ============ æ’­æ”¾æ§åˆ¶ ============
    
    def toggle_play(self):
        """æ’­æ”¾/æš‚åœ"""
        if not self.video_path or self.cap is None:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return
        
        if not HAS_CV2:
            messagebox.showwarning("è­¦å‘Š", "æœªå®‰è£… opencv-pythonï¼Œæ— æ³•æ’­æ”¾è§†é¢‘ï¼")
            return
        
        if not self.playing:
            # å¼€å§‹æ’­æ”¾
            self.playing = True
            self.play_btn['text'] = "â¸ æš‚åœ"
            self.update_status("æ’­æ”¾ä¸­...")
            self.start_audio_playback(self._current_time())
            
            # å¯åŠ¨æ’­æ”¾çº¿ç¨‹
            if self.play_thread is None or not self.play_thread.is_alive():
                self.play_thread = threading.Thread(target=self._play_video_loop, daemon=True)
                self.play_thread.start()
        else:
            # æš‚åœæ’­æ”¾
            self.playing = False
            self.play_btn['text'] = "â–¶ æ’­æ”¾"
            self.update_status("å·²æš‚åœ")
            self.stop_audio_playback()
    
    def _has_ffplay(self):
        return shutil.which('ffplay') is not None
    
    def _current_time(self):
        fps = self.video_info.get('fps', 30.0)
        return self.current_frame_pos / fps if fps > 0 else 0
    
    def start_audio_playback(self, start_time=None):
        if self.is_muted or self.volume <= 0:
            return
        if not self._has_ffplay():
            return
        if start_time is None:
            start_time = self._current_time()
        try:
            vol = max(0, min(100, int(self.volume * 100)))
            spd = self.playback_speed
            if spd < 0.5:
                spd = 0.5
            elif spd > 2.0:
                spd = 2.0
            cmd = [
                'ffplay',
                '-nodisp',
                '-autoexit',
                '-loglevel', 'error',
                '-ss', f'{start_time:.3f}',
                '-i', self.video_path,
                '-volume', str(vol),
                '-af', f'atempo={spd}'
            ]
            self.audio_proc = subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except Exception:
            self.audio_proc = None
    
    def stop_audio_playback(self):
        if self.audio_proc is not None:
            try:
                self.audio_proc.terminate()
            except Exception:
                pass
            self.audio_proc = None
    
    def _play_video_loop(self):
        """è§†é¢‘æ’­æ”¾å¾ªç¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        if self.cap is None:
            return
            
        fps = self.video_info.get('fps', 30.0)
        # ç›®æ ‡å¸§é—´éš”
        target_interval = 1.0 / (fps * self.playback_speed)
        
        last_frame_time = time.time()
        
        # è®°å½•ä¸Šä¸€å¸§çš„æ˜¾ç¤ºæ—¶é—´ï¼Œç”¨äºè®¡ç®—å»¶è¿Ÿ
        last_display_time = time.time()
        
        while self.playing and self.cap is not None:
            loop_start_time = time.time()
            
            # 1. è¯»å–ä¸‹ä¸€å¸§
            ret, frame = self.cap.read()
            
            if not ret:
                # æ’­æ”¾ç»“æŸ
                self.playing = False
                # åœ¨ä¸»çº¿ç¨‹æ›´æ–°UI
                self.root.after(0, lambda: self.play_btn.config(text="â–¶ æ’­æ”¾"))
                self.root.after(0, lambda: self.update_status("æ’­æ”¾å®Œæˆ"))
                self.stop_audio_playback()
                break
            
            self.current_frame_pos = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
            
            # 2. åªæœ‰å½“è·ç¦»ä¸Šæ¬¡æ˜¾ç¤ºè¶…è¿‡ä¸€å®šé—´éš”æ—¶æ‰æ›´æ–°UIï¼ˆé¿å…è¿‡åº¦åˆ·æ–°ï¼‰
            # é™åˆ¶æœ€é«˜åˆ·æ–°ç‡ä¸º 30fpsï¼Œæˆ–è€…åŸè§†é¢‘å¸§ç‡ï¼ˆå–è¾ƒå°å€¼ï¼‰
            current_time = time.time()
            if current_time - last_display_time >= 0.033: # çº¦30fps
                # å¤åˆ¶å¸§æ•°æ®ä¼ é€’ç»™UIçº¿ç¨‹ï¼Œé¿å…å†²çª
                display_frame = frame.copy()
                self.root.after(0, self._display_frame, display_frame)
                
                # æ›´æ–°è¿›åº¦æ¡ (æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹åˆ·æ–°)
                if current_time - last_display_time > 0.5:
                    current_video_time = self.current_frame_pos / fps if fps > 0 else 0
                    self.root.after(0, self.progress_var.set, current_video_time)
                    self.root.after(0, self._update_time_display, current_video_time)
                
                last_display_time = current_time
            
            # 3. å¸§ç‡æ§åˆ¶
            process_time = time.time() - loop_start_time
            sleep_time = target_interval - process_time
            
            if sleep_time > 0:
                time.sleep(sleep_time)
            else:
                # å¦‚æœå¤„ç†å¤ªæ…¢ï¼Œä¸éœ€è¦sleepï¼Œç”šè‡³å¯èƒ½éœ€è¦è·³å¸§ï¼ˆè¿™é‡Œæš‚ä¸å®ç°è·³å¸§ï¼‰
                pass
    
    def _display_frame(self, frame):
        """æ˜¾ç¤ºè§†é¢‘å¸§"""
        if frame is None:
            return
            
        # å åŠ GPXä¿¡æ¯
        if self.gpx_data:
            fps = self.video_info.get('fps', 30.0)
            current_seconds = self.current_frame_pos / fps if fps > 0 else 0
            self._draw_overlay_on_frame(frame, current_seconds)
            
        # è°ƒæ•´å¤§å°ä»¥é€‚åº”ç”»å¸ƒ
        canvas_width = self.video_canvas.winfo_width()
        canvas_height = self.video_canvas.winfo_height()
        
        if canvas_width <= 1 or canvas_height <= 1:
            canvas_width = 640
            canvas_height = 360
            
        # ä¿æŒå®½é«˜æ¯”
        img_h, img_w = frame.shape[:2]
        
        # ä¼˜åŒ–ï¼šå¦‚æœå›¾åƒå°ºå¯¸ä¸ç”»å¸ƒå·®å¼‚ä¸å¤§ï¼Œä¸ç¼©æ”¾
        if abs(img_w - canvas_width) > 10 or abs(img_h - canvas_height) > 10:
            ratio = min(canvas_width / img_w, canvas_height / img_h)
            new_w = int(img_w * ratio)
            new_h = int(img_h * ratio)
            resized_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        else:
            resized_frame = frame
        
        # è½¬æ¢ä¸º RGB
        rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
        
        # è½¬æ¢ä¸º ImageTk
        img = Image.fromarray(rgb_frame)
        photo = ImageTk.PhotoImage(image=img)
        
        # æ›´æ–°ç”»å¸ƒ
        self.video_canvas.delete("all")
        # å±…ä¸­æ˜¾ç¤º
        x_center = canvas_width // 2
        y_center = canvas_height // 2
        self.video_canvas.create_image(x_center, y_center, image=photo, anchor=tk.CENTER)
        self.video_canvas.image = photo # ä¿æŒå¼•ç”¨é˜²æ­¢è¢«åƒåœ¾å›æ”¶
    
    def _draw_overlay_on_frame(self, frame, current_seconds):
        """åœ¨å¸§ä¸Šç»˜åˆ¶GPXå åŠ å±‚"""
        if not self.gpx_data:
            return

        speed, hr, lat, lon = self.get_data_at_time(current_seconds)
        h, w = frame.shape[:2]
        
        # 1. ç»˜åˆ¶è½¨è¿¹ç¼©ç•¥å›¾ (å³ä¸Šè§’)
        if self.track_thumbnail is not None and self.track_transform is not None:
            thumb_h, thumb_w = self.track_thumbnail.shape[:2]
            
            # ç¡®ä¿ç¼©ç•¥å›¾ä¸æ¯”è§†é¢‘å¤§ä¸”ä½ç½®åˆç†
            if thumb_h < h and thumb_w < w:
                # ä½ç½®ï¼šå³ä¸Šè§’ï¼Œè¾¹è·20
                x_offset = w - thumb_w - 20
                y_offset = 20
                
                # æå–ROI
                roi = frame[y_offset:y_offset+thumb_h, x_offset:x_offset+thumb_w]
                
                # Alphaæ··åˆ
                thumb_bgr = self.track_thumbnail[:, :, :3]
                thumb_alpha = self.track_thumbnail[:, :, 3] / 255.0
                thumb_alpha_3ch = cv2.merge([thumb_alpha, thumb_alpha, thumb_alpha])
                
                blended = (thumb_bgr * thumb_alpha_3ch + roi * (1.0 - thumb_alpha_3ch)).astype(np.uint8)
                frame[y_offset:y_offset+thumb_h, x_offset:x_offset+thumb_w] = blended
                
                # ç»˜åˆ¶å½“å‰ä½ç½® (é—ªçƒè“ç‚¹)
                if lat is not None and lon is not None:
                    # è§£åŒ…å˜æ¢å‚æ•° (æ”¯æŒæ—§ç‰ˆå’Œæ–°ç‰ˆ)
                    if len(self.track_transform) == 5:
                        min_lat, min_lon, scale, t_h, padding = self.track_transform
                        lon_correction = 1.0
                    else:
                        min_lat, min_lon, scale, t_h, padding, lon_correction = self.track_transform
                    
                    # è®¡ç®—åæ ‡
                    pt_x = int(padding + (lon - min_lon) * lon_correction * scale)
                    pt_y = int(t_h - padding - (lat - min_lat) * scale)
                    
                    # è½¬æ¢ä¸ºå±å¹•åæ ‡
                    screen_x = x_offset + pt_x
                    screen_y = y_offset + pt_y
                    
                    # é—ªçƒæ•ˆæœ (æ¯ç§’é—ªçƒçº¦2æ¬¡)
                    if int(time.time() * 4) % 2 == 0:
                        cv2.circle(frame, (screen_x, screen_y), 6, (255, 0, 0), -1) # è“è‰²å®å¿ƒåœ†
                        cv2.circle(frame, (screen_x, screen_y), 8, (255, 255, 255), 1) # ç™½è‰²æè¾¹

        # 2. ç»˜åˆ¶é€Ÿåº¦è¡¨ç›˜
        gauge_radius = 70
        gauge_center = (w - gauge_radius - 20, h - gauge_radius - 20)
        self.draw_speed_gauge(frame, speed, max_speed=60, center=gauge_center, radius=gauge_radius)
        
        # 3. æ·»åŠ æ–‡å­— (å¿ƒç‡) - å¦‚æœæœ‰å¿ƒç‡æ•°æ®
        if hr > 0:
            text_hr = f"{hr} bpm"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = max(0.5, w / 1000.0)
            thickness = max(1, int(font_scale * 2))
            
            text_size_hr = cv2.getTextSize(text_hr, font, font_scale, thickness)[0]
            # æ˜¾ç¤ºåœ¨è¡¨ç›˜ä¸Šæ–¹ä¸­å¿ƒ
            text_x_hr = gauge_center[0] - text_size_hr[0] // 2
            text_y_hr = gauge_center[1] - gauge_radius - 15
            
            cv2.putText(frame, text_hr, (text_x_hr, text_y_hr), font, font_scale, (0, 0, 0), thickness + 2)
            cv2.putText(frame, text_hr, (text_x_hr, text_y_hr), font, font_scale, (0, 0, 255), thickness)
            
            # æ·»åŠ å¿ƒå½¢å›¾æ ‡ (ç®€å•çš„åœ†)
            cv2.circle(frame, (text_x_hr - 15, text_y_hr - 5), 6, (0, 0, 255), -1)

        # 4. æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ (å§‹ç»ˆæ˜¾ç¤ºåœ¨å·¦ä¸Šè§’)
        debug_y = 40
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = max(0.5, w / 1000.0)
        thickness = max(1, int(font_scale * 2))
        
        # å¦‚æœæœ‰åç§»ï¼Œä¼˜å…ˆæ˜¾ç¤º
        if abs(self.gpx_offset) > 0.1:
            text_offset = f"Offset: {self.gpx_offset:+.1f}s"
            cv2.putText(frame, text_offset, (20, debug_y), font, font_scale * 0.8, (0, 0, 0), thickness + 2)
            cv2.putText(frame, text_offset, (20, debug_y), font, font_scale * 0.8, (255, 255, 0), thickness)
            debug_y += 30
        
        if self.debug_info:
            for k, v in self.debug_info.items():
                # è·³è¿‡å·²ç»æ˜¾ç¤ºçš„offset
                if k == 'offset': continue
                
                if isinstance(v, float):
                    text = f"{k}: {v:.3f}"
                else:
                    text = f"{k}: {v}"
                
                # é»‘è‰²æè¾¹
                cv2.putText(frame, text, (20, debug_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 4)
                # çº¢è‰²æ–‡å­—
                cv2.putText(frame, text, (20, debug_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                debug_y += 25

    def _update_time_display(self, current_time):
        """æ›´æ–°æ—¶é—´æ˜¾ç¤ºï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­è°ƒç”¨ï¼‰"""
        duration = self.video_info.get('duration', 0)
        self.time_label.config(text=f"{self.format_time(current_time)} / {self.format_time(duration)}")
        
        # æ›´æ–°æ’­æ”¾å¤´ä½ç½®
        self.draw_playhead(current_time)
    
    def seek_to_frame(self, frame_number):
        """è·³è½¬åˆ°æŒ‡å®šå¸§"""
        if self.cap is None:
            return
        
        try:
            # ç¡®ä¿å¸§æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
            frame_number = max(0, min(frame_number, max(0, self.total_frames - 1)))
            
            # å°è¯•è®¾ç½®å¸§ä½ç½®
            success = self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            
            if not success:
                # å¦‚æœç›´æ¥è®¾ç½®å¤±è´¥ï¼Œå°è¯•ä»å¼€å¤´è¯»å–åˆ°ç›®æ ‡ä½ç½®
                self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                for _ in range(frame_number):
                    ret, _ = self.cap.read()
                    if not ret:
                        break
            
            self.current_frame_pos = frame_number
            
            # è¯»å–å¹¶æ˜¾ç¤ºè¯¥å¸§
            ret, frame = self.cap.read()
            if ret and frame is not None:
                self._display_frame(frame)
                
                # æ›´æ–°è¿›åº¦æ¡
                fps = self.video_info.get('fps', 30.0)
                current_time = frame_number / fps if fps > 0 else 0
                self.progress_var.set(current_time)
                self._update_time_display(current_time)
            else:
                # å¦‚æœè¯»å–å¤±è´¥ï¼Œå°è¯•æ˜¾ç¤ºä¸€ä¸ªé»‘è‰²å¸§
                width = self.video_info.get('width', 640)
                height = self.video_info.get('height', 480)
                black_frame = np.zeros((height, width, 3), dtype=np.uint8)
                self._display_frame(black_frame)
                
        except Exception as e:
            print(f"è·³è½¬å¸§æ—¶å‡ºé”™: {e}")
            self.update_status(f"è·³è½¬å¸§å¤±è´¥: {str(e)}")
            # å°è¯•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            width = self.video_info.get('width', 640)
            height = self.video_info.get('height', 480)
            error_frame = np.zeros((height, width, 3), dtype=np.uint8)
            # è¿™é‡Œå¯ä»¥æ·»åŠ é”™è¯¯æ–‡æœ¬æ˜¾ç¤º
            self._display_frame(error_frame)
    
    def stop_play(self):
        """åœæ­¢æ’­æ”¾"""
        self.playing = False
        self.play_btn['text'] = "â–¶ æ’­æ”¾"
        if self.cap is not None:
            self.seek_to_frame(0)
        self.update_status("å·²åœæ­¢")
        self.stop_audio_playback()
    
    def prev_frame(self):
        """ä¸Šä¸€å¸§"""
        if self.cap is None:
            return
        
        fps = self.video_info.get('fps', 30.0)
        frame_step = max(1, int(fps * 0.033))  # å¤§çº¦ä¸€å¸§
        new_frame = max(0, self.current_frame_pos - frame_step)
        self.seek_to_frame(new_frame)
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def next_frame(self):
        """ä¸‹ä¸€å¸§"""
        if self.cap is None:
            return
        
        fps = self.video_info.get('fps', 30.0)
        frame_step = max(1, int(fps * 0.033))  # å¤§çº¦ä¸€å¸§
        new_frame = min(self.total_frames - 1, self.current_frame_pos + frame_step)
        self.seek_to_frame(new_frame)
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def jump_to_start(self):
        """è·³è½¬åˆ°å¼€å§‹"""
        if self.cap is not None:
            self.seek_to_frame(0)
        else:
            self.progress_var.set(0)
        self.update_status("è·³è½¬åˆ°å¼€å§‹")
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def jump_to_end(self):
        """è·³è½¬åˆ°ç»“æŸ"""
        if self.cap is not None and self.total_frames > 0:
            self.seek_to_frame(self.total_frames - 1)
        else:
            duration = self.video_info.get('duration', 100)
            self.progress_var.set(duration)
        self.update_status("è·³è½¬åˆ°ç»“æŸ")
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def rewind_5s(self):
        """åé€€5ç§’"""
        if self.cap is not None and self.total_frames > 0:
            current_time = self.current_frame_pos / self.video_info.get('fps', 30.0)
            new_time = max(0, current_time - 5)
            new_frame = int(new_time * self.video_info.get('fps', 30.0))
            self.seek_to_frame(new_frame)
            self.update_status("åé€€5ç§’")
            if self.playing:
                self.stop_audio_playback()
                self.start_audio_playback(self._current_time())
    
    def forward_5s(self):
        """å‰è¿›5ç§’"""
        if self.cap is not None and self.total_frames > 0:
            current_time = self.current_frame_pos / self.video_info.get('fps', 30.0)
            duration = self.video_info.get('duration', 0)
            new_time = min(duration, current_time + 5)
            new_frame = int(new_time * self.video_info.get('fps', 30.0))
            self.seek_to_frame(new_frame)
            self.update_status("å‰è¿›5ç§’")
            if self.playing:
                self.stop_audio_playback()
                self.start_audio_playback(self._current_time())
    
    def toggle_mute(self):
        """åˆ‡æ¢é™éŸ³"""
        self.is_muted = not self.is_muted
        if self.is_muted:
            self.mute_btn.config(text="ğŸ”‡")
            self.volume_scale.set(0)
        else:
            self.mute_btn.config(text="ğŸ”Š")
            self.volume_scale.set(100)
        self.update_status("é™éŸ³" if self.is_muted else "å–æ¶ˆé™éŸ³")
        if self.playing:
            if self.is_muted:
                self.stop_audio_playback()
            else:
                self.stop_audio_playback()
                self.start_audio_playback(self._current_time())
    
    def on_volume_change(self, value):
        """éŸ³é‡æ”¹å˜"""
        self.volume = float(value) / 100.0
        if self.volume == 0:
            self.mute_btn.config(text="ğŸ”‡")
            self.is_muted = True
        else:
            self.mute_btn.config(text="ğŸ”Š")
            self.is_muted = False
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def on_speed_change(self, event):
        """æ’­æ”¾é€Ÿåº¦æ”¹å˜"""
        speed_str = self.speed_var.get()
        self.playback_speed = float(speed_str.replace('x', ''))
        self.update_status(f"æ’­æ”¾é€Ÿåº¦: {speed_str}")
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def toggle_loop(self):
        """åˆ‡æ¢å¾ªç¯æ’­æ”¾"""
        self.loop_playback = not self.loop_playback
        status = "å¼€å¯" if self.loop_playback else "å…³é—­"
        self.update_status(f"å¾ªç¯æ’­æ”¾å·²{status}")
    
    def update_clip_list(self):
        """æ›´æ–°å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨"""
        # æ¸…ç©ºç°æœ‰åˆ—è¡¨
        for item in self.clip_tree.get_children():
            self.clip_tree.delete(item)
            
        # æ·»åŠ ç‰‡æ®µ
        fps = self.video_info.get('fps', 30.0)
        for clip in self.clips:
            start_time = clip['start_frame'] / fps
            end_time = clip['end_frame'] / fps
            duration = end_time - start_time
            
            self.clip_tree.insert('', 'end', values=(
                clip['name'],
                self.format_time(start_time),
                self.format_time(end_time),
                f"{duration:.2f}s"
            ))
            
        # æ›´æ–°æ—¶é—´è½´ä¸Šçš„ç‰‡æ®µæ˜¾ç¤º
        self.draw_timeline_tracks()

    def split_clip(self):
        """åˆ†å‰²å½“å‰ç‰‡æ®µ"""
        if not self.video_info or not self.clips:
            return
            
        current_frame = self.current_frame_pos
        
        # æŸ¥æ‰¾å½“å‰æ—¶é—´ç‚¹æ‰€åœ¨çš„ç‰‡æ®µ
        target_clip = None
        target_index = -1
        
        for i, clip in enumerate(self.clips):
            if clip['start_frame'] < current_frame < clip['end_frame']:
                target_clip = clip
                target_index = i
                break
        
        if target_clip:
            # åˆ›å»ºæ–°ç‰‡æ®µ
            new_clip = target_clip.copy()
            new_clip['id'] = f"clip_{len(self.clips)}"
            new_clip['name'] = f"ç‰‡æ®µ_{len(self.clips) + 1}"
            new_clip['start_frame'] = current_frame
            new_clip['end_frame'] = target_clip['end_frame']
            
            # ä¿®æ”¹åŸç‰‡æ®µ
            target_clip['end_frame'] = current_frame
            
            # æ’å…¥æ–°ç‰‡æ®µ
            self.clips.insert(target_index + 1, new_clip)
            
            # æ›´æ–°åˆ—è¡¨
            self.update_clip_list()
            self.update_status(f"å·²åœ¨ {self.format_time(current_frame / self.video_info.get('fps', 30.0))} å¤„åˆ†å‰²ç‰‡æ®µ")
        else:
            self.update_status("å½“å‰ä½ç½®æ— æ³•åˆ†å‰²ï¼ˆä¸åœ¨ä»»ä½•ç‰‡æ®µä¸­é—´ï¼‰")
    
    # ============ UIæ›´æ–°æ–¹æ³• ============
    
    def update_video_info(self):
        """æ›´æ–°è§†é¢‘ä¿¡æ¯æ˜¾ç¤º"""
        if self.video_info:
            info_text = f"""æ–‡ä»¶: {self.video_info.get('name', 'N/A')}
åˆ†è¾¨ç‡: {self.video_info.get('width', 0)}x{self.video_info.get('height', 0)}
å¸§ç‡: {self.video_info.get('fps', 0):.2f} fps
æ—¶é•¿: {self.format_time(self.video_info.get('duration', 0))}
ç¼–ç : {self.video_info.get('codec', 'N/A')}"""
            
            self.info_text.config(state=tk.NORMAL)
            self.info_text.delete(1.0, tk.END)
            self.info_text.insert(1.0, info_text)
            self.info_text.config(state=tk.DISABLED)
            
            # æ›´æ–°çŠ¶æ€æ 
            self.resolution_label.config(text=f"{self.video_info.get('width', 0)}x{self.video_info.get('height', 0)}")
            self.fps_label.config(text=f"{self.video_info.get('fps', 0):.1f} fps")
            
            # æ›´æ–°è¿›åº¦æ¡æœ€å¤§å€¼
            self.progress_scale.config(to=self.video_info.get('duration', 100))
    
    def update_preview_label(self, text):
        """æ›´æ–°é¢„è§ˆæ ‡ç­¾"""
        if self.preview_label:
            display_text = "" if text is None else str(text)
            if display_text.strip():
                self.preview_label.config(text=display_text)
                self.preview_label.place(relx=0.5, rely=0.5, anchor=tk.CENTER)
            else:
                self.preview_label.config(text="")
                self.preview_label.place_forget()
    
    def update_status(self, message):
        """æ›´æ–°çŠ¶æ€æ """
        self.status_label.config(text=message)
    
    def format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    
    # ============ æ—¶é—´è½´ç›¸å…³ ============
    
    def init_timeline(self):
        """åˆå§‹åŒ–æ—¶é—´è½´"""
        if not self.video_info:
            return
        
        duration = self.video_info.get('duration', 100)
        self.draw_timeline_ruler(duration)
        self.draw_timeline_tracks()
    
    def draw_timeline_ruler(self, duration):
        """ç»˜åˆ¶æ—¶é—´æ ‡å°º"""
        self.ruler_canvas.delete("all")
        
        # è®¡ç®—æ€»å®½åº¦
        total_width = duration * self.timeline_scale
        if total_width < 1:
            total_width = 1
            
        # æ›´æ–°æ»šåŠ¨åŒºåŸŸ
        self.ruler_canvas.config(scrollregion=(0, 0, total_width, 25))
        self.timeline_canvas.config(scrollregion=(0, 0, total_width, 150))
        
        # ç»˜åˆ¶åˆ»åº¦
        # æ ¹æ®ç¼©æ”¾æ¯”ä¾‹å†³å®šåˆ»åº¦é—´éš”
        if self.timeline_scale < 1: # ç¼©å°å¾ˆå¤šï¼Œæ¯10ç§’æˆ–æ›´å¤šä¸€ä¸ªåˆ»åº¦
            step = 60
        elif self.timeline_scale < 5: # æ¯10ç§’
            step = 10
        elif self.timeline_scale < 20: # æ¯5ç§’
            step = 5
        else: # æ¯1ç§’
            step = 1
            
        for second in range(0, int(duration) + 1, step):
            x = second * self.timeline_scale
            self.ruler_canvas.create_line(x, 0, x, 25, fill="#666666", width=1)
            self.ruler_canvas.create_text(x + 2, 12, text=self.format_time(second),
                                         anchor=tk.W, font=("Arial", 8))
    
    def draw_timeline_tracks(self):
        """ç»˜åˆ¶æ—¶é—´è½´è½¨é“"""
        self.timeline_canvas.delete("all")
        
        if not self.video_info:
            return
            
        # ç»˜åˆ¶å‰ªè¾‘ç‰‡æ®µ
        fps = self.video_info.get('fps', 30.0)
        track_height = 40
        track_y = 10
        
        for i, clip in enumerate(self.clips):
            start_time = clip['start_frame'] / fps
            end_time = clip['end_frame'] / fps
            
            x1 = start_time * self.timeline_scale
            x2 = end_time * self.timeline_scale
            
            # ç»˜åˆ¶ç‰‡æ®µçŸ©å½¢
            # ä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ç›¸é‚»ç‰‡æ®µ
            color = "#4a90e2" if i % 2 == 0 else "#357abd"
            
            self.timeline_canvas.create_rectangle(x1, track_y, x2, track_y + track_height,
                                                 fill=color, outline="white", tags=("clip", clip['id']))
            
            # ç»˜åˆ¶ç‰‡æ®µåç§°
            if x2 - x1 > 20: # å¦‚æœå¤Ÿå®½æ‰æ˜¾ç¤ºæ–‡å­—
                self.timeline_canvas.create_text(x1 + 5, track_y + track_height/2,
                                                text=clip['name'], anchor=tk.W, fill="white",
                                                font=("Arial", 9))
    
    def draw_playhead(self, current_time):
        """ç»˜åˆ¶æ’­æ”¾å¤´"""
        self.timeline_canvas.delete("playhead")
        self.ruler_canvas.delete("playhead")
        
        if self.timeline_scale <= 0:
            return
            
        x = current_time * self.timeline_scale
        
        # åœ¨æ ‡å°ºä¸Šç»˜åˆ¶
        self.ruler_canvas.create_line(x, 0, x, 25, fill="red", width=2, tags="playhead")
        # ç»˜åˆ¶å€’ä¸‰è§’æŒ‡ç¤ºå™¨
        self.ruler_canvas.create_polygon(x-4, 0, x+4, 0, x, 8, fill="red", tags="playhead")
        
        # åœ¨è½¨é“ä¸Šç»˜åˆ¶
        height = 150 # ä¼°è®¡é«˜åº¦
        if self.timeline_canvas.winfo_height() > 1:
            height = self.timeline_canvas.winfo_height()
            
        self.timeline_canvas.create_line(x, 0, x, height, fill="red", width=1, tags="playhead")
    
    def on_timeline_click(self, event):
        """æ—¶é—´è½´ç‚¹å‡»/æ‹–åŠ¨äº‹ä»¶"""
        if not self.video_info:
            return
            
        canvas = event.widget
        # è·å–ç”»å¸ƒåæ ‡ï¼ˆè€ƒè™‘æ»šåŠ¨ï¼‰
        x = canvas.canvasx(event.x)
        
        if self.timeline_scale > 0:
            time = x / self.timeline_scale
            duration = self.video_info.get('duration', 0)
            
            # é™åˆ¶æ—¶é—´èŒƒå›´
            time = max(0, min(time, duration))
            
            # ç«‹å³æ›´æ–°æ’­æ”¾å¤´ä»¥è·å¾—æ›´å¥½å“åº”
            self.draw_playhead(time)
            
            # è·³è½¬è§†é¢‘
            fps = self.video_info.get('fps', 30.0)
            frame = int(time * fps)
            self.seek_to_frame(frame)

    def on_progress_press(self, event):
        """è¿›åº¦æ¡æŒ‰ä¸‹äº‹ä»¶"""
        self.is_dragging_progress = True
        if self.playing:
            self.was_playing_before_drag = True
            # æš‚åœæ’­æ”¾ä»¥é¿å…å†²çª
            self.playing = False
            self.play_btn['text'] = "â–¶ æ’­æ”¾"
            self.update_status("æš‚åœ(æ‹–åŠ¨)")
        else:
            self.was_playing_before_drag = False

    def on_progress_release(self, event):
        """è¿›åº¦æ¡é‡Šæ”¾äº‹ä»¶"""
        self.is_dragging_progress = False
        if self.was_playing_before_drag:
            # æ¢å¤æ’­æ”¾
            self.toggle_play()

    def on_progress_change(self, value):
        """è¿›åº¦æ¡æ”¹å˜äº‹ä»¶"""
        if self.cap is None:
            return
        
        current_time = float(value)
        fps = self.video_info.get('fps', 30.0)
        frame_number = int(current_time * fps)
        
        # åªæœ‰åœ¨ä¸æ’­æ”¾æ—¶æ‰å…è®¸æ‰‹åŠ¨è·³è½¬
        if not self.playing:
            self.seek_to_frame(frame_number)
        
        duration = self.video_info.get('duration', 0)
        self.time_label.config(text=f"{self.format_time(current_time)} / {self.format_time(duration)}")
    
    def on_clip_select(self, event):
        """ç‰‡æ®µé€‰æ‹©äº‹ä»¶ - åŒå‡»è·³è½¬"""
        selection = self.clip_tree.selection()
        if selection:
            # è·å–é€‰ä¸­é¡¹çš„ç´¢å¼•
            index = self.clip_tree.index(selection[0])
            if 0 <= index < len(self.clips):
                clip = self.clips[index]
                # è·³è½¬åˆ°ç‰‡æ®µå¼€å§‹ä½ç½®
                self.seek_to_frame(clip['start_frame'])
                self.update_status(f"è·³è½¬åˆ°ç‰‡æ®µ: {clip['name']}")
    
    def on_zoom_change(self, event):
        """ç¼©æ”¾æ”¹å˜äº‹ä»¶"""
        zoom = self.zoom_var.get()
        self.update_status(f"é¢„è§ˆç¼©æ”¾: {zoom}")
    
    def timeline_zoom_in(self):
        """æ—¶é—´è½´æ”¾å¤§"""
        self.timeline_scale *= 1.5
        self.update_timeline()
    
    def timeline_zoom_out(self):
        """æ—¶é—´è½´ç¼©å°"""
        self.timeline_scale /= 1.5
        self.update_timeline()
    
    def timeline_fit(self):
        """æ—¶é—´è½´é€‚åº”çª—å£"""
        if self.video_info:
            duration = self.video_info.get('duration', 100)
            width = self.timeline_canvas.winfo_width()
            if width > 0:
                self.timeline_scale = width / duration
                self.update_timeline()
    
    def update_timeline(self):
        """æ›´æ–°æ—¶é—´è½´æ˜¾ç¤º"""
        self.init_timeline()
    
    def generate_thumbnail(self):
        """ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾"""
        if not HAS_CV2 or self.cap is None:
            return
        
        try:
            # è·å–è§†é¢‘ä¸­é—´ä½ç½®çš„å¸§ä½œä¸ºç¼©ç•¥å›¾
            middle_frame = max(0, self.total_frames // 2)
            
            # ä¿å­˜å½“å‰ä½ç½®
            original_pos = self.current_frame_pos
            
            # å°è¯•è·³è½¬åˆ°ä¸­é—´å¸§
            success = self.cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame)
            if not success:
                # å¦‚æœè·³è½¬å¤±è´¥ï¼Œå°è¯•ä»å¼€å¤´è¯»å–
                self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                # è·³è¿‡ä¸€äº›å¸§åˆ°è¾¾ä¸­é—´ä½ç½®
                for _ in range(middle_frame):
                    ret, _ = self.cap.read()
                    if not ret:
                        break
            
            ret, frame = self.cap.read()
            
            if ret and frame is not None:
                # è°ƒæ•´å¸§å¤§å°ä»¥é€‚åº”ç¼©ç•¥å›¾æ˜¾ç¤ºåŒºåŸŸ
                canvas_width = self.thumbnail_canvas.winfo_width()
                canvas_height = self.thumbnail_canvas.winfo_height()
                
                if canvas_width > 1 and canvas_height > 1:  # ç¡®ä¿ç”»å¸ƒå·²ç»æ˜¾ç¤º
                    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒå®½é«˜æ¯”
                    frame_height, frame_width = frame.shape[:2]
                    scale = min(canvas_width / frame_width, canvas_height / frame_height)
                    
                    new_width = int(frame_width * scale)
                    new_height = int(frame_height * scale)
                    
                    # è°ƒæ•´å¸§å¤§å°
                    resized_frame = cv2.resize(frame, (new_width, new_height))
                    
                    # è½¬æ¢é¢œè‰²æ ¼å¼
                    rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
                    
                    # åˆ›å»ºPILå›¾åƒ
                    if HAS_PIL:
                        pil_image = Image.fromarray(rgb_frame)
                        self.thumbnail_image = ImageTk.PhotoImage(pil_image)
                        
                        # æ¸…ç©ºç”»å¸ƒå¹¶æ˜¾ç¤ºå›¾åƒ
                        self.thumbnail_canvas.delete("all")
                        x = (canvas_width - new_width) // 2
                        y = (canvas_height - new_height) // 2
                        self.thumbnail_canvas.create_image(x, y, anchor=tk.NW, image=self.thumbnail_image)
                    
        except Exception as e:
            print(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}")
        finally:
            # æ¢å¤åŸå§‹å¸§ä½ç½®
            if self.cap is not None:
                try:
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.current_frame_pos)
                except:
                    # å¦‚æœæ¢å¤å¤±è´¥ï¼Œè‡³å°‘å°è¯•å›åˆ°å¼€å¤´
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    
    # ============ å¸®åŠ©åŠŸèƒ½ ============
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©"""
        help_window = tk.Toplevel(self.root)
        help_window.title("ä½¿ç”¨è¯´æ˜")
        help_window.geometry("700x500")
        
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(help_window)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        notebook = ttk.Notebook(main_frame)
        notebook.pack(fill=tk.BOTH, expand=True)
        
        # åŸºæœ¬æ“ä½œæ ‡ç­¾é¡µ
        basic_frame = ttk.Frame(notebook)
        notebook.add(basic_frame, text="åŸºæœ¬æ“ä½œ")
        
        basic_text = tk.Text(basic_frame, wrap=tk.WORD, font=default_font, padx=10, pady=10)
        basic_text.pack(fill=tk.BOTH, expand=True)
        
        basic_content = """è§†é¢‘ç¼–è¾‘å™¨åŸºæœ¬æ“ä½œè¯´æ˜

1. æ–‡ä»¶æ“ä½œ:
   â€¢ æ–‡ä»¶ -> æ‰“å¼€è§†é¢‘: åŠ è½½è§†é¢‘æ–‡ä»¶ (Ctrl+O)
   â€¢ æ–‡ä»¶ -> å¯¼å…¥è§†é¢‘: æ·»åŠ æ›´å¤šè§†é¢‘åˆ°é¡¹ç›®
   â€¢ æ–‡ä»¶ -> ä¿å­˜é¡¹ç›®: ä¿å­˜å½“å‰ç¼–è¾‘è¿›åº¦ (Ctrl+S)
   â€¢ æ–‡ä»¶ -> å¯¼å‡ºè§†é¢‘: å¯¼å‡ºæœ€ç»ˆè§†é¢‘ (Ctrl+E)

2. æ’­æ”¾æ§åˆ¶:
   â€¢ æ’­æ”¾/æš‚åœ: ç©ºæ ¼é”®æˆ–æ’­æ”¾æŒ‰é’®
   â€¢ åœæ­¢: Ké”®æˆ–åœæ­¢æŒ‰é’®
   â€¢ ä¸Šä¸€å¸§: â† é”®
   â€¢ ä¸‹ä¸€å¸§: â†’ é”®
   â€¢ åé€€5ç§’: Shift+â† æˆ– âª æŒ‰é’®
   â€¢ å‰è¿›5ç§’: Shift+â†’ æˆ– â© æŒ‰é’®
   â€¢ è·³è½¬åˆ°å¼€å§‹: Home é”®æˆ– â® æŒ‰é’®
   â€¢ è·³è½¬åˆ°ç»“æŸ: End é”®æˆ– â­ æŒ‰é’®

3. éŸ³é‡æ§åˆ¶:
   â€¢ é™éŸ³åˆ‡æ¢: ç‚¹å‡»éŸ³é‡å›¾æ ‡
   â€¢ éŸ³é‡è°ƒèŠ‚: æ‹–åŠ¨éŸ³é‡æ»‘å—

4. æ’­æ”¾é€Ÿåº¦:
   â€¢ é€Ÿåº¦è°ƒèŠ‚: é€‰æ‹©æ’­æ”¾é€Ÿåº¦ (0.25x - 2.0x)
   â€¢ å¾ªç¯æ’­æ”¾: åœ¨æ’­æ”¾èœå•ä¸­å¼€å¯/å…³é—­"""
        
        basic_text.insert(1.0, basic_content)
        basic_text.config(state=tk.DISABLED)
        
        # å¿«æ·é”®æ ‡ç­¾é¡µ
        shortcut_frame = ttk.Frame(notebook)
        notebook.add(shortcut_frame, text="å¿«æ·é”®")
        
        shortcut_text = tk.Text(shortcut_frame, wrap=tk.WORD, font=default_font, padx=10, pady=10)
        shortcut_text.pack(fill=tk.BOTH, expand=True)
        
        shortcut_content = """è§†é¢‘ç¼–è¾‘å™¨å¿«æ·é”®å¤§å…¨

æ–‡ä»¶æ“ä½œ:
â€¢ Ctrl+O: æ‰“å¼€è§†é¢‘æ–‡ä»¶
â€¢ Ctrl+S: ä¿å­˜é¡¹ç›®
â€¢ Ctrl+Shift+O: æ‰“å¼€é¡¹ç›®
â€¢ Ctrl+E: å¯¼å‡ºè§†é¢‘
â€¢ Ctrl+Q: é€€å‡ºç¨‹åº

æ’­æ”¾æ§åˆ¶:
â€¢ ç©ºæ ¼é”®: æ’­æ”¾/æš‚åœ
â€¢ K: åœæ­¢æ’­æ”¾
â€¢ â†: ä¸Šä¸€å¸§
â€¢ â†’: ä¸‹ä¸€å¸§
â€¢ Shift+â†: åé€€5ç§’
â€¢ Shift+â†’: å‰è¿›5ç§’
â€¢ Home: è·³è½¬åˆ°å¼€å§‹
â€¢ End: è·³è½¬åˆ°ç»“æŸ

å‰ªè¾‘æ“ä½œ:
â€¢ S: åˆ†å‰²ç‰‡æ®µ
â€¢ M: åˆå¹¶ç‰‡æ®µ
â€¢ Del: åˆ é™¤é€‰ä¸­ç‰‡æ®µ
â€¢ I: è®¾ç½®å…¥ç‚¹
â€¢ O: è®¾ç½®å‡ºç‚¹

ç¼–è¾‘æ“ä½œ:
â€¢ Ctrl+Z: æ’¤é”€ (å¾…å®ç°)
â€¢ Ctrl+Y: é‡åš (å¾…å®ç°)
â€¢ Ctrl+X: å‰ªåˆ‡
â€¢ Ctrl+C: å¤åˆ¶
â€¢ Ctrl+V: ç²˜è´´"""
        
        shortcut_text.insert(1.0, shortcut_content)
        shortcut_text.config(state=tk.DISABLED)
        
        # å‰ªè¾‘åŠŸèƒ½æ ‡ç­¾é¡µ
        clip_frame = ttk.Frame(notebook)
        notebook.add(clip_frame, text="å‰ªè¾‘åŠŸèƒ½")
        
        clip_text = tk.Text(clip_frame, wrap=tk.WORD, font=default_font, padx=10, pady=10)
        clip_text.pack(fill=tk.BOTH, expand=True)
        
        clip_content = """è§†é¢‘ç¼–è¾‘å™¨å‰ªè¾‘åŠŸèƒ½è¯´æ˜

1. åˆ†å‰²ç‰‡æ®µ:
   â€¢ åœ¨æ—¶é—´è½´ä¸Šé€‰æ‹©åˆ†å‰²ä½ç½®
   â€¢ ç‚¹å‡»"åˆ†å‰²"æŒ‰é’®æˆ–æŒ‰Sé”®
   â€¢ è§†é¢‘å°†åœ¨å½“å‰ä½ç½®åˆ†å‰²æˆä¸¤ä¸ªç‰‡æ®µ

2. åˆå¹¶ç‰‡æ®µ:
   â€¢ é€‰æ‹©å¤šä¸ªç›¸é‚»çš„ç‰‡æ®µ
   â€¢ ç‚¹å‡»"åˆå¹¶"æŒ‰é’®æˆ–æŒ‰Mé”®
   â€¢ é€‰ä¸­çš„ç‰‡æ®µå°†åˆå¹¶ä¸ºä¸€ä¸ªç‰‡æ®µ

3. åˆ é™¤ç‰‡æ®µ:
   â€¢ åœ¨æ—¶é—´è½´æˆ–ç‰‡æ®µåˆ—è¡¨ä¸­é€‰æ‹©è¦åˆ é™¤çš„ç‰‡æ®µ
   â€¢ ç‚¹å‡»"åˆ é™¤"æŒ‰é’®æˆ–æŒ‰Delé”®
   â€¢ é€‰ä¸­çš„ç‰‡æ®µå°†è¢«åˆ é™¤

4. è®¾ç½®å…¥ç‚¹/å‡ºç‚¹:
   â€¢ æ’­æ”¾è§†é¢‘åˆ°æƒ³è¦è®¾ç½®å…¥ç‚¹çš„ä½ç½®
   â€¢ æŒ‰Ié”®è®¾ç½®å…¥ç‚¹
   â€¢ æ’­æ”¾è§†é¢‘åˆ°æƒ³è¦è®¾ç½®å‡ºç‚¹çš„ä½ç½®
   â€¢ æŒ‰Oé”®è®¾ç½®å‡ºç‚¹
   â€¢ å¯ä»¥åŸºäºå…¥ç‚¹å’Œå‡ºç‚¹åˆ›å»ºæ–°ç‰‡æ®µ

5. æ—¶é—´è½´æ“ä½œ:
   â€¢ æ”¾å¤§/ç¼©å°: ä½¿ç”¨æ—¶é—´è½´æ§åˆ¶æŒ‰é’®
   â€¢ é€‚åº”çª—å£: è‡ªåŠ¨è°ƒæ•´æ—¶é—´è½´æ˜¾ç¤º
   â€¢ æ‹–åŠ¨ç‰‡æ®µ: åœ¨æ—¶é—´è½´ä¸Šæ‹–åŠ¨ç‰‡æ®µè°ƒæ•´ä½ç½®"""
        
        clip_text.insert(1.0, clip_content)
        clip_text.config(state=tk.DISABLED)
    
    def show_about(self):
        """æ˜¾ç¤ºå…³äº"""
        about_text = """è§†é¢‘ç¼–è¾‘å™¨ v1.0

åŸºäºPythonå’ŒTkinterå¼€å‘çš„è§†é¢‘ç¼–è¾‘è½¯ä»¶

åŠŸèƒ½:
- è§†é¢‘åŠ è½½å’Œé¢„è§ˆ
- åŸºæœ¬å‰ªè¾‘æ“ä½œ
- æ—¶é—´è½´ç¼–è¾‘
- è§†é¢‘å¯¼å‡º

å¼€å‘ä¸­..."""
        messagebox.showinfo("å…³äº", about_text)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢æ’­æ”¾
        self.playing = False
        self.stop_audio_playback()
        
        # ç­‰å¾…æ’­æ”¾çº¿ç¨‹ç»“æŸ
        if self.play_thread is not None and self.play_thread.is_alive():
            time.sleep(0.1)  # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©çº¿ç¨‹ç»“æŸ
        
        # é‡Šæ”¾è§†é¢‘èµ„æº
        if self.cap is not None:
            self.cap.release()
            self.cap = None
    
    def on_closing(self):
        """çª—å£å…³é—­äº‹ä»¶"""
        self.cleanup()
        self.root.destroy()


def main():
    """ä¸»å‡½æ•°"""
    try:
        root = tk.Tk()
        app = VideoEditorApp(root)
        root.mainloop()
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²åœæ­¢ (KeyboardInterrupt)")
        # å°è¯•æ¸…ç†èµ„æº
        try:
            # è·å– app å®ä¾‹å¹¶æ¸…ç† (å¦‚æœå­˜åœ¨)
            # ç”±äº app æ˜¯å±€éƒ¨å˜é‡ï¼Œè¿™é‡Œå¯èƒ½æ— æ³•ç›´æ¥è®¿é—®ï¼Œ
            # ä½†é€šå¸¸ Tkinter åº”ç”¨ä¼šåœ¨çª—å£å…³é—­æ—¶è°ƒç”¨ cleanup
            pass
        except:
            pass
        
        # ç¡®ä¿é€€å‡º
        import sys
        sys.exit(0)


if __name__ == "__main__":
    main()
