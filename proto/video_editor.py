#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘ç¼–è¾‘è½¯ä»¶ - ä¸»ç¨‹åº
æ”¯æŒè§†é¢‘åŠ è½½ã€é¢„è§ˆã€å‰ªè¾‘ã€å¯¼å‡ºç­‰åŠŸèƒ½
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog
import os
import threading
import time
from pathlib import Path
import math
from datetime import datetime, timedelta, timezone
import bisect
import subprocess
import shutil
import xml.dom.minidom
import struct
import tempfile
import json
import re
import signal

# å°è¯•å¯¼å…¥numpyç”¨äºé”™è¯¯å¤„ç†
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    print("è­¦å‘Š: æœªå®‰è£… numpyï¼ŒæŸäº›åŠŸèƒ½å°†å—é™ã€‚è¯·è¿è¡Œ: pip install numpy")

# å°è¯•å¯¼å…¥è§†é¢‘å¤„ç†åº“
try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    print("è­¦å‘Š: æœªå®‰è£… opencv-pythonï¼Œè§†é¢‘æ’­æ”¾åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install opencv-python")

try:
    from PIL import Image, ImageTk
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("è­¦å‘Š: æœªå®‰è£… Pillowï¼Œè§†é¢‘æ˜¾ç¤ºåŠŸèƒ½å°†å—é™ã€‚è¯·è¿è¡Œ: pip install Pillow")

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
import platform
if platform.system() == 'Windows':
    import tkinter.font as tkFont
    default_font = ('Microsoft YaHei', 9)
elif platform.system() == 'Darwin':  # macOS
    default_font = ('PingFang SC', 11)
else:  # Linux
    default_font = ('WenQuanYi Micro Hei', 10)


class VideoEditorApp:
    """è§†é¢‘ç¼–è¾‘å™¨ä¸»åº”ç”¨ç±»"""
    
    def __init__(self, root):
        self.root = root
        self.root.title("è§†é¢‘ç¼–è¾‘å™¨")
        self.root.geometry("1200x800")
        self.root.minsize(800, 600)
        
        # è§†é¢‘ç›¸å…³å˜é‡
        self.video_path = None
        self.video_info = {}
        self.video_creation_time = None # è§†é¢‘åˆ›å»ºæ—¶é—´
        self.clips = []  # å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
        self.timeline_thumbnails = {} # æ—¶é—´è½´ç¼©ç•¥å›¾ {time_sec: photo_image}
        self.thumbnail_thread = None # ç¼©ç•¥å›¾ç”Ÿæˆçº¿ç¨‹
        
        # GPX æ•°æ®
        self.gpx_data = None  # æ ¼å¼: {'segments': [(start_time, end_time, speed), ...]}
        self.gpx_offset = 0.0  # GPXæ—¶é—´åç§»ï¼ˆç§’ï¼‰
        self.track_thumbnail = None # è½¨è¿¹ç¼©ç•¥å›¾
        self.track_transform = None # åæ ‡è½¬æ¢å‚æ•°
        
        # è½¨è¿¹é¢„è§ˆç¼©æ”¾å’Œå¹³ç§»
        self.align_zoom_scale = 1.0
        self.align_offset_x = 0.0
        self.align_offset_y = 0.0
        self.align_drag_start = None
        
        # è°ƒè¯•ä¿¡æ¯
        self.debug_info = {}
        
        # æ’­æ”¾ç›¸å…³å˜é‡
        self.cap = None  # OpenCV VideoCapture å¯¹è±¡
        self.playing = False  # æ˜¯å¦æ­£åœ¨æ’­æ”¾
        self.current_frame_pos = 0  # å½“å‰å¸§ä½ç½®
        self.total_frames = 0  # æ€»å¸§æ•°
        self.current_frame_image = None  # å½“å‰å¸§å›¾åƒ
        self.play_thread = None  # æ’­æ”¾çº¿ç¨‹
        self.audio_proc = None
        
        # æ‹–æ‹½çŠ¶æ€å˜é‡
        self.is_dragging_progress = False
        self.was_playing_before_drag = False
        
        # æ–°å¢ï¼šæ’­æ”¾æ§åˆ¶å¢å¼º
        self.playback_speed = 1.0  # æ’­æ”¾é€Ÿåº¦
        self.volume = 1.0  # éŸ³é‡
        self.is_muted = False  # æ˜¯å¦é™éŸ³
        self.loop_playback = False  # æ˜¯å¦å¾ªç¯æ’­æ”¾
        self.fullscreen_mode = False  # æ˜¯å¦å…¨å±æ¨¡å¼
        
        # åˆ›å»ºGUI
        self.create_menu()
        self.create_toolbar()
        self.create_main_panel()
        self.create_timeline()
        self.create_status_bar()
        
        # è®¾ç½®æ ·å¼
        self.setup_styles()
        
        # ç»‘å®šçª—å£å…³é—­äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        
        # ç»‘å®šGPXåç§»è°ƒæ•´å¿«æ·é”®
        self.root.bind('[', self.decrease_offset)
        self.root.bind(']', self.increase_offset)
        self.root.bind('{', self.decrease_offset_fine) # Shift+[
        self.root.bind('}', self.increase_offset_fine) # Shift+]
    
    def _get_ffprobe_cmd(self):
        """è·å–ffprobeå‘½ä»¤è·¯å¾„"""
        # 1. æ£€æŸ¥ç³»ç»ŸPATH
        if shutil.which('ffprobe'):
            return ['ffprobe']
        env_ffprobe = os.environ.get('FFPROBE')
        if env_ffprobe and os.path.exists(env_ffprobe):
            return [env_ffprobe]
            
        # 2. æ£€æŸ¥å½“å‰ç›®å½•
        if os.path.exists('ffprobe.exe'):
            return [os.path.abspath('ffprobe.exe')]
            
        if os.path.exists('ffprobe'):
            return [os.path.abspath('ffprobe')]
            
        # 3. æ£€æŸ¥å¸¸è§å­ç›®å½•
        common_paths = [
            os.path.join('ffmpeg', 'bin', 'ffprobe.exe'),
            os.path.join('bin', 'ffprobe.exe'),
            os.path.join('tools', 'ffprobe.exe'),
            os.path.join('ffmpeg', 'bin', 'ffprobe'),
            os.path.join('bin', 'ffprobe'),
            os.path.join('tools', 'ffprobe'),
            '/usr/local/bin/ffprobe',
            '/opt/homebrew/bin/ffprobe',
            '/usr/bin/ffprobe',
            '/opt/local/bin/ffprobe',
        ]
        
        for p in common_paths:
            if os.path.exists(p):
                return [os.path.abspath(p)]
                
        return None

    def setup_styles(self):
        """è®¾ç½®ç•Œé¢æ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
    
    def create_menu(self):
        """åˆ›å»ºèœå•æ """
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # æ–‡ä»¶èœå•
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ–‡ä»¶", menu=file_menu)
        file_menu.add_command(label="æ‰“å¼€è§†é¢‘...", command=self.open_video, accelerator="Ctrl+O")
        file_menu.add_command(label="å¯¼å…¥è§†é¢‘...", command=self.import_video)
        file_menu.add_command(label="å¯¼å…¥GPX...", command=self.import_gpx)
        file_menu.add_separator()
        file_menu.add_command(label="ä¿å­˜é¡¹ç›®...", command=self.save_project, accelerator="Ctrl+S")
        file_menu.add_command(label="æ‰“å¼€é¡¹ç›®...", command=self.open_project, accelerator="Ctrl+Shift+O")
        file_menu.add_separator()
        file_menu.add_command(label="å¯¼å‡ºè§†é¢‘...", command=self.export_video, accelerator="Ctrl+E")
        file_menu.add_separator()
        file_menu.add_command(label="é€€å‡º", command=self.root.quit, accelerator="Ctrl+Q")
        
        # ç¼–è¾‘èœå•
        edit_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="ç¼–è¾‘", menu=edit_menu)
        edit_menu.add_command(label="æ’¤é”€", command=self.undo, accelerator="Ctrl+Z", state="disabled")
        edit_menu.add_command(label="é‡åš", command=self.redo, accelerator="Ctrl+Y", state="disabled")
        edit_menu.add_separator()
        edit_menu.add_command(label="å‰ªåˆ‡", command=self.cut_clip, accelerator="Ctrl+X")
        edit_menu.add_command(label="å¤åˆ¶", command=self.copy_clip, accelerator="Ctrl+C")
        edit_menu.add_command(label="ç²˜è´´", command=self.paste_clip, accelerator="Ctrl+V")
        edit_menu.add_separator()
        edit_menu.add_command(label="åˆ é™¤", command=self.delete_clip, accelerator="Del")
        
        # å‰ªè¾‘èœå•
        clip_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å‰ªè¾‘", menu=clip_menu)
        clip_menu.add_command(label="åˆ†å‰²", command=self.split_clip, accelerator="S")
        clip_menu.add_command(label="åˆå¹¶", command=self.merge_clips, accelerator="M")
        clip_menu.add_separator()
        clip_menu.add_command(label="è®¾ç½®å…¥ç‚¹", command=self.set_in_point, accelerator="I")
        clip_menu.add_command(label="è®¾ç½®å‡ºç‚¹", command=self.set_out_point, accelerator="O")
        clip_menu.add_separator()
        clip_menu.add_command(label="æ·»åŠ è½¬åœºæ•ˆæœ...", command=self.add_transition, state="disabled")
        clip_menu.add_command(label="æ·»åŠ æ»¤é•œ...", command=self.add_filter, state="disabled")
        
        # æ’­æ”¾èœå•
        play_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ’­æ”¾", menu=play_menu)
        play_menu.add_command(label="æ’­æ”¾/æš‚åœ", command=self.toggle_play, accelerator="Space")
        play_menu.add_command(label="åœæ­¢", command=self.stop_play, accelerator="K")
        play_menu.add_separator()
        play_menu.add_command(label="ä¸Šä¸€å¸§", command=self.prev_frame, accelerator="â†")
        play_menu.add_command(label="ä¸‹ä¸€å¸§", command=self.next_frame, accelerator="â†’")
        play_menu.add_separator()
        play_menu.add_command(label="è·³è½¬åˆ°å¼€å§‹", command=self.jump_to_start, accelerator="Home")
        play_menu.add_command(label="è·³è½¬åˆ°ç»“æŸ", command=self.jump_to_end, accelerator="End")
        play_menu.add_separator()
        play_menu.add_checkbutton(label="å¾ªç¯æ’­æ”¾", command=self.toggle_loop, 
                                 variable=tk.BooleanVar(value=self.loop_playback))

        # å·¥å…·èœå•
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å·¥å…·", menu=tools_menu)
        tools_menu.add_command(label="æ‰‹åŠ¨è®¾ç½®GPXåç§»", command=self.set_manual_offset)
        
        # å¸®åŠ©èœå•
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å¸®åŠ©", menu=help_menu)
        help_menu.add_command(label="ä½¿ç”¨è¯´æ˜", command=self.show_help)
        help_menu.add_command(label="å…³äº", command=self.show_about)
        
        # ç»‘å®šå¿«æ·é”®
        self.root.bind('<Control-o>', lambda e: self.open_video())
        self.root.bind('<Control-s>', lambda e: self.save_project())
        self.root.bind('<Control-e>', lambda e: self.export_video())
        self.root.bind('<space>', lambda e: self.toggle_play())
        self.root.bind('<k>', lambda e: self.stop_play())
        
        # æ–°å¢å¿«æ·é”®
        self.root.bind('<Left>', lambda e: self.prev_frame())
        self.root.bind('<Right>', lambda e: self.next_frame())
        self.root.bind('<Shift-Left>', lambda e: self.rewind_5s())
        self.root.bind('<Shift-Right>', lambda e: self.forward_5s())
        self.root.bind('<Home>', lambda e: self.jump_to_start())
        self.root.bind('<End>', lambda e: self.jump_to_end())
        self.root.bind('<Delete>', lambda e: self.delete_clip())
        self.root.bind('<s>', lambda e: self.split_clip())
        self.root.bind('<m>', lambda e: self.merge_clips())
        self.root.bind('<i>', lambda e: self.set_in_point())
        self.root.bind('<o>', lambda e: self.set_out_point())
        self.root.bind('<m>', lambda e: self.toggle_mute())
    
    def create_toolbar(self):
        """åˆ›å»ºå·¥å…·æ """
        toolbar = ttk.Frame(self.root, relief=tk.RAISED, borderwidth=1)
        toolbar.pack(side=tk.TOP, fill=tk.X, padx=2, pady=2)
        
        # æ–‡ä»¶æ“ä½œæŒ‰é’®
        ttk.Button(toolbar, text="æ‰“å¼€è§†é¢‘", command=self.open_video, width=12).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="å¯¼å…¥è§†é¢‘", command=self.import_video, width=12).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="å¯¼å…¥GPX", command=self.import_gpx, width=12).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="å¯¼å‡ºè§†é¢‘", command=self.export_video, width=12).pack(side=tk.LEFT, padx=2)
        
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=5)
        
        # æ’­æ”¾æ§åˆ¶æŒ‰é’®
        self.play_btn = ttk.Button(toolbar, text="â–¶ æ’­æ”¾", command=self.toggle_play, width=10)
        self.play_btn.pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="â¹ åœæ­¢", command=self.stop_play, width=10).pack(side=tk.LEFT, padx=2)
        
        # æ–°å¢ï¼šå¿«é€Ÿè·³è½¬æŒ‰é’®
        ttk.Button(toolbar, text="â®", command=self.jump_to_start, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(toolbar, text="âª", command=self.rewind_5s, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(toolbar, text="â©", command=self.forward_5s, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(toolbar, text="â­", command=self.jump_to_end, width=3).pack(side=tk.LEFT, padx=1)
        
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=5)
        
        # å‰ªè¾‘æ“ä½œæŒ‰é’®
        ttk.Button(toolbar, text="åˆ†å‰²", command=self.split_clip, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="åˆ é™¤", command=self.delete_clip, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="åˆå¹¶", command=self.merge_clips, width=8).pack(side=tk.LEFT, padx=2)
        
        ttk.Separator(toolbar, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=5)
        
        # ç¼©æ”¾æ§åˆ¶
        ttk.Label(toolbar, text="ç¼©æ”¾:").pack(side=tk.LEFT, padx=2)
        self.zoom_var = tk.StringVar(value="100%")
        zoom_combo = ttk.Combobox(toolbar, textvariable=self.zoom_var, width=8, 
                                  values=["25%", "50%", "75%", "100%", "125%", "150%", "200%"],
                                  state="readonly")
        zoom_combo.pack(side=tk.LEFT, padx=2)
        zoom_combo.bind('<<ComboboxSelected>>', self.on_zoom_change)
    
    def create_main_panel(self):
        """åˆ›å»ºä¸»é¢æ¿ï¼ˆé¢„è§ˆçª—å£å’Œæ§åˆ¶é¢æ¿ï¼‰"""
        main_container = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_container.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        left_container = ttk.Frame(main_container)
        main_container.add(left_container, weight=2)
        self.preview_notebook = ttk.Notebook(left_container)
        self.preview_notebook.pack(fill=tk.BOTH, expand=True)
        video_tab = ttk.Frame(self.preview_notebook)
        self.preview_notebook.add(video_tab, text="è§†é¢‘")
        # self.align_tab = ttk.Frame(self.preview_notebook)
        # self.preview_notebook.add(self.align_tab, text="è½¨è¿¹å¯¹é½")
        self.video_canvas = tk.Canvas(video_tab, bg="#000000", width=640, height=360, highlightthickness=0, bd=0)
        self.video_canvas.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.preview_label = ttk.Label(video_tab, text="ğŸ“¹ æœªåŠ è½½è§†é¢‘\n\nç‚¹å‡» æ–‡ä»¶ -> æ‰“å¼€è§†é¢‘ æ¥åŠ è½½è§†é¢‘æ–‡ä»¶", font=default_font, foreground="gray", justify=tk.CENTER)
        self.preview_label.place(relx=0.5, rely=0.5, anchor=tk.CENTER)
        control_frame = ttk.Frame(video_tab)
        control_frame.pack(fill=tk.X, padx=5, pady=5)
        self.progress_var = tk.DoubleVar()
        self.progress_scale = ttk.Scale(control_frame, from_=0, to=100, variable=self.progress_var, orient=tk.HORIZONTAL, command=self.on_progress_change)
        self.progress_scale.pack(fill=tk.X, padx=5, pady=2)
        self.progress_scale.bind("<ButtonPress-1>", self.on_progress_press)
        self.progress_scale.bind("<ButtonRelease-1>", self.on_progress_release)
        time_frame = ttk.Frame(control_frame)
        time_frame.pack(fill=tk.X, padx=5)
        self.time_label = ttk.Label(time_frame, text="00:00:00 / 00:00:00", font=default_font)
        self.time_label.pack(side=tk.LEFT)
        control_buttons_frame = ttk.Frame(time_frame)
        control_buttons_frame.pack(side=tk.LEFT, padx=20)
        ttk.Button(control_buttons_frame, text="â®", command=self.jump_to_start, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(control_buttons_frame, text="âª", command=self.rewind_5s, width=3).pack(side=tk.LEFT, padx=1)
        self.play_btn = ttk.Button(control_buttons_frame, text="â–¶", command=self.toggle_play, width=3)
        self.play_btn.pack(side=tk.LEFT, padx=1)
        ttk.Button(control_buttons_frame, text="â©", command=self.forward_5s, width=3).pack(side=tk.LEFT, padx=1)
        ttk.Button(control_buttons_frame, text="â­", command=self.jump_to_end, width=3).pack(side=tk.LEFT, padx=1)
        volume_frame = ttk.Frame(time_frame)
        volume_frame.pack(side=tk.RIGHT, padx=5)
        self.mute_btn = ttk.Button(volume_frame, text="ğŸ”Š", command=self.toggle_mute, width=3)
        self.mute_btn.pack(side=tk.LEFT, padx=1)
        self.volume_scale = ttk.Scale(volume_frame, from_=0, to=100, orient=tk.HORIZONTAL, command=self.on_volume_change, length=80)
        self.volume_scale.set(100)
        self.volume_scale.pack(side=tk.LEFT, padx=2)
        speed_frame = ttk.Frame(time_frame)
        speed_frame.pack(side=tk.RIGHT, padx=10)
        ttk.Label(speed_frame, text="é€Ÿåº¦:", font=default_font).pack(side=tk.LEFT, padx=2)
        self.speed_var = tk.StringVar(value="1.0x")
        speed_combo = ttk.Combobox(speed_frame, textvariable=self.speed_var, width=6, values=["0.25x", "0.5x", "0.75x", "1.0x", "1.25x", "1.5x", "2.0x"], state="readonly")
        speed_combo.pack(side=tk.LEFT, padx=2)
        speed_combo.bind('<<ComboboxSelected>>', self.on_speed_change)
        # self.init_align_tab(self.align_tab)
        property_frame = ttk.LabelFrame(main_container, text="å±æ€§", padding=10, width=250)
        main_container.add(property_frame, weight=1)
        self.create_property_panel(property_frame)
    
    def create_property_panel(self, parent):
        """åˆ›å»ºå±æ€§é¢æ¿"""
        # è½¨è¿¹é¢„è§ˆ (åŸè§†é¢‘ç¼©ç•¥å›¾ä½ç½®)
        self.align_frame = ttk.LabelFrame(parent, text="è½¨è¿¹é¢„è§ˆ", padding=5)
        self.align_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        self.align_canvas = tk.Canvas(self.align_frame, bg="#1E1E1E", height=200, width=160,
                                          highlightthickness=0, bd=0)
        self.align_canvas.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.align_canvas.bind("<Configure>", lambda e: self.update_align_canvas())
        self.align_canvas.bind("<MouseWheel>", self.on_align_zoom) # Windows/MacOS
        self.align_canvas.bind("<Button-4>", self.on_align_zoom)   # Linux Scroll Up
        self.align_canvas.bind("<Button-5>", self.on_align_zoom)   # Linux Scroll Down
        self.align_canvas.bind("<ButtonPress-1>", self.on_align_drag_start)
        self.align_canvas.bind("<B1-Motion>", self.on_align_drag_move)
        
        # è½¨è¿¹å¯¹é½æ§åˆ¶ (åŸè§†é¢‘ä¿¡æ¯ä½ç½®)
        control_frame = ttk.LabelFrame(parent, text="å¯¹é½æ§åˆ¶", padding=5)
        control_frame.pack(fill=tk.X, pady=5)
        
        # æ§ä»¶
        self.align_reverse_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(control_frame, text="åå‘", variable=self.align_reverse_var, command=self.update_align_canvas).pack(side=tk.TOP, anchor=tk.E, padx=5)
        
        self.align_progress_var = tk.DoubleVar(value=0.0)
        self.align_scale = ttk.Scale(control_frame, from_=0.0, to=0.0, orient=tk.HORIZONTAL, variable=self.align_progress_var, command=self.on_align_progress_change)
        self.align_scale.pack(fill=tk.X, padx=5, pady=5)
        
        self.align_time_label = ttk.Label(control_frame, text="GPXæ—¶é—´: 0.0s")
        self.align_time_label.pack(side=tk.LEFT, padx=5)
        
        self.align_confirm_btn = ttk.Button(control_frame, text="ç¡®è®¤å¯¹é½", command=self.align_confirm)
        self.align_confirm_btn.pack(side=tk.RIGHT, padx=5)
        
        ttk.Button(control_frame, text="é‡ç½®è§†å›¾", command=self.reset_align_view, width=8).pack(side=tk.RIGHT, padx=2)
        
        # Init variables
        self.align_track_points = None
        self.align_transform = None
        self.thumbnail_canvas = None # Disable video thumbnail canvas

        # å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
        clip_frame = ttk.LabelFrame(parent, text="å‰ªè¾‘ç‰‡æ®µ", padding=5)
        clip_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # ç‰‡æ®µåˆ—è¡¨æ ‘å½¢è§†å›¾
        columns = ('åç§°', 'å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´', 'æ—¶é•¿')
        self.clip_tree = ttk.Treeview(clip_frame, columns=columns, show='tree headings', height=10)
        
        self.clip_tree.heading('#0', text='#')
        self.clip_tree.heading('åç§°', text='åç§°')
        self.clip_tree.heading('å¼€å§‹æ—¶é—´', text='å¼€å§‹æ—¶é—´')
        self.clip_tree.heading('ç»“æŸæ—¶é—´', text='ç»“æŸæ—¶é—´')
        self.clip_tree.heading('æ—¶é•¿', text='æ—¶é•¿')
        
        self.clip_tree.column('#0', width=40)
        self.clip_tree.column('åç§°', width=100)
        self.clip_tree.column('å¼€å§‹æ—¶é—´', width=80)
        self.clip_tree.column('ç»“æŸæ—¶é—´', width=80)
        self.clip_tree.column('æ—¶é•¿', width=80)
        
        scrollbar = ttk.Scrollbar(clip_frame, orient=tk.VERTICAL, command=self.clip_tree.yview)
        self.clip_tree.configure(yscrollcommand=scrollbar.set)
        
        self.clip_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        self.clip_tree.bind('<Double-1>', self.on_clip_select)
    
    # def init_align_tab(self, parent):
    #     self.align_canvas = tk.Canvas(parent, bg="#1E1E1E", height=420, highlightthickness=0, bd=0)
    #     self.align_canvas.pack(fill=tk.BOTH, expand=True, padx=6, pady=6)
    #     bottom = ttk.Frame(parent)
    #     bottom.pack(fill=tk.X, padx=6, pady=6)
    #     self.align_reverse_var = tk.BooleanVar(value=False)
    #     ttk.Checkbutton(bottom, text="åå‘", variable=self.align_reverse_var, command=self.update_align_canvas).pack(side=tk.RIGHT, padx=6)
    #     self.align_progress_var = tk.DoubleVar(value=0.0)
    #     self.align_scale = ttk.Scale(bottom, from_=0.0, to=0.0, orient=tk.HORIZONTAL, variable=self.align_progress_var, command=self.on_align_progress_change)
    #     self.align_scale.pack(fill=tk.X, side=tk.LEFT, expand=True, padx=6)
    #     self.align_time_label = ttk.Label(bottom, text="GPXæ—¶é—´: 0.0s")
    #     self.align_time_label.pack(side=tk.LEFT, padx=8)
    #     self.align_confirm_btn = ttk.Button(bottom, text="ç¡®è®¤å¯¹é½", command=self.align_confirm)
    #     self.align_confirm_btn.pack(side=tk.RIGHT, padx=6)
    #     self.align_canvas.bind("<Configure>", lambda e: self.update_align_canvas())
    #     self.align_track_points = None
    #     self.align_transform = None
    
    def get_gpx_duration(self):
        if isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data and self.gpx_data['segments']:
            return float(self.gpx_data['segments'][-1]['end'])
        return 0.0
    
    def _get_latlon_at_gpx_time(self, t):
        if not (isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data):
            return None, None
        segs = self.gpx_data['segments']
        if not segs:
            return None, None
        if t <= segs[0]['start']:
            return segs[0]['lat_start'], segs[0]['lon_start']
        if t >= segs[-1]['end']:
            return segs[-1]['lat_end'], segs[-1]['lon_end']
        low, high = 0, len(segs) - 1
        while low <= high:
            mid = (low + high) // 2
            s = segs[mid]
            if s['start'] <= t <= s['end']:
                ratio = 0.0
                span = s['end'] - s['start']
                if span > 0:
                    ratio = (t - s['start']) / span
                lat = s['lat_start'] + (s['lat_end'] - s['lat_start']) * ratio
                lon = s['lon_start'] + (s['lon_end'] - s['lon_start']) * ratio
                return lat, lon
            if t > s['end']:
                low = mid + 1
            else:
                high = mid - 1
        return None, None
    
    def update_align_controls(self):
        if not (isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data and self.gpx_data['segments']):
            self.align_scale.config(from_=0.0, to=0.0)
            self.align_progress_var.set(0.0)
            self.align_time_label.config(text="GPXæ—¶é—´: 0.0s")
            self.update_align_canvas()
            return
        duration = max(0.0, self.get_gpx_duration())
        self.align_scale.config(from_=0.0, to=duration)
        self.align_progress_var.set(0.0)
        self.align_time_label.config(text=f"GPXæ—¶é—´: 0.0s")
        self.update_align_canvas()
    
    def reset_align_view(self):
        """é‡ç½®è½¨è¿¹é¢„è§ˆè§†å›¾"""
        self.align_zoom_scale = 1.0
        self.align_offset_x = 0.0
        self.align_offset_y = 0.0
        self.update_align_canvas()
        
    def on_align_zoom(self, event):
        """å¤„ç†è½¨è¿¹é¢„è§ˆç¼©æ”¾"""
        if not self.gpx_data:
            return
            
        # Determine scroll direction
        if event.num == 5 or event.delta < 0:
            scale_factor = 0.9
        else:
            scale_factor = 1.1
            
        # Update zoom scale
        new_zoom = self.align_zoom_scale * scale_factor
        if 0.1 <= new_zoom <= 50.0:
            # Zoom around mouse position
            w = self.align_canvas.winfo_width()
            h = self.align_canvas.winfo_height()
            mx = event.x - w / 2
            my = event.y - h / 2
            
            self.align_offset_x = mx - (mx - self.align_offset_x) * scale_factor
            self.align_offset_y = my - (my - self.align_offset_y) * scale_factor
            
            self.align_zoom_scale = new_zoom
            self.update_align_canvas()
            
    def on_align_drag_start(self, event):
        """å¼€å§‹æ‹–æ‹½è½¨è¿¹é¢„è§ˆ"""
        self.align_drag_start = (event.x, event.y)
        
    def on_align_drag_move(self, event):
        """æ‹–æ‹½è½¨è¿¹é¢„è§ˆ"""
        if not self.align_drag_start:
            return
            
        dx = event.x - self.align_drag_start[0]
        dy = event.y - self.align_drag_start[1]
        
        self.align_offset_x += dx
        self.align_offset_y += dy
        
        self.align_drag_start = (event.x, event.y)
        self.update_align_canvas()

    def update_align_canvas(self):
        if not hasattr(self, 'align_canvas'):
            return
        self.align_canvas.delete("all")
        if not (isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data and self.gpx_data['segments']):
            w = self.align_canvas.winfo_width()
            h = self.align_canvas.winfo_height()
            if w > 0 and h > 0:
                self.align_canvas.create_text(w//2, h//2, text="æœªåŠ è½½GPX", fill="#999999")
            return
        pts = []
        for s in self.gpx_data['segments']:
            pts.append((s['lat_start'], s['lon_start']))
        if self.gpx_data['segments']:
            last = self.gpx_data['segments'][-1]
            pts.append((last['lat_end'], last['lon_end']))
            
        lats = [p[0] for p in pts]
        lons = [p[1] for p in pts]
        if not lats:
            return
            
        min_lat, max_lat = min(lats), max(lats)
        min_lon, max_lon = min(lons), max(lons)
        
        w = max(1, self.align_canvas.winfo_width())
        h = max(1, self.align_canvas.winfo_height())
        padding = 20
        
        mid_lat = math.radians((min_lat + max_lat) / 2) if max_lat != min_lat else 0.0
        lon_corr = math.cos(mid_lat) if max_lat != min_lat else 1.0
        
        lat_range = max(1e-9, max_lat - min_lat)
        lon_range = max(1e-9, (max_lon - min_lon) * lon_corr)
        
        # Base scale to fit screen
        scale_x = (w - 2 * padding) / lon_range
        scale_y = (h - 2 * padding) / lat_range
        base_scale = min(scale_x, scale_y)
        
        bb_w = lon_range * base_scale
        bb_h = lat_range * base_scale
        
        cx = w / 2
        cy = h / 2
        
        zoom = getattr(self, 'align_zoom_scale', 1.0)
        off_x = getattr(self, 'align_offset_x', 0.0)
        off_y = getattr(self, 'align_offset_y', 0.0)
        
        def tf(lat, lon):
            norm_x = ((lon - min_lon) * lon_corr / lon_range) - 0.5
            norm_y = ((lat - min_lat) / lat_range) - 0.5
            
            x_base = norm_x * bb_w
            y_base = -norm_y * bb_h
            
            x_zoomed = x_base * zoom
            y_zoomed = y_base * zoom
            
            x = cx + x_zoomed + off_x
            y = cy + y_zoomed + off_y
            return x, y
            
        screen = [tf(lat, lon) for lat, lon in pts]
        
        # Draw all lines at once
        flat_pts = [coord for pt in screen for coord in pt]
        if len(flat_pts) >= 4:
            self.align_canvas.create_line(flat_pts, fill="#00FF00", width=2)
            
        t = self.align_progress_var.get()
        duration = self.get_gpx_duration()
        eff_t = duration - t if self.align_reverse_var.get() else t
        lat, lon = self._get_latlon_at_gpx_time(eff_t)
        
        if lat is not None and lon is not None:
            x, y = tf(lat, lon)
            r = 5
            self.align_canvas.create_oval(x-r, y-r, x+r, y+r, fill="#00BFFF", outline="")
            # Crosshair
            self.align_canvas.create_line(x-10, y, x+10, y, fill="white", width=1)
            self.align_canvas.create_line(x, y-10, x, y+10, fill="white", width=1)
            
        self.align_transform = (min_lat, min_lon, base_scale, h, padding, lon_corr)
        self.align_track_points = pts
    
    def on_align_progress_change(self, value):
        try:
            v = float(value)
        except:
            v = 0.0
        duration = self.get_gpx_duration()
        eff_v = duration - v if getattr(self, 'align_reverse_var', None) and self.align_reverse_var.get() else v
        self.align_time_label.config(text=f"GPXæ—¶é—´: {eff_v:.1f}s")
        self.update_align_canvas()
    
    def align_confirm(self):
        if not (isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data and self.gpx_data['segments']):
            messagebox.showwarning("æç¤º", "æœªåŠ è½½GPXæ•°æ®")
            return
        current_video_time = self._current_time()
        raw_gpx_time = self.align_progress_var.get()
        duration = self.get_gpx_duration()
        selected_gpx_time = duration - raw_gpx_time if self.align_reverse_var.get() else raw_gpx_time
        self.gpx_offset = selected_gpx_time - current_video_time
        self.update_status(f"è®¾ç½®åç§»: {self.gpx_offset:+.2f}s")
        if self.cap is not None:
            # å¼ºåˆ¶åˆ·æ–°å½“å‰å¸§å åŠ å±‚ï¼ˆæ— è®ºæ˜¯å¦åœ¨æ’­æ”¾ï¼‰
            self.seek_to_frame(self.current_frame_pos)
    
    def create_timeline(self):
        """åˆ›å»ºæ—¶é—´è½´"""
        timeline_frame = ttk.LabelFrame(self.root, text="æ—¶é—´è½´", padding=5)
        timeline_frame.pack(fill=tk.BOTH, expand=False, padx=5, pady=5, side=tk.BOTTOM)
        
        # åˆ›å»ºæ»šåŠ¨æ¡
        timeline_scroll = ttk.Scrollbar(timeline_frame, orient=tk.HORIZONTAL)
        timeline_scroll.pack(side=tk.BOTTOM, fill=tk.X)
        
        # å®šä¹‰åŒæ­¥æ»šåŠ¨å‡½æ•°
        def sync_scroll(*args):
            self.ruler_canvas.xview(*args)
            self.timeline_canvas.xview(*args)
            
        timeline_scroll.config(command=sync_scroll)
        
        # æ—¶é—´æ ‡å°º
        ruler_frame = ttk.Frame(timeline_frame, height=30)
        ruler_frame.pack(fill=tk.X, pady=2)
        
        self.ruler_canvas = tk.Canvas(ruler_frame, height=25, bg="#F0F0F0",
                                      xscrollcommand=timeline_scroll.set)
        self.ruler_canvas.pack(fill=tk.BOTH, expand=True)
        
        # æ—¶é—´è½´è½¨é“
        track_container = ttk.Frame(timeline_frame)
        track_container.pack(fill=tk.BOTH, expand=True)
        
        # æ—¶é—´è½´ç”»å¸ƒ
        self.timeline_canvas = tk.Canvas(track_container, bg="#2B2B2B", height=150,
                                         xscrollcommand=timeline_scroll.set)
        self.timeline_canvas.pack(fill=tk.BOTH, expand=True)
        
        # ç»‘å®šäº‹ä»¶
        self.timeline_canvas.bind("<Button-1>", self.on_timeline_click)
        self.timeline_canvas.bind("<B1-Motion>", self.on_timeline_click)
        self.ruler_canvas.bind("<Button-1>", self.on_timeline_click)
        self.ruler_canvas.bind("<B1-Motion>", self.on_timeline_click)
        
        # æ—¶é—´è½´æ§åˆ¶
        timeline_control = ttk.Frame(timeline_frame)
        timeline_control.pack(fill=tk.X, pady=2)
        
        ttk.Button(timeline_control, text="æ”¾å¤§", command=self.timeline_zoom_in, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(timeline_control, text="ç¼©å°", command=self.timeline_zoom_out, width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(timeline_control, text="é€‚åº”", command=self.timeline_fit, width=8).pack(side=tk.LEFT, padx=2)
        
        # æ—¶é—´è½´ç¼©æ”¾å˜é‡
        self.timeline_scale = 1.0  # åƒç´ /ç§’
    
    def create_status_bar(self):
        """åˆ›å»ºçŠ¶æ€æ """
        self.status_bar = ttk.Frame(self.root, relief=tk.SUNKEN)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)
        
        self.status_label = ttk.Label(self.status_bar, text="å°±ç»ª", font=default_font)
        self.status_label.pack(side=tk.LEFT, padx=5)
        
        # åˆ†è¾¨ç‡æ˜¾ç¤º
        self.resolution_label = ttk.Label(self.status_bar, text="", font=default_font)
        self.resolution_label.pack(side=tk.RIGHT, padx=5)
        
        # å¸§ç‡æ˜¾ç¤º
        self.fps_label = ttk.Label(self.status_bar, text="", font=default_font)
        self.fps_label.pack(side=tk.RIGHT, padx=5)
    
    # ============ èœå•åŠŸèƒ½å®ç° ============
    
    def open_video(self):
        """æ‰“å¼€è§†é¢‘æ–‡ä»¶"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            filetypes=[
                ("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv *.m4v"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if file_path:
            self.load_video(file_path)
    
    def _parse_iso8601(self, time_str):
        """è§£æISO8601æ—¶é—´å­—ç¬¦ä¸²"""
        try:
            # å¤„ç† '2023-10-01T12:00:00.000000Z'
            if time_str.endswith('Z'):
                time_str = time_str[:-1]
            # å¤„ç†å¯èƒ½çš„æ¯«ç§’
            if '.' in time_str:
                # æˆªæ–­åˆ°6ä½å¾®ç§’ï¼Œå› ä¸ºPythonåªæ”¯æŒ6ä½
                main, frac = time_str.split('.')
                frac = frac[:6]
                time_str = f"{main}.{frac}"
            return datetime.fromisoformat(time_str)
        except Exception as e:
            print(f"æ—¶é—´è§£æé”™è¯¯: {time_str}, {e}")
            return None

    def load_video(self, video_path):
        """åŠ è½½è§†é¢‘"""
        if not HAS_CV2:
            messagebox.showerror("é”™è¯¯", "æœªå®‰è£… opencv-pythonï¼\nè¯·è¿è¡Œ: pip install opencv-python")
            return
        
        # å…³é—­ä¹‹å‰æ‰“å¼€çš„è§†é¢‘
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        
        self.video_path = video_path
        # è·å–è§†é¢‘åˆ›å»ºæ—¶é—´
        self.video_creation_time, _ = self._get_video_creation_time(video_path)
        self.update_status(f"æ­£åœ¨åŠ è½½è§†é¢‘: {os.path.basename(video_path)}...")
        
        try:
            # ä½¿ç”¨ OpenCV åŠ è½½è§†é¢‘
            self.cap = cv2.VideoCapture(video_path)
            
            if not self.cap.isOpened():
                raise Exception("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            
            # è·å–ç¼–è§£ç å™¨ä¿¡æ¯
            fourcc = int(self.cap.get(cv2.CAP_PROP_FOURCC))
            codec = "".join([chr((fourcc >> 8 * i) & 0xFF) for i in range(4)])
            
            self.video_info = {
                'path': video_path,
                'name': os.path.basename(video_path),
                'duration': duration,
                'fps': fps,
                'width': width,
                'height': height,
                'codec': codec if codec.strip() else 'Unknown',
                'frame_count': frame_count
            }
            
            self.total_frames = frame_count
            self.current_frame_pos = 0
            
            # æ›´æ–°ç•Œé¢
            self.update_video_info()
            self.update_preview_label("")
            
            # æ˜¾ç¤ºç¬¬ä¸€å¸§
            self.seek_to_frame(0)
            
            self.update_status(f"è§†é¢‘åŠ è½½æˆåŠŸ: {self.video_info['name']} ({width}x{height}, {fps:.2f}fps)")
            
            # åˆå§‹åŒ–å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
            self.clips = [{
                'id': 'clip_0',
                'name': 'åˆå§‹ç‰‡æ®µ',
                'start_frame': 0,
                'end_frame': self.total_frames,
                'source': self.video_path
            }]
            self.update_clip_list()
            
            # åˆå§‹åŒ–æ—¶é—´è½´
            self.timeline_fit()
            # å¯åŠ¨ç¼©ç•¥å›¾ç”Ÿæˆ
            self.start_timeline_thumbnail_generation()
            # åŠ è½½å¤–éƒ¨GPXæ–‡ä»¶ï¼ˆä¸å†ä»è§†é¢‘ä¸­æå–GPMDï¼‰
            self.load_gpx_data(video_path)
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½è§†é¢‘å¤±è´¥:\n{str(e)}")
            self.update_status(f"åŠ è½½å¤±è´¥: {str(e)}")
            if self.cap is not None:
                self.cap.release()
                self.cap = None
    
    def set_manual_offset(self):
        """æ‰‹åŠ¨è®¾ç½®æ—¶é—´åç§»"""
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¯¹è¯æ¡†
        offset_str = simpledialog.askstring("æ‰‹åŠ¨åŒæ­¥", f"å½“å‰åç§»: {self.gpx_offset:.2f}ç§’\nè¯·è¾“å…¥æ–°çš„åç§»é‡ (ç§’):", initialvalue=str(self.gpx_offset))
        if offset_str:
            try:
                self.gpx_offset = float(offset_str)
                self.update_status(f"æ‰‹åŠ¨è®¾ç½®åç§»: {self.gpx_offset:.2f}ç§’")
                if not self.playing:
                    self.seek_to_frame(self.current_frame_pos)
            except ValueError:
                messagebox.showerror("é”™è¯¯", "æ— æ•ˆçš„æ•°å­—æ ¼å¼")

    # å·²ç§»é™¤ï¼šä»è§†é¢‘ä¸­æå–GPMDçš„é€»è¾‘

    # å·²ç§»é™¤ï¼š_calculate_speeds_from_pointsï¼ˆä»…ç”¨äº GPMD åˆ—è¡¨æ•°æ®ï¼‰

    def draw_track_thumbnail(self):
        """Draw track thumbnail for internal points"""
        if not hasattr(self, 'gpx_data') or not self.gpx_data:
            return
            
        # Extract lat/lon list from segments
        points = []
        if isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data:
            for s in self.gpx_data['segments']:
                points.append((s['lat_start'], s['lon_start']))
            if self.gpx_data['segments']:
                last = self.gpx_data['segments'][-1]
                points.append((last['lat_end'], last['lon_end']))
            
        if not points:
            return

        # Generate thumbnail
        
        # Calculate bounds
        lats = [p[0] for p in points]
        lons = [p[1] for p in points]
        min_lat, max_lat = min(lats), max(lats)
        min_lon, max_lon = min(lons), max(lons)
        
        # Create image
        w, h = 200, 150
        padding = 10
        img = Image.new('RGBA', (w, h), (0, 0, 0, 128)) # Semi-transparent background
        from PIL import ImageDraw
        draw = ImageDraw.Draw(img)
        
        # Scale
        lat_range = max_lat - min_lat
        lon_range = max_lon - min_lon
        
        if lat_range == 0 or lon_range == 0:
            return
            
        scale_x = (w - 2 * padding) / lon_range
        scale_y = (h - 2 * padding) / lat_range
        scale = min(scale_x, scale_y)
        
        # Transform function
        def transform(lat, lon):
            x = padding + (lon - min_lon) * scale
            y = h - (padding + (lat - min_lat) * scale) # Invert Y for screen coords
            return x, y
            
        # Draw track
        screen_points = [transform(lat, lon) for lat, lon in points]
        draw.line(screen_points, fill=(0, 255, 0, 255), width=2)
        
        # Store for overlay (Tkinter)
        self.track_thumbnail_img = ImageTk.PhotoImage(img)
        self.track_transform_func = transform
        self.track_bounds = (min_lat, max_lat, min_lon, max_lon)
        
        # Store for overlay (OpenCV)
        # Convert PIL RGBA to numpy array
        pil_array = np.array(img)
        # Convert RGBA to BGRA for OpenCV
        if HAS_CV2:
            self.track_thumbnail = cv2.cvtColor(pil_array, cv2.COLOR_RGBA2BGRA)
            # Store transform parameters for _draw_overlay_on_frame
            # Format: (min_lat, min_lon, scale, h, padding, lon_correction=1.0)
            self.track_transform = (min_lat, min_lon, scale, h, padding, 1.0)
        
    # å·²ç§»é™¤ï¼šGPMD æµç´¢å¼•ä¸è§£æå‡½æ•°ï¼ˆget_gpmd_stream_index / extract_gpmd_data / parse_gpmd_structureï¼‰

    def _haversine_distance(self, lat1, lon1, lat2, lon2):
        """Calculate haversine distance between two points in meters"""
        R = 6371000 # Earth radius in meters
        phi1, phi2 = math.radians(lat1), math.radians(lat2)
        dphi = math.radians(lat2 - lat1)
        dlambda = math.radians(lon2 - lon1)
        
        a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2) * math.sin(dlambda/2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        return R * c

    def import_video(self):
        """å¯¼å…¥è§†é¢‘ï¼ˆæ·»åŠ åˆ°æ—¶é—´è½´ï¼‰"""
        file_path = filedialog.askopenfilename(
            title="å¯¼å…¥è§†é¢‘",
            filetypes=[("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv *.m4v")]
        )
        
        if file_path:
            # TODO: æ·»åŠ åˆ°å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨
            self.update_status(f"å¯¼å…¥è§†é¢‘: {os.path.basename(file_path)}")
    
    def import_gpx(self):
        """å¯¼å…¥GPXæ–‡ä»¶"""
        if not self.video_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return

        file_path = filedialog.askopenfilename(
            title="å¯¼å…¥GPXæ–‡ä»¶",
            filetypes=[("GPXæ–‡ä»¶", "*.gpx"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            self.load_gpx_data(self.video_path, gpx_path=file_path)

    def load_gpx_data(self, video_path, gpx_path=None):
        """åŠ è½½å¯¹åº”çš„GPXæ•°æ®"""
        try:
            if not gpx_path:
                # å¯»æ‰¾åŒåGPXæ–‡ä»¶æˆ–ride.gpx
                video_dir = os.path.dirname(video_path)
                
                # 1. å°è¯• ride.gpx (ä¼˜å…ˆçº§æœ€é«˜)
                check_path = os.path.join(video_dir, 'ride.gpx')
                if os.path.exists(check_path):
                    gpx_path = check_path
                
                # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å½“å‰ç›®å½•ä¸‹çš„ ride.gpx
                if not gpx_path and os.path.exists('ride.gpx'):
                    gpx_path = 'ride.gpx'
                
                # 3. å°è¯•åŒåGPX
                if not gpx_path:
                    base_name = os.path.splitext(os.path.basename(video_path))[0]
                    check_path = os.path.join(video_dir, f"{base_name}.gpx")
                    if os.path.exists(check_path):
                        gpx_path = check_path
                
            if not gpx_path:
                return

            points, name, gpx_start_time = self._parse_gpx_file(gpx_path)
            
            if not points:
                return

            speeds = self._calculate_speeds(points)
            
            # å¤„ç†æ—¶é—´å¹¶å»ºç«‹æŸ¥è¯¢ç»“æ„
            segments = []
            
            # å°è¯•è·å–è§†é¢‘å¼€å§‹æ—¶é—´ä»¥è¿›è¡ŒåŒæ­¥
            video_start_time, method = self._get_video_creation_time(video_path)
            
            # è®¡ç®—åˆå§‹åç§»é‡
            if video_start_time and gpx_start_time:
                # åç§»é‡ = è§†é¢‘å¼€å§‹æ—¶é—´ - GPXå¼€å§‹æ—¶é—´
                initial_offset = (video_start_time - gpx_start_time).total_seconds()
                self.gpx_offset = initial_offset
                
                msg = f"è‡ªåŠ¨åŒæ­¥GPX: åç§» {self.gpx_offset:.2f}ç§’\nè§†é¢‘æ—¶é—´: {video_start_time} ({method})\nGPXæ—¶é—´: {gpx_start_time}"
                self.update_status(msg)
                print(msg)
                
                # å¼¹å‡ºæç¤ºè®©ç”¨æˆ·ç¡®è®¤æ—¶é—´
                messagebox.showinfo("æ—¶é—´åŒæ­¥ä¿¡æ¯", msg)
            else:
                self.gpx_offset = 0.0
                
            for i in range(len(speeds)):
                p1 = points[i]
                p2 = points[i+1]
                t1 = p1[3]
                t2 = p2[3]
                
                if t1 and t2:
                    # è®¡ç®—ç›¸å¯¹äºGPXèµ·ç‚¹çš„ç§’æ•°
                    rel_t1 = (t1 - gpx_start_time).total_seconds()
                    rel_t2 = (t2 - gpx_start_time).total_seconds()
                    
                    # è·å–è¯¥æ®µçš„å¿ƒç‡ï¼ˆå–èµ·ç‚¹çš„å¿ƒç‡ï¼‰
                    hr = points[i][4] if len(points[i]) > 4 else 0
                    
                    segments.append({
                        'start': rel_t1,
                        'end': rel_t2,
                        'speed': speeds[i],
                        'hr': hr,
                        'lat_start': points[i][0],
                        'lon_start': points[i][1],
                        'lat_end': points[i+1][0],
                        'lon_end': points[i+1][1]
                    })
            
            # ä¿é™©èµ·è§ï¼ŒæŒ‰æ—¶é—´æ’åº
            segments.sort(key=lambda s: (s['start'], s['end']))
            
            self.gpx_data = {'segments': segments, 'name': name, 'start_time': gpx_start_time}
            
            # ç”Ÿæˆå…¨é‡è½¨è¿¹ç¼©ç•¥å›¾ (å§‹ç»ˆæ˜¾ç¤ºå®Œæ•´è½¨è¿¹)
            all_points = []
            for seg in segments:
                all_points.append((seg['lat_start'], seg['lon_start']))
            # æ·»åŠ æœ€åä¸€ç‚¹
            if segments:
                all_points.append((segments[-1]['lat_end'], segments[-1]['lon_end']))
                
            self.track_thumbnail, self.track_transform = self.generate_track_thumbnail(all_points)
            
            self.update_status(f"å·²åŠ è½½GPXæ•°æ®: {name}")
            
            # å¦‚æœæš‚åœçŠ¶æ€ï¼Œåˆ·æ–°å½“å‰å¸§ä»¥æ˜¾ç¤ºå åŠ å±‚
            if not self.playing and self.cap:
                self.seek_to_frame(self.current_frame_pos)
            
            # æ›´æ–°å¯¹é½é¡µæ§ä»¶
            if hasattr(self, 'update_align_controls'):
                self.update_align_controls()
            
        except Exception as e:
            print(f"GPXåŠ è½½å¤±è´¥: {e}")
            self.update_status(f"GPXåŠ è½½å¤±è´¥: {e}")

    def _parse_gpx_file(self, gpx_path):
        """è§£æGPXæ–‡ä»¶"""
        try:
            dom = xml.dom.minidom.parse(gpx_path)
            gpx = dom.documentElement
            
            # è·å–åç§°
            name = "Unknown"
            trk = gpx.getElementsByTagName('trk')
            if trk:
                name_nodes = trk[0].getElementsByTagName('name')
                if name_nodes and name_nodes[0].firstChild:
                    name = name_nodes[0].firstChild.data
            
            points = []
            
            # è§£æè½¨è¿¹ç‚¹
            trkpts = gpx.getElementsByTagName('trkpt')
            for trkpt in trkpts:
                lat = float(trkpt.getAttribute('lat'))
                lon = float(trkpt.getAttribute('lon'))
                
                ele = 0.0
                ele_nodes = trkpt.getElementsByTagName('ele')
                if ele_nodes and ele_nodes[0].firstChild:
                    ele = float(ele_nodes[0].firstChild.data)
                
                time_obj = None
                time_nodes = trkpt.getElementsByTagName('time')
                if time_nodes and time_nodes[0].firstChild:
                    time_str = time_nodes[0].firstChild.data
                    time_obj = self._parse_time(time_str)
                
                hr = 0
                spd_kph = None
                # å°è¯•è·å–å¿ƒç‡
                extensions = trkpt.getElementsByTagName('extensions')
                if extensions:
                    # å°è¯•å¤šç§å¸¸è§çš„å‘½åç©ºé—´
                    for tag in ['gpxtpx:hr', 'ns3:hr', 'hr']:
                        hr_nodes = extensions[0].getElementsByTagName(tag)
                        if hr_nodes and hr_nodes[0].firstChild:
                            hr = int(hr_nodes[0].firstChild.data)
                            break
                    # å°è¯•é€Ÿåº¦ (å•ä½å¤šä¸º m/s)
                    for tag in ['gpxtpx:speed', 'ns3:speed', 'speed']:
                        sp_nodes = extensions[0].getElementsByTagName(tag)
                        if sp_nodes and sp_nodes[0].firstChild:
                            try:
                                sp_mps = float(sp_nodes[0].firstChild.data)
                                spd_kph = sp_mps * 3.6
                            except:
                                pass
                            break
                
                # points: (lat, lon, ele, time, hr, opt_speed_kph)
                points.append((lat, lon, ele, time_obj, hr, spd_kph))
            
            if not points:
                return None, None, None
                
            # è¿‡æ»¤æ‰æ— æ•ˆæ—¶é—´ç‚¹
            points = [p for p in points if p[3] is not None]
            
            if not points:
                return None, None, None

            start_time = points[0][3]
            return points, name, start_time
            
        except Exception as e:
            print(f"è§£æGPXå‡ºé”™: {e}")
            return None, None, None

    def _parse_time(self, t_str):
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼Œç»Ÿä¸€è¿”å› UTC datetime"""
        if not t_str: return None
        
        # ç»Ÿä¸€å¤„ç† Z å’Œ T
        t_str = t_str.replace('Z', '').replace('T', ' ')
        
        # å¤„ç†æ—¶åŒºåç§» (ç®€å•å»æ‰ +08:00 ç­‰ï¼Œå‡å®šä¸º UTC)
        if '+' in t_str:
            t_str = t_str.split('+')[0]
        
        dt = None
        try:
            if '.' in t_str:
                main_part, frac_part = t_str.split('.')
                if len(frac_part) > 6:
                    frac_part = frac_part[:6]
                t_str = f"{main_part}.{frac_part}"
                dt = datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S.%f')
            else:
                dt = datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S')
        except:
            try:
                 dt = datetime.strptime(t_str.split('.')[0], '%Y-%m-%d %H:%M:%S')
            except:
                return None
        
        # å‡å®šè§£æå‡ºæ¥çš„æ˜¯ UTC æ—¶é—´ (naive)
        return dt

    def _calculate_speeds(self, points):
        """è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„é€Ÿåº¦ (km/h)
        ä¼˜å…ˆä½¿ç”¨ GPX æ‰©å±•ä¸­æä¾›çš„é€Ÿåº¦(è‹¥å­˜åœ¨ï¼Œå–ç›¸é‚»ä¸¤ç‚¹é€Ÿåº¦çš„å¹³å‡å€¼)ï¼Œå¦åˆ™å›é€€ä¸ºè·ç¦»/æ—¶é—´è®¡ç®—
        å¹¶åšè½»åº¦å¹³æ»‘
        """
        speeds = []
        # ç®€å•è®¡ç®—æ¯ä¸¤ç‚¹é—´çš„é€Ÿåº¦
        raw_speeds = []
        for i in range(len(points) - 1):
            p1 = points[i]
            p2 = points[i+1]
            
            # ä¼˜å…ˆä½¿ç”¨æ‰©å±•é€Ÿåº¦
            s1 = p1[5] if len(p1) > 5 else None
            s2 = p2[5] if len(p2) > 5 else None
            if s1 is not None and s2 is not None and s1 > 0 and s2 > 0:
                speed_kph = (s1 + s2) / 2.0
            else:
                dist = self._haversine_distance(p1[0], p1[1], p2[0], p2[1])
                time_diff = (p2[3] - p1[3]).total_seconds()
                if time_diff > 0:
                    speed_kph = (dist / time_diff) * 3.6
                else:
                    speed_kph = 0
            raw_speeds.append(speed_kph)
        
        # å¹³æ»‘å¤„ç† (ç§»åŠ¨å¹³å‡)
        if len(raw_speeds) > 0:
            # ä½¿ç”¨æ›´å°çš„çª—å£ï¼Œä¿ç•™åŠ é€Ÿ/ä¸‹å¡å³°å€¼
            window_size = 3
            for i in range(len(raw_speeds)):
                start = max(0, i - window_size // 2)
                end = min(len(raw_speeds), i + window_size // 2 + 1)
                speeds.append(sum(raw_speeds[start:end]) / (end - start))
            return speeds
            
        return []

    def _haversine_distance(self, lat1, lon1, lat2, lon2):
        """è®¡ç®—ä¸¤ç‚¹é—´çš„è·ç¦» (ç±³)"""
        R = 6371000
        phi1 = math.radians(lat1)
        phi2 = math.radians(lat2)
        delta_phi = math.radians(lat2 - lat1)
        delta_lambda = math.radians(lon2 - lon1)
        
        a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
        return R * c

    def _get_video_creation_time(self, video_path):
        """è·å–è§†é¢‘åˆ›å»ºæ—¶é—´ (å°è¯•è¿”å› UTC æ—¶é—´)"""
        creation_time = None
        method = "Unknown"
        
        # 1. å°è¯•ä½¿ç”¨ ffprobe è·å–å…ƒæ•°æ® (JSON)
        ffprobe_cmd = self._get_ffprobe_cmd()
        if ffprobe_cmd:
            try:
                cmd = ffprobe_cmd + [
                    '-v', 'quiet',
                    '-print_format', 'json',
                    '-show_format',
                    '-show_streams',
                    video_path
                ]
                
                startupinfo = None
                if platform.system() == 'Windows':
                    startupinfo = subprocess.STARTUPINFO()
                    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                    
                output = subprocess.check_output(cmd, startupinfo=startupinfo).decode('utf-8')
                data = json.loads(output)
                
                # Check format tags
                if 'format' in data and 'tags' in data['format']:
                    tags = data['format']['tags']
                    if 'creation_time' in tags:
                        creation_time = self._parse_iso8601(tags['creation_time'])
                        if creation_time:
                            method = "FFprobe Metadata (JSON)"
                
                # Check stream tags (first video stream) if not found yet
                if not creation_time:
                    for stream in data.get('streams', []):
                        if stream.get('codec_type') == 'video':
                            if 'tags' in stream and 'creation_time' in stream['tags']:
                                 creation_time = self._parse_iso8601(stream['tags']['creation_time'])
                                 if creation_time:
                                     method = "FFprobe Stream Metadata (JSON)"
                                     break
            except Exception as e:
                print(f"ffprobe JSONè·å–æ—¶é—´å¤±è´¥: {e}")

        # 2. å¦‚æœå…ƒæ•°æ®è·å–å¤±è´¥ï¼Œå›é€€åˆ°æ–‡ä»¶ç³»ç»Ÿæ—¶é—´
        if not creation_time:
            try:
                # ä¼˜å…ˆä½¿ç”¨ä¿®æ”¹æ—¶é—´ (mtime)ï¼Œå› ä¸ºå®ƒåœ¨å¤åˆ¶æ—¶é€šå¸¸ä¿æŒä¸å˜
                mtime = os.path.getmtime(video_path)
                # è½¬æ¢ä¸º UTC æ—¶é—´ (Naive)
                # datetime.utcfromtimestamp is deprecated
                creation_time = datetime.fromtimestamp(mtime, timezone.utc).replace(tzinfo=None)
                method = "File System MTime (UTC)"
            except:
                pass
            
        print(f"è§†é¢‘æ—¶é—´æ£€æµ‹ç»“æœ: {creation_time} (Method: {method})")
        return creation_time, method

    def generate_track_thumbnail(self, points):
        """ç”Ÿæˆè½¨è¿¹ç¼©ç•¥å›¾"""
        if not points:
            return None, None
            
        lats = np.array([p[0] for p in points])
        lons = np.array([p[1] for p in points])
        
        # æ•°æ®å¹³æ»‘ (ç§»åŠ¨å¹³å‡)
        if len(points) > 10:
            window_size = min(len(points) // 5, 20) # åŠ¨æ€çª—å£å¤§å°ï¼Œæœ€å¤§20
            if window_size > 2:
                kernel = np.ones(window_size) / window_size
                # ä½¿ç”¨ 'valid' æ¨¡å¼ä¼šå‡å°‘ç‚¹æ•°ï¼Œä½¿ç”¨ 'same' æ¨¡å¼è¾¹ç¼˜ä¼šæœ‰è¯¯å·®
                # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ pad æ¨¡å¼æ¥ä¿æŒç‚¹æ•°å¹¶å‡å°‘è¾¹ç¼˜æ•ˆåº”
                lats = np.convolve(np.pad(lats, (window_size//2, window_size//2), mode='edge'), kernel, mode='valid')
                lons = np.convolve(np.pad(lons, (window_size//2, window_size//2), mode='edge'), kernel, mode='valid')
        
        min_lat, max_lat = np.min(lats), np.max(lats)
        min_lon, max_lon = np.min(lons), np.max(lons)
        
        # ç¼©ç•¥å›¾å°ºå¯¸
        w, h = 200, 150
        padding = 10
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ (å¼•å…¥åœ°ç†æ ¡æ­£)
        mid_lat = np.radians((min_lat + max_lat) / 2)
        lon_correction = np.cos(mid_lat)
        
        lat_range = max_lat - min_lat
        lon_range = (max_lon - min_lon) * lon_correction
        
        if lat_range == 0 or lon_range == 0:
            return None, None
            
        # ä¿æŒæ¯”ä¾‹
        scale_x = (w - 2 * padding) / lon_range
        scale_y = (h - 2 * padding) / lat_range
        scale = min(scale_x, scale_y)
        
        # åˆ›å»ºç©ºç™½å›¾åƒ (BGRA) - ä½¿ç”¨é€æ˜èƒŒæ™¯
        thumbnail = np.zeros((h, w, 4), dtype=np.uint8)
        # åŠé€æ˜èƒŒæ™¯ (ç°è‰², alpha=100)
        thumbnail[:] = [50, 50, 50, 100]
        
        # è½¬æ¢åæ ‡ç‚¹
        pts = []
        for lat, lon in zip(lats, lons):
            x = int(padding + (lon - min_lon) * lon_correction * scale)
            y = int(h - padding - (lat - min_lat) * scale) # çº¬åº¦è¶Šé«˜yè¶Šå°
            pts.append([x, y])
            
        pts = np.array(pts, np.int32)
        pts = pts.reshape((-1, 1, 2))
        
        # ç»˜åˆ¶è½¨è¿¹ (ç™½è‰²)
        cv2.polylines(thumbnail, [pts], False, (255, 255, 255, 255), 2, cv2.LINE_AA)
        
        # ç»˜åˆ¶èµ·ç‚¹(ç»¿è‰²)å’Œç»ˆç‚¹(çº¢è‰²)
        start_pt = tuple(pts[0][0])
        end_pt = tuple(pts[-1][0])
        cv2.circle(thumbnail, start_pt, 4, (0, 255, 0, 255), -1)
        cv2.circle(thumbnail, end_pt, 4, (0, 0, 255, 255), -1)
        
        return thumbnail, (min_lat, min_lon, scale, h, padding, lon_correction)

    def update_track_thumbnail_by_offset(self):
        """ä¸å†æ ¹æ®offsetæ›´æ–°ç¼©ç•¥å›¾ï¼Œæ”¹ä¸ºå§‹ç»ˆæ˜¾ç¤ºå…¨é‡è½¨è¿¹"""
        # å·²æ”¹ä¸ºåœ¨ load_gpx_data ä¸­ç”Ÿæˆå…¨é‡è½¨è¿¹ç¼©ç•¥å›¾
        pass


    def draw_speed_gauge(self, frame, speed, max_speed=60, center=None, radius=60):
        """ç»˜åˆ¶æ¨¡æ‹Ÿé€Ÿåº¦è¡¨ç›˜"""
        if center is None:
            h, w = frame.shape[:2]
            center = (w - radius - 30, h - radius - 30)
        
        x, y = center
        
        # 1. ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.circle(overlay, center, radius, (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)
        
        # 2. ç»˜åˆ¶å¤–åœˆ (ä»135åº¦åˆ°405åº¦ï¼Œå…±270åº¦)
        start_angle = 135
        end_angle = 405
        total_angle = 270
        
        # ç»˜åˆ¶åˆ»åº¦
        # å¤§åˆ»åº¦ï¼šæ¯10km/hä¸€ä¸ª
        for i in range(0, max_speed + 1, 10):
            angle = start_angle + (i / max_speed) * total_angle
            angle_rad = math.radians(angle)
            
            # å¤§åˆ»åº¦çº¿
            p1_x = int(x + (radius - 15) * math.cos(angle_rad))
            p1_y = int(y + (radius - 15) * math.sin(angle_rad))
            p2_x = int(x + radius * math.cos(angle_rad))
            p2_y = int(y + radius * math.sin(angle_rad))
            
            cv2.line(frame, (p1_x, p1_y), (p2_x, p2_y), (255, 255, 255), 2)
            
            # æ•°å­—
            if i % 20 == 0: # æ¯20æ˜¾ç¤ºæ•°å­—
                text_x = int(x + (radius - 30) * math.cos(angle_rad))
                text_y = int(y + (radius - 30) * math.sin(angle_rad))
                
                # ç®€å•åç§»ä¿®æ­£æ–‡å­—å±…ä¸­
                text_x -= 8
                text_y += 5
                
                cv2.putText(frame, str(i), (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

        # 3. ç»˜åˆ¶æŒ‡é’ˆ
        # é™åˆ¶é€Ÿåº¦åœ¨0-max_speedä¹‹é—´
        disp_speed = max(0, min(speed, max_speed))
        needle_angle = start_angle + (disp_speed / max_speed) * total_angle
        needle_rad = math.radians(needle_angle)
        
        needle_len = radius - 10
        needle_x = int(x + needle_len * math.cos(needle_rad))
        needle_y = int(y + needle_len * math.sin(needle_rad))
        
        cv2.line(frame, center, (needle_x, needle_y), (0, 0, 255), 3)
        
        # 4. ä¸­å¿ƒåœ†ç‚¹
        cv2.circle(frame, center, 5, (255, 0, 0), -1)
        cv2.circle(frame, center, 3, (200, 200, 200), -1)
        
        # 5. æ˜¾ç¤ºå½“å‰æ•°å­—é€Ÿåº¦ (åœ¨ä¸‹æ–¹)
        text_speed = f"{speed:.1f}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        text_size = cv2.getTextSize(text_speed, font, 0.8, 2)[0]
        
        # åœ¨è¡¨ç›˜ä¸‹æ–¹ä¸­å¿ƒ
        tx = x - text_size[0] // 2
        ty = y + radius // 2 + 10
        
        cv2.putText(frame, text_speed, (tx, ty), font, 0.8, (255, 255, 255), 2)
        
        # å•ä½
        cv2.putText(frame, "km/h", (x - 15, y + radius // 2 + 25), font, 0.4, (200, 200, 200), 1)

    def get_data_at_time(self, current_seconds):
        """è·å–æŒ‡å®šæ—¶é—´ç‚¹çš„GPXæ•°æ®ï¼ˆé€Ÿåº¦ã€å¿ƒç‡ã€ç»åº¦ã€çº¬åº¦ï¼‰"""
        if not self.gpx_data:
            self.debug_info = {'status': 'No Data'}
            return 0.0, 0, None, None
            
        # ä»…å¤„ç† GPX æ®µç»“æ„
        if isinstance(self.gpx_data, dict) and 'segments' in self.gpx_data:
            segments = self.gpx_data['segments']
            if not segments:
                return 0.0, 0, None, None
            
            # åº”ç”¨æ—¶é—´åç§»
            target_time = current_seconds + self.gpx_offset
            
            self.debug_info['target_time'] = target_time
            self.debug_info['offset'] = self.gpx_offset
            
            # äºŒåˆ†æŸ¥æ‰¾
            low = 0
            high = len(segments) - 1
            
            while low <= high:
                mid = (low + high) // 2
                seg = segments[mid]
                if seg['start'] <= target_time <= seg['end']:
                    # çº¿æ€§æ’å€¼è®¡ç®—åæ ‡
                    duration = seg['end'] - seg['start']
                    ratio = 0.0
                    if duration > 0.001:
                        ratio = (target_time - seg['start']) / duration
                        lat = seg['lat_start'] + (seg['lat_end'] - seg['lat_start']) * ratio
                        lon = seg['lon_start'] + (seg['lon_end'] - seg['lon_start']) * ratio
                    else:
                        lat = seg['lat_start']
                        lon = seg['lon_start']
                    
                    self.debug_info['seg_idx'] = mid
                    self.debug_info['seg_start'] = seg['start']
                    self.debug_info['seg_end'] = seg['end']
                    self.debug_info['ratio'] = ratio
                    self.debug_info['lat'] = lat
                    self.debug_info['lon'] = lon
                    
                    return seg['speed'], seg.get('hr', 0), lat, lon
                elif seg['start'] > target_time:
                    high = mid - 1
                else:
                    low = mid + 1
                    
            # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œè¿”å›æœ€è¿‘çš„æ•°æ®æˆ–è€…é»˜è®¤å€¼
            if target_time < segments[0]['start']:
                s = segments[0]
                self.debug_info['status'] = 'Before Start'
                self.debug_info['seg_idx'] = 0
                self.debug_info['lat'] = s.get('lat_start')
                return s['speed'], s.get('hr', 0), s.get('lat_start'), s.get('lon_start')
            if target_time > segments[-1]['end']:
                s = segments[-1]
                self.debug_info['status'] = 'After End'
                self.debug_info['seg_idx'] = len(segments) - 1
                self.debug_info['lat'] = s.get('lat_end')
                return s['speed'], s.get('hr', 0), s.get('lat_end'), s.get('lon_end')
                
            self.debug_info['status'] = 'Not Found'
            return 0.0, 0, None, None
            
        return 0.0, 0, None, None

    def decrease_offset(self, event=None):
        """å‡å°‘GPXæ—¶é—´åç§»"""
        self.gpx_offset -= 1.0
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        # æ›´æ–°ç¼©ç•¥å›¾
        self.update_track_thumbnail_by_offset()
        # åˆ·æ–°å½“å‰å¸§ä»¥æ›´æ–°æ˜¾ç¤º
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)
            
    def increase_offset(self, event=None):
        """å¢åŠ GPXæ—¶é—´åç§»"""
        self.gpx_offset += 1.0
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        # æ›´æ–°ç¼©ç•¥å›¾
        self.update_track_thumbnail_by_offset()
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)

    def decrease_offset_fine(self, event=None):
        """å‡å°‘GPXæ—¶é—´åç§» (0.1s)"""
        self.gpx_offset -= 0.1
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        self.update_track_thumbnail_by_offset()
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)

    def increase_offset_fine(self, event=None):
        """å¢åŠ GPXæ—¶é—´åç§» (0.1s)"""
        self.gpx_offset += 0.1
        self.update_status(f"GPXåç§»: {self.gpx_offset:+.1f}s")
        self.update_track_thumbnail_by_offset()
        if not self.playing:
            self.seek_to_frame(self.current_frame_pos)

    def save_project(self):
        """ä¿å­˜é¡¹ç›®"""
        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜é¡¹ç›®",
            defaultextension=".veproj",
            filetypes=[("è§†é¢‘ç¼–è¾‘é¡¹ç›®", "*.veproj"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            # TODO: ä¿å­˜é¡¹ç›®æ–‡ä»¶
            self.update_status(f"é¡¹ç›®å·²ä¿å­˜: {file_path}")
            messagebox.showinfo("ä¿å­˜æˆåŠŸ", f"é¡¹ç›®å·²ä¿å­˜åˆ°:\n{file_path}")
    
    def open_project(self):
        """æ‰“å¼€é¡¹ç›®"""
        file_path = filedialog.askopenfilename(
            title="æ‰“å¼€é¡¹ç›®",
            filetypes=[("è§†é¢‘ç¼–è¾‘é¡¹ç›®", "*.veproj"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if file_path:
            # TODO: åŠ è½½é¡¹ç›®æ–‡ä»¶
            self.update_status(f"é¡¹ç›®å·²æ‰“å¼€: {file_path}")
    
    def export_video(self):
        """å¯¼å‡ºè§†é¢‘"""
        if not self.video_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="å¯¼å‡ºè§†é¢‘",
            defaultextension=".mp4",
            filetypes=[
                ("MP4è§†é¢‘", "*.mp4"),
                ("AVIè§†é¢‘", "*.avi"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if file_path:
            # ç¦ç”¨ç•Œé¢äº¤äº’
            self.root.config(cursor="watch")
            self.update_status(f"æ­£åœ¨å¯¼å‡ºè§†é¢‘: {file_path}...")
            
            # å¯åŠ¨å¯¼å‡ºçº¿ç¨‹
            threading.Thread(target=self._export_video_worker, args=(file_path,), daemon=True).start()

    def _export_video_worker(self, output_path):
        """è§†é¢‘å¯¼å‡ºå·¥ä½œçº¿ç¨‹"""
        try:
            cap = cv2.VideoCapture(self.video_path)
            if not cap.isOpened():
                raise Exception("æ— æ³•æ‰“å¼€æºè§†é¢‘")
            
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å­˜å‚¨æ— éŸ³é¢‘è§†é¢‘
            temp_video_path = output_path + ".temp.mp4"
            
            # æ ¹æ®æ‰©å±•åé€‰æ‹©ç¼–ç å™¨
            ext = os.path.splitext(output_path)[1].lower()
            if ext == '.avi':
                fourcc = cv2.VideoWriter_fourcc(*'MJPG')
            else:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            
            out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
            
            if not out.isOpened():
                raise Exception("æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘æµ")
            
            processed_frames = 0
            last_update_time = time.time()
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # å åŠ GPX
                if self.gpx_data:
                    current_seconds = processed_frames / fps if fps > 0 else 0
                    self._draw_overlay_on_frame(frame, current_seconds)
                
                out.write(frame)
                
                processed_frames += 1
                
                # æ›´æ–°è¿›åº¦ (æ¯0.5ç§’)
                if time.time() - last_update_time > 0.5:
                    progress = (processed_frames / total_frames) * 100
                    self.root.after(0, self.update_status, f"å¯¼å‡ºä¸­: {progress:.1f}%")
                    last_update_time = time.time()
            
            cap.release()
            out.release()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ ffmpeg
            has_ffmpeg = shutil.which('ffmpeg') is not None
            
            # åˆå¹¶éŸ³é¢‘
            if has_ffmpeg: 
                self.root.after(0, self.update_status, "æ­£åœ¨åˆå¹¶éŸ³é¢‘...")
                try:
                    # ffmpeg -i temp.mp4 -i source.mp4 -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 output.mp4
                    cmd = [
                        'ffmpeg', '-y', '-v', 'error',
                        '-i', temp_video_path,
                        '-i', self.video_path,
                        '-c:v', 'copy',
                        '-c:a', 'aac',
                        '-map', '0:v:0',
                        '-map', '1:a:0',
                        output_path
                    ]
                    
                    startupinfo = None
                    if platform.system() == 'Windows':
                        startupinfo = subprocess.STARTUPINFO()
                        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                        
                    subprocess.check_call(cmd, startupinfo=startupinfo)
                    
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_video_path):
                        os.remove(temp_video_path)
                        
                except Exception as e:
                    print(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
                    # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œä¿ç•™æ— éŸ³é¢‘ç‰ˆæœ¬
                    if os.path.exists(output_path):
                        os.remove(output_path)
                    os.rename(temp_video_path, output_path)
                    self.root.after(0, messagebox.showwarning, "è­¦å‘Š", f"éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå¯¼å‡ºçš„è§†é¢‘å°†æ²¡æœ‰å£°éŸ³ã€‚\né”™è¯¯: {e}")
            else:
                # æ²¡æœ‰ffmpegï¼Œç›´æ¥é‡å‘½å
                if os.path.exists(output_path):
                    os.remove(output_path)
                os.rename(temp_video_path, output_path)
                self.root.after(0, messagebox.showinfo, "æç¤º", "æœªæ£€æµ‹åˆ°FFmpegï¼Œå¯¼å‡ºçš„è§†é¢‘å°†æ²¡æœ‰å£°éŸ³ã€‚")

            self.root.after(0, self.update_status, f"å¯¼å‡ºå®Œæˆ: {output_path}")
            self.root.after(0, messagebox.showinfo, "æˆåŠŸ", "è§†é¢‘å¯¼å‡ºæˆåŠŸï¼")
            
        except Exception as e:
            self.root.after(0, self.update_status, f"å¯¼å‡ºå¤±è´¥: {e}")
            self.root.after(0, messagebox.showerror, "é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
        finally:
            self.root.after(0, self.root.config, {"cursor": ""})
    
    # ============ ç¼–è¾‘åŠŸèƒ½ ============
    
    def undo(self):
        """æ’¤é”€"""
        self.update_status("æ’¤é”€æ“ä½œ")
    
    def redo(self):
        """é‡åš"""
        self.update_status("é‡åšæ“ä½œ")
    
    def cut_clip(self):
        """å‰ªåˆ‡ç‰‡æ®µ"""
        self.update_status("å‰ªåˆ‡ç‰‡æ®µ")
    
    def copy_clip(self):
        """å¤åˆ¶ç‰‡æ®µ"""
        self.update_status("å¤åˆ¶ç‰‡æ®µ")
    
    def paste_clip(self):
        """ç²˜è´´ç‰‡æ®µ"""
        self.update_status("ç²˜è´´ç‰‡æ®µ")
    
    def delete_clip(self):
        """åˆ é™¤ç‰‡æ®µ"""
        selected = self.clip_tree.selection()
        if selected:
            self.clip_tree.delete(selected)
            self.update_status("åˆ é™¤ç‰‡æ®µ")
        else:
            messagebox.showinfo("æç¤º", "è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„ç‰‡æ®µ")
    
    # ============ å‰ªè¾‘åŠŸèƒ½ ============
    
    def split_clip(self):
        """åˆ†å‰²ç‰‡æ®µ"""
        if not self.video_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return
        
        current_time = self.progress_var.get()
        self.update_status(f"åœ¨ {self.format_time(current_time)} å¤„åˆ†å‰²")
        messagebox.showinfo("åˆ†å‰²", "è§†é¢‘åˆ†å‰²åŠŸèƒ½å¾…å®ç°")
    
    def merge_clips(self):
        """åˆå¹¶ç‰‡æ®µ"""
        selected = self.clip_tree.selection()
        if len(selected) < 2:
            messagebox.showinfo("æç¤º", "è¯·è‡³å°‘é€‰æ‹©ä¸¤ä¸ªç‰‡æ®µè¿›è¡Œåˆå¹¶")
            return
        
        self.update_status("åˆå¹¶ç‰‡æ®µ")
        messagebox.showinfo("åˆå¹¶", "ç‰‡æ®µåˆå¹¶åŠŸèƒ½å¾…å®ç°")
    
    def set_in_point(self):
        """è®¾ç½®å…¥ç‚¹"""
        current_time = self.progress_var.get()
        self.update_status(f"è®¾ç½®å…¥ç‚¹: {self.format_time(current_time)}")
    
    def set_out_point(self):
        """è®¾ç½®å‡ºç‚¹"""
        current_time = self.progress_var.get()
        self.update_status(f"è®¾ç½®å‡ºç‚¹: {self.format_time(current_time)}")
    
    def add_transition(self):
        """æ·»åŠ è½¬åœºæ•ˆæœ"""
        messagebox.showinfo("è½¬åœº", "è½¬åœºæ•ˆæœåŠŸèƒ½å¾…å®ç°")
    
    def add_filter(self):
        """æ·»åŠ æ»¤é•œ"""
        messagebox.showinfo("æ»¤é•œ", "æ»¤é•œåŠŸèƒ½å¾…å®ç°")
    
    # ============ æ’­æ”¾æ§åˆ¶ ============
    
    def toggle_play(self):
        """æ’­æ”¾/æš‚åœ"""
        if not self.video_path or self.cap is None:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½è§†é¢‘æ–‡ä»¶ï¼")
            return
        
        if not HAS_CV2:
            messagebox.showwarning("è­¦å‘Š", "æœªå®‰è£… opencv-pythonï¼Œæ— æ³•æ’­æ”¾è§†é¢‘ï¼")
            return
        
        if not self.playing:
            # å¼€å§‹æ’­æ”¾
            self.playing = True
            self.play_btn['text'] = "â¸ æš‚åœ"
            self.update_status("æ’­æ”¾ä¸­...")
            self.start_audio_playback(self._current_time())
            
            # å¯åŠ¨æ’­æ”¾çº¿ç¨‹
            if self.play_thread is None or not self.play_thread.is_alive():
                self.play_thread = threading.Thread(target=self._play_video_loop, daemon=True)
                self.play_thread.start()
        else:
            # æš‚åœæ’­æ”¾
            self.playing = False
            self.play_btn['text'] = "â–¶ æ’­æ”¾"
            self.update_status("å·²æš‚åœ")
            self.stop_audio_playback()
    
    def _has_ffplay(self):
        return shutil.which('ffplay') is not None
    
    def _current_time(self):
        fps = self.video_info.get('fps', 30.0)
        return self.current_frame_pos / fps if fps > 0 else 0
    
    def start_audio_playback(self, start_time=None):
        if self.is_muted or self.volume <= 0:
            return
        if not self._has_ffplay():
            return
        if start_time is None:
            start_time = self._current_time()
        try:
            self.stop_audio_playback()
            vol = max(0, min(100, int(self.volume * 100)))
            spd = self.playback_speed
            if spd < 0.5:
                spd = 0.5
            elif spd > 2.0:
                spd = 2.0
            cmd = [
                'ffplay',
                '-nodisp',
                '-autoexit',
                '-loglevel', 'error',
                '-ss', f'{start_time:.3f}',
                '-i', self.video_path,
                '-volume', str(vol),
                '-af', f'atempo={spd}'
            ]
            if platform.system() == 'Windows':
                creationflags = getattr(subprocess, 'CREATE_NEW_PROCESS_GROUP', 0)
                self.audio_proc = subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, creationflags=creationflags)
            else:
                self.audio_proc = subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, start_new_session=True)
        except Exception:
            self.audio_proc = None
    
    def stop_audio_playback(self):
        if self.audio_proc is not None:
            try:
                if platform.system() == 'Windows':
                    self.audio_proc.terminate()
                else:
                    try:
                        os.killpg(self.audio_proc.pid, signal.SIGTERM)
                    except Exception:
                        self.audio_proc.terminate()
                try:
                    self.audio_proc.wait(timeout=0.5)
                except Exception:
                    pass
                if self.audio_proc.poll() is None:
                    if platform.system() != 'Windows':
                        try:
                            os.killpg(self.audio_proc.pid, signal.SIGKILL)
                        except Exception:
                            self.audio_proc.kill()
                    else:
                        self.audio_proc.kill()
            except Exception:
                pass
            self.audio_proc = None
    
    def _play_video_loop(self):
        """è§†é¢‘æ’­æ”¾å¾ªç¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        if self.cap is None:
            return
            
        fps = self.video_info.get('fps', 30.0)
        # ç›®æ ‡å¸§é—´éš”
        target_interval = 1.0 / (fps * self.playback_speed)
        
        last_frame_time = time.time()
        
        # è®°å½•ä¸Šä¸€å¸§çš„æ˜¾ç¤ºæ—¶é—´ï¼Œç”¨äºè®¡ç®—å»¶è¿Ÿ
        last_display_time = time.time()
        
        while self.playing and self.cap is not None:
            loop_start_time = time.time()
            
            # 1. è¯»å–ä¸‹ä¸€å¸§
            ret, frame = self.cap.read()
            
            if not ret:
                # æ’­æ”¾ç»“æŸ
                self.playing = False
                # åœ¨ä¸»çº¿ç¨‹æ›´æ–°UI
                self.root.after(0, lambda: self.play_btn.config(text="â–¶ æ’­æ”¾"))
                self.root.after(0, lambda: self.update_status("æ’­æ”¾å®Œæˆ"))
                self.stop_audio_playback()
                break
            
            self.current_frame_pos = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
            
            # 2. åªæœ‰å½“è·ç¦»ä¸Šæ¬¡æ˜¾ç¤ºè¶…è¿‡ä¸€å®šé—´éš”æ—¶æ‰æ›´æ–°UIï¼ˆé¿å…è¿‡åº¦åˆ·æ–°ï¼‰
            # é™åˆ¶æœ€é«˜åˆ·æ–°ç‡ä¸º 30fpsï¼Œæˆ–è€…åŸè§†é¢‘å¸§ç‡ï¼ˆå–è¾ƒå°å€¼ï¼‰
            current_time = time.time()
            if current_time - last_display_time >= 0.033: # çº¦30fps
                # å¤åˆ¶å¸§æ•°æ®ä¼ é€’ç»™UIçº¿ç¨‹ï¼Œé¿å…å†²çª
                display_frame = frame.copy()
                self.root.after(0, self._display_frame, display_frame)
                
                # æ›´æ–°è¿›åº¦æ¡ (æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹åˆ·æ–°)
                if current_time - last_display_time > 0.5:
                    current_video_time = self.current_frame_pos / fps if fps > 0 else 0
                    self.root.after(0, self.progress_var.set, current_video_time)
                    self.root.after(0, self._update_time_display, current_video_time)
                
                last_display_time = current_time
            
            # 3. å¸§ç‡æ§åˆ¶
            process_time = time.time() - loop_start_time
            sleep_time = target_interval - process_time
            
            if sleep_time > 0:
                time.sleep(sleep_time)
            else:
                # å¦‚æœå¤„ç†å¤ªæ…¢ï¼Œä¸éœ€è¦sleepï¼Œç”šè‡³å¯èƒ½éœ€è¦è·³å¸§ï¼ˆè¿™é‡Œæš‚ä¸å®ç°è·³å¸§ï¼‰
                pass
    
    def _display_frame(self, frame):
        """æ˜¾ç¤ºè§†é¢‘å¸§"""
        if frame is None:
            return
            
        # å åŠ GPXä¿¡æ¯
        if self.gpx_data:
            fps = self.video_info.get('fps', 30.0)
            current_seconds = self.current_frame_pos / fps if fps > 0 else 0
            self._draw_overlay_on_frame(frame, current_seconds)
            
        # è°ƒæ•´å¤§å°ä»¥é€‚åº”ç”»å¸ƒ
        canvas_width = self.video_canvas.winfo_width()
        canvas_height = self.video_canvas.winfo_height()
        
        if canvas_width <= 1 or canvas_height <= 1:
            canvas_width = 640
            canvas_height = 360
            
        # ä¿æŒå®½é«˜æ¯”
        img_h, img_w = frame.shape[:2]
        
        # ä¼˜åŒ–ï¼šå¦‚æœå›¾åƒå°ºå¯¸ä¸ç”»å¸ƒå·®å¼‚ä¸å¤§ï¼Œä¸ç¼©æ”¾
        if abs(img_w - canvas_width) > 10 or abs(img_h - canvas_height) > 10:
            ratio = min(canvas_width / img_w, canvas_height / img_h)
            new_w = int(img_w * ratio)
            new_h = int(img_h * ratio)
            resized_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        else:
            resized_frame = frame
        
        # è½¬æ¢ä¸º RGB
        rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
        
        # è½¬æ¢ä¸º ImageTk
        img = Image.fromarray(rgb_frame)
        photo = ImageTk.PhotoImage(image=img)
        
        # æ›´æ–°ç”»å¸ƒ
        self.video_canvas.delete("all")
        # å±…ä¸­æ˜¾ç¤º
        x_center = canvas_width // 2
        y_center = canvas_height // 2
        self.video_canvas.create_image(x_center, y_center, image=photo, anchor=tk.CENTER)
        self.video_canvas.image = photo # ä¿æŒå¼•ç”¨é˜²æ­¢è¢«åƒåœ¾å›æ”¶
    
    def _draw_overlay_on_frame(self, frame, current_seconds):
        """åœ¨å¸§ä¸Šç»˜åˆ¶GPXå åŠ å±‚"""
        if not self.gpx_data:
            return

        speed, hr, lat, lon = self.get_data_at_time(current_seconds)
        h, w = frame.shape[:2]
        
        # 1. ç»˜åˆ¶è½¨è¿¹ç¼©ç•¥å›¾ (å³ä¸Šè§’)
        if self.track_thumbnail is not None and self.track_transform is not None:
            thumb_h, thumb_w = self.track_thumbnail.shape[:2]
            
            # ç¡®ä¿ç¼©ç•¥å›¾ä¸æ¯”è§†é¢‘å¤§ä¸”ä½ç½®åˆç†
            if thumb_h < h and thumb_w < w:
                # ä½ç½®ï¼šå³ä¸Šè§’ï¼Œè¾¹è·20
                x_offset = w - thumb_w - 20
                y_offset = 20
                
                # æå–ROI
                roi = frame[y_offset:y_offset+thumb_h, x_offset:x_offset+thumb_w]
                
                # Alphaæ··åˆ
                thumb_bgr = self.track_thumbnail[:, :, :3]
                thumb_alpha = self.track_thumbnail[:, :, 3] / 255.0
                thumb_alpha_3ch = cv2.merge([thumb_alpha, thumb_alpha, thumb_alpha])
                
                blended = (thumb_bgr * thumb_alpha_3ch + roi * (1.0 - thumb_alpha_3ch)).astype(np.uint8)
                frame[y_offset:y_offset+thumb_h, x_offset:x_offset+thumb_w] = blended
                
                # ç»˜åˆ¶å½“å‰ä½ç½® (é—ªçƒè“ç‚¹)
                if lat is not None and lon is not None:
                    # è§£åŒ…å˜æ¢å‚æ•° (æ”¯æŒæ—§ç‰ˆå’Œæ–°ç‰ˆ)
                    if len(self.track_transform) == 5:
                        min_lat, min_lon, scale, t_h, padding = self.track_transform
                        lon_correction = 1.0
                    else:
                        min_lat, min_lon, scale, t_h, padding, lon_correction = self.track_transform
                    
                    # è®¡ç®—åæ ‡
                    pt_x = int(padding + (lon - min_lon) * lon_correction * scale)
                    pt_y = int(t_h - padding - (lat - min_lat) * scale)
                    
                    # è½¬æ¢ä¸ºå±å¹•åæ ‡
                    screen_x = x_offset + pt_x
                    screen_y = y_offset + pt_y
                    
                    # é—ªçƒæ•ˆæœ (æ¯ç§’é—ªçƒçº¦2æ¬¡)
                    if int(time.time() * 4) % 2 == 0:
                        cv2.circle(frame, (screen_x, screen_y), 6, (255, 0, 0), -1) # è“è‰²å®å¿ƒåœ†
                        cv2.circle(frame, (screen_x, screen_y), 8, (255, 255, 255), 1) # ç™½è‰²æè¾¹

        # 2. ç»˜åˆ¶é€Ÿåº¦è¡¨ç›˜
        gauge_radius = 70
        gauge_center = (w - gauge_radius - 20, h - gauge_radius - 20)
        self.draw_speed_gauge(frame, speed, max_speed=60, center=gauge_center, radius=gauge_radius)
        
        # 3. æ·»åŠ æ–‡å­— (å¿ƒç‡) - å¦‚æœæœ‰å¿ƒç‡æ•°æ®
        if hr > 0:
            text_hr = f"{hr} bpm"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = max(0.5, w / 1000.0)
            thickness = max(1, int(font_scale * 2))
            
            text_size_hr = cv2.getTextSize(text_hr, font, font_scale, thickness)[0]
            # æ˜¾ç¤ºåœ¨è¡¨ç›˜ä¸Šæ–¹ä¸­å¿ƒ
            text_x_hr = gauge_center[0] - text_size_hr[0] // 2
            text_y_hr = gauge_center[1] - gauge_radius - 15
            
            cv2.putText(frame, text_hr, (text_x_hr, text_y_hr), font, font_scale, (0, 0, 0), thickness + 2)
            cv2.putText(frame, text_hr, (text_x_hr, text_y_hr), font, font_scale, (0, 0, 255), thickness)
            
            # æ·»åŠ å¿ƒå½¢å›¾æ ‡ (ç®€å•çš„åœ†)
            cv2.circle(frame, (text_x_hr - 15, text_y_hr - 5), 6, (0, 0, 255), -1)

        # 4. æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ (å§‹ç»ˆæ˜¾ç¤ºåœ¨å·¦ä¸Šè§’)
        debug_y = 40
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = max(0.5, w / 1000.0)
        thickness = max(1, int(font_scale * 2))
        
        # å¦‚æœæœ‰åç§»ï¼Œä¼˜å…ˆæ˜¾ç¤º
        if abs(self.gpx_offset) > 0.1:
            text_offset = f"Offset: {self.gpx_offset:+.1f}s"
            cv2.putText(frame, text_offset, (20, debug_y), font, font_scale * 0.8, (0, 0, 0), thickness + 2)
            cv2.putText(frame, text_offset, (20, debug_y), font, font_scale * 0.8, (255, 255, 0), thickness)
            debug_y += 30
        
        if self.debug_info:
            for k, v in self.debug_info.items():
                # è·³è¿‡å·²ç»æ˜¾ç¤ºçš„offset
                if k == 'offset': continue
                
                if isinstance(v, float):
                    text = f"{k}: {v:.3f}"
                else:
                    text = f"{k}: {v}"
                
                # é»‘è‰²æè¾¹
                cv2.putText(frame, text, (20, debug_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 4)
                # çº¢è‰²æ–‡å­—
                cv2.putText(frame, text, (20, debug_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                debug_y += 25

    def _update_time_display(self, current_time):
        """æ›´æ–°æ—¶é—´æ˜¾ç¤ºï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­è°ƒç”¨ï¼‰"""
        duration = self.video_info.get('duration', 0)
        self.time_label.config(text=f"{self.format_time(current_time)} / {self.format_time(duration)}")
        
        # æ›´æ–°æ’­æ”¾å¤´ä½ç½®
        self.draw_playhead(current_time)
    
    def seek_to_frame(self, frame_number):
        """è·³è½¬åˆ°æŒ‡å®šå¸§"""
        if self.cap is None:
            return
        
        try:
            # ç¡®ä¿å¸§æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
            frame_number = max(0, min(frame_number, max(0, self.total_frames - 1)))
            
            # å°è¯•è®¾ç½®å¸§ä½ç½®
            success = self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            
            if not success:
                # å¦‚æœç›´æ¥è®¾ç½®å¤±è´¥ï¼Œå°è¯•ä»å¼€å¤´è¯»å–åˆ°ç›®æ ‡ä½ç½®
                self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                for _ in range(frame_number):
                    ret, _ = self.cap.read()
                    if not ret:
                        break
            
            self.current_frame_pos = frame_number
            
            # è¯»å–å¹¶æ˜¾ç¤ºè¯¥å¸§
            ret, frame = self.cap.read()
            if ret and frame is not None:
                self._display_frame(frame)
                
                # æ›´æ–°è¿›åº¦æ¡
                fps = self.video_info.get('fps', 30.0)
                current_time = frame_number / fps if fps > 0 else 0
                self.progress_var.set(current_time)
                self._update_time_display(current_time)
            else:
                # å¦‚æœè¯»å–å¤±è´¥ï¼Œå°è¯•æ˜¾ç¤ºä¸€ä¸ªé»‘è‰²å¸§
                width = self.video_info.get('width', 640)
                height = self.video_info.get('height', 480)
                black_frame = np.zeros((height, width, 3), dtype=np.uint8)
                self._display_frame(black_frame)
                
        except Exception as e:
            print(f"è·³è½¬å¸§æ—¶å‡ºé”™: {e}")
            self.update_status(f"è·³è½¬å¸§å¤±è´¥: {str(e)}")
            # å°è¯•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            width = self.video_info.get('width', 640)
            height = self.video_info.get('height', 480)
            error_frame = np.zeros((height, width, 3), dtype=np.uint8)
            # è¿™é‡Œå¯ä»¥æ·»åŠ é”™è¯¯æ–‡æœ¬æ˜¾ç¤º
            self._display_frame(error_frame)
    
    def stop_play(self):
        """åœæ­¢æ’­æ”¾"""
        self.playing = False
        self.play_btn['text'] = "â–¶ æ’­æ”¾"
        if self.cap is not None:
            self.seek_to_frame(0)
        self.update_status("å·²åœæ­¢")
        self.stop_audio_playback()
    
    def prev_frame(self):
        """ä¸Šä¸€å¸§"""
        if self.cap is None:
            return
        
        fps = self.video_info.get('fps', 30.0)
        frame_step = max(1, int(fps * 0.033))  # å¤§çº¦ä¸€å¸§
        new_frame = max(0, self.current_frame_pos - frame_step)
        self.seek_to_frame(new_frame)
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def next_frame(self):
        """ä¸‹ä¸€å¸§"""
        if self.cap is None:
            return
        
        fps = self.video_info.get('fps', 30.0)
        frame_step = max(1, int(fps * 0.033))  # å¤§çº¦ä¸€å¸§
        new_frame = min(self.total_frames - 1, self.current_frame_pos + frame_step)
        self.seek_to_frame(new_frame)
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def jump_to_start(self):
        """è·³è½¬åˆ°å¼€å§‹"""
        if self.cap is not None:
            self.seek_to_frame(0)
        else:
            self.progress_var.set(0)
        self.update_status("è·³è½¬åˆ°å¼€å§‹")
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def jump_to_end(self):
        """è·³è½¬åˆ°ç»“æŸ"""
        if self.cap is not None and self.total_frames > 0:
            self.seek_to_frame(self.total_frames - 1)
        else:
            duration = self.video_info.get('duration', 100)
            self.progress_var.set(duration)
        self.update_status("è·³è½¬åˆ°ç»“æŸ")
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def rewind_5s(self):
        """åé€€5ç§’"""
        if self.cap is not None and self.total_frames > 0:
            current_time = self.current_frame_pos / self.video_info.get('fps', 30.0)
            new_time = max(0, current_time - 5)
            new_frame = int(new_time * self.video_info.get('fps', 30.0))
            self.seek_to_frame(new_frame)
            self.update_status("åé€€5ç§’")
            if self.playing:
                self.stop_audio_playback()
                self.start_audio_playback(self._current_time())
    
    def forward_5s(self):
        """å‰è¿›5ç§’"""
        if self.cap is not None and self.total_frames > 0:
            current_time = self.current_frame_pos / self.video_info.get('fps', 30.0)
            duration = self.video_info.get('duration', 0)
            new_time = min(duration, current_time + 5)
            new_frame = int(new_time * self.video_info.get('fps', 30.0))
            self.seek_to_frame(new_frame)
            self.update_status("å‰è¿›5ç§’")
            if self.playing:
                self.stop_audio_playback()
                self.start_audio_playback(self._current_time())
    
    def toggle_mute(self):
        """åˆ‡æ¢é™éŸ³"""
        self.is_muted = not self.is_muted
        if self.is_muted:
            self.mute_btn.config(text="ğŸ”‡")
            self.volume_scale.set(0)
        else:
            self.mute_btn.config(text="ğŸ”Š")
            self.volume_scale.set(100)
        self.update_status("é™éŸ³" if self.is_muted else "å–æ¶ˆé™éŸ³")
        if self.playing:
            if self.is_muted:
                self.stop_audio_playback()
            else:
                self.stop_audio_playback()
                self.start_audio_playback(self._current_time())
    
    def on_volume_change(self, value):
        """éŸ³é‡æ”¹å˜"""
        self.volume = float(value) / 100.0
        if self.volume == 0:
            self.mute_btn.config(text="ğŸ”‡")
            self.is_muted = True
        else:
            self.mute_btn.config(text="ğŸ”Š")
            self.is_muted = False
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def on_speed_change(self, event):
        """æ’­æ”¾é€Ÿåº¦æ”¹å˜"""
        speed_str = self.speed_var.get()
        self.playback_speed = float(speed_str.replace('x', ''))
        self.update_status(f"æ’­æ”¾é€Ÿåº¦: {speed_str}")
        if self.playing:
            self.stop_audio_playback()
            self.start_audio_playback(self._current_time())
    
    def toggle_loop(self):
        """åˆ‡æ¢å¾ªç¯æ’­æ”¾"""
        self.loop_playback = not self.loop_playback
        status = "å¼€å¯" if self.loop_playback else "å…³é—­"
        self.update_status(f"å¾ªç¯æ’­æ”¾å·²{status}")
    
    def update_clip_list(self):
        """æ›´æ–°å‰ªè¾‘ç‰‡æ®µåˆ—è¡¨"""
        # æ¸…ç©ºç°æœ‰åˆ—è¡¨
        for item in self.clip_tree.get_children():
            self.clip_tree.delete(item)
            
        # æ·»åŠ ç‰‡æ®µ
        fps = self.video_info.get('fps', 30.0)
        for clip in self.clips:
            start_time = clip['start_frame'] / fps
            end_time = clip['end_frame'] / fps
            duration = end_time - start_time
            
            self.clip_tree.insert('', 'end', values=(
                clip['name'],
                self.format_time(start_time),
                self.format_time(end_time),
                f"{duration:.2f}s"
            ))
            
        # æ›´æ–°æ—¶é—´è½´ä¸Šçš„ç‰‡æ®µæ˜¾ç¤º
        self.draw_timeline_tracks()

    def split_clip(self):
        """åˆ†å‰²å½“å‰ç‰‡æ®µ"""
        if not self.video_info or not self.clips:
            return
            
        current_frame = self.current_frame_pos
        
        # æŸ¥æ‰¾å½“å‰æ—¶é—´ç‚¹æ‰€åœ¨çš„ç‰‡æ®µ
        target_clip = None
        target_index = -1
        
        for i, clip in enumerate(self.clips):
            if clip['start_frame'] < current_frame < clip['end_frame']:
                target_clip = clip
                target_index = i
                break
        
        if target_clip:
            # åˆ›å»ºæ–°ç‰‡æ®µ
            new_clip = target_clip.copy()
            new_clip['id'] = f"clip_{len(self.clips)}"
            new_clip['name'] = f"ç‰‡æ®µ_{len(self.clips) + 1}"
            new_clip['start_frame'] = current_frame
            new_clip['end_frame'] = target_clip['end_frame']
            
            # ä¿®æ”¹åŸç‰‡æ®µ
            target_clip['end_frame'] = current_frame
            
            # æ’å…¥æ–°ç‰‡æ®µ
            self.clips.insert(target_index + 1, new_clip)
            
            # æ›´æ–°åˆ—è¡¨
            self.update_clip_list()
            self.update_status(f"å·²åœ¨ {self.format_time(current_frame / self.video_info.get('fps', 30.0))} å¤„åˆ†å‰²ç‰‡æ®µ")
        else:
            self.update_status("å½“å‰ä½ç½®æ— æ³•åˆ†å‰²ï¼ˆä¸åœ¨ä»»ä½•ç‰‡æ®µä¸­é—´ï¼‰")
    
    # ============ UIæ›´æ–°æ–¹æ³• ============
    
    def update_video_info(self):
        """æ›´æ–°è§†é¢‘ä¿¡æ¯æ˜¾ç¤º"""
        if self.video_info:
            info_text = f"""æ–‡ä»¶: {self.video_info.get('name', 'N/A')}
åˆ†è¾¨ç‡: {self.video_info.get('width', 0)}x{self.video_info.get('height', 0)}
å¸§ç‡: {self.video_info.get('fps', 0):.2f} fps
æ—¶é•¿: {self.format_time(self.video_info.get('duration', 0))}
ç¼–ç : {self.video_info.get('codec', 'N/A')}"""
            
            # self.info_text.config(state=tk.NORMAL)
            # self.info_text.delete(1.0, tk.END)
            # self.info_text.insert(1.0, info_text)
            # self.info_text.config(state=tk.DISABLED)
            
            # æ›´æ–°çŠ¶æ€æ 
            self.resolution_label.config(text=f"{self.video_info.get('width', 0)}x{self.video_info.get('height', 0)}")
            self.fps_label.config(text=f"{self.video_info.get('fps', 0):.1f} fps")
            
            # æ›´æ–°è¿›åº¦æ¡æœ€å¤§å€¼
            self.progress_scale.config(to=self.video_info.get('duration', 100))
    
    def update_preview_label(self, text):
        """æ›´æ–°é¢„è§ˆæ ‡ç­¾"""
        if self.preview_label:
            display_text = "" if text is None else str(text)
            if display_text.strip():
                self.preview_label.config(text=display_text)
                self.preview_label.place(relx=0.5, rely=0.5, anchor=tk.CENTER)
            else:
                self.preview_label.config(text="")
                self.preview_label.place_forget()
    
    def update_status(self, message):
        """æ›´æ–°çŠ¶æ€æ """
        self.status_label.config(text=message)
    
    def format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    
    # ============ æ—¶é—´è½´ç›¸å…³ ============
    
    def init_timeline(self):
        """åˆå§‹åŒ–æ—¶é—´è½´"""
        if not self.video_info:
            return
        
        duration = self.video_info.get('duration', 100)
        self.draw_timeline_ruler(duration)
        self.draw_timeline_tracks()
    
    def draw_timeline_ruler(self, duration):
        """ç»˜åˆ¶æ—¶é—´æ ‡å°º"""
        self.ruler_canvas.delete("all")
        
        # è®¡ç®—æ€»å®½åº¦
        total_width = duration * self.timeline_scale
        if total_width < 1:
            total_width = 1
            
        # æ›´æ–°æ»šåŠ¨åŒºåŸŸ
        self.ruler_canvas.config(scrollregion=(0, 0, total_width, 25))
        self.timeline_canvas.config(scrollregion=(0, 0, total_width, 150))
        
        # ç»˜åˆ¶åˆ»åº¦
        # æ ¹æ®ç¼©æ”¾æ¯”ä¾‹å†³å®šåˆ»åº¦é—´éš”
        if self.timeline_scale < 1: # ç¼©å°å¾ˆå¤šï¼Œæ¯10ç§’æˆ–æ›´å¤šä¸€ä¸ªåˆ»åº¦
            step = 60
        elif self.timeline_scale < 5: # æ¯10ç§’
            step = 10
        elif self.timeline_scale < 20: # æ¯5ç§’
            step = 5
        else: # æ¯1ç§’
            step = 1
            
        for second in range(0, int(duration) + 1, step):
            x = second * self.timeline_scale
            self.ruler_canvas.create_line(x, 0, x, 25, fill="#666666", width=1)
            self.ruler_canvas.create_text(x + 2, 12, text=self.format_time(second),
                                         anchor=tk.W, font=("Arial", 8))
    
    def draw_timeline_tracks(self):
        """ç»˜åˆ¶æ—¶é—´è½´è½¨é“"""
        self.timeline_canvas.delete("all")
        
        if not self.video_info:
            return
            
        # ç»˜åˆ¶å‰ªè¾‘ç‰‡æ®µ
        fps = self.video_info.get('fps', 30.0)
        track_height = 40
        track_y = 10
        
        # 1. ç»˜åˆ¶ç¼©ç•¥å›¾èƒŒæ™¯ (å¦‚æœæœ‰)
        has_thumbs = hasattr(self, 'timeline_thumbnails') and self.timeline_thumbnails
        if has_thumbs:
            # éå†æ‰€æœ‰ç¼©ç•¥å›¾
            for t_sec, photo in self.timeline_thumbnails.items():
                x = t_sec * self.timeline_scale
                # ç»˜åˆ¶å›¾ç‰‡ï¼Œå‚ç›´å±…ä¸­äºè½¨é“
                self.timeline_canvas.create_image(x, track_y + track_height/2, image=photo, anchor=tk.W)
        
        for i, clip in enumerate(self.clips):
            start_time = clip['start_frame'] / fps
            end_time = clip['end_frame'] / fps
            
            x1 = start_time * self.timeline_scale
            x2 = end_time * self.timeline_scale
            
            # ç»˜åˆ¶ç‰‡æ®µçŸ©å½¢
            if has_thumbs:
                # å¦‚æœæœ‰ç¼©ç•¥å›¾ï¼Œåªç”»è¾¹æ¡†ï¼Œä»¥ä¾¿çœ‹åˆ°ç¼©ç•¥å›¾
                self.timeline_canvas.create_rectangle(x1, track_y, x2, track_y + track_height,
                                                     fill="", outline="#4a90e2", width=2, tags=("clip", clip['id']))
                # å¢åŠ ä¸€ä¸ªåŠé€æ˜é»‘è‰²é®ç½©æ¥å¢åŠ æ–‡å­—å¯¹æ¯”åº¦ï¼Ÿ(Tkinterä¸æ”¯æŒ)
                # æˆ‘ä»¬å¯ä»¥ç”»æ–‡å­—èƒŒæ™¯
            else:
                # åŸæ¥çš„é€»è¾‘ï¼šå®å¿ƒå¡«å……
                color = "#4a90e2" if i % 2 == 0 else "#357abd"
                self.timeline_canvas.create_rectangle(x1, track_y, x2, track_y + track_height,
                                                     fill=color, outline="white", tags=("clip", clip['id']))
            
            # ç»˜åˆ¶ç‰‡æ®µåç§°
            if x2 - x1 > 20: # å¦‚æœå¤Ÿå®½æ‰æ˜¾ç¤ºæ–‡å­—
                # æ·»åŠ æ–‡å­—é˜´å½±æ•ˆæœä»¥æé«˜å¯è¯»æ€§
                self.timeline_canvas.create_text(x1 + 6, track_y + track_height/2 + 1,
                                                text=clip['name'], anchor=tk.W, fill="black",
                                                font=("Arial", 9))
                self.timeline_canvas.create_text(x1 + 5, track_y + track_height/2,
                                                text=clip['name'], anchor=tk.W, fill="white",
                                                font=("Arial", 9))
    
    def draw_playhead(self, current_time):
        """ç»˜åˆ¶æ’­æ”¾å¤´"""
        self.timeline_canvas.delete("playhead")
        self.ruler_canvas.delete("playhead")
        
        if self.timeline_scale <= 0:
            return
            
        x = current_time * self.timeline_scale
        
        # åœ¨æ ‡å°ºä¸Šç»˜åˆ¶
        self.ruler_canvas.create_line(x, 0, x, 25, fill="red", width=2, tags="playhead")
        # ç»˜åˆ¶å€’ä¸‰è§’æŒ‡ç¤ºå™¨
        self.ruler_canvas.create_polygon(x-4, 0, x+4, 0, x, 8, fill="red", tags="playhead")
        
        # åœ¨è½¨é“ä¸Šç»˜åˆ¶
        height = 150 # ä¼°è®¡é«˜åº¦
        if self.timeline_canvas.winfo_height() > 1:
            height = self.timeline_canvas.winfo_height()
            
        self.timeline_canvas.create_line(x, 0, x, height, fill="red", width=1, tags="playhead")
    
    def on_timeline_click(self, event):
        """æ—¶é—´è½´ç‚¹å‡»/æ‹–åŠ¨äº‹ä»¶"""
        if not self.video_info:
            return
            
        canvas = event.widget
        # è·å–ç”»å¸ƒåæ ‡ï¼ˆè€ƒè™‘æ»šåŠ¨ï¼‰
        x = canvas.canvasx(event.x)
        
        if self.timeline_scale > 0:
            time = x / self.timeline_scale
            duration = self.video_info.get('duration', 0)
            
            # é™åˆ¶æ—¶é—´èŒƒå›´
            time = max(0, min(time, duration))
            
            # ç«‹å³æ›´æ–°æ’­æ”¾å¤´ä»¥è·å¾—æ›´å¥½å“åº”
            self.draw_playhead(time)
            
            # è·³è½¬è§†é¢‘
            fps = self.video_info.get('fps', 30.0)
            frame = int(time * fps)
            self.seek_to_frame(frame)

    def on_progress_press(self, event):
        """è¿›åº¦æ¡æŒ‰ä¸‹äº‹ä»¶"""
        self.is_dragging_progress = True
        if self.playing:
            self.was_playing_before_drag = True
            # æš‚åœæ’­æ”¾ä»¥é¿å…å†²çª
            self.playing = False
            self.play_btn['text'] = "â–¶ æ’­æ”¾"
            self.update_status("æš‚åœ(æ‹–åŠ¨)")
        else:
            self.was_playing_before_drag = False

    def on_progress_release(self, event):
        """è¿›åº¦æ¡é‡Šæ”¾äº‹ä»¶"""
        self.is_dragging_progress = False
        if self.was_playing_before_drag:
            # æ¢å¤æ’­æ”¾
            self.toggle_play()

    def on_progress_change(self, value):
        """è¿›åº¦æ¡æ”¹å˜äº‹ä»¶"""
        if self.cap is None:
            return
        
        current_time = float(value)
        fps = self.video_info.get('fps', 30.0)
        frame_number = int(current_time * fps)
        
        # åªæœ‰åœ¨ä¸æ’­æ”¾æ—¶æ‰å…è®¸æ‰‹åŠ¨è·³è½¬
        if not self.playing:
            self.seek_to_frame(frame_number)
        
        duration = self.video_info.get('duration', 0)
        self.time_label.config(text=f"{self.format_time(current_time)} / {self.format_time(duration)}")
    
    def on_clip_select(self, event):
        """ç‰‡æ®µé€‰æ‹©äº‹ä»¶ - åŒå‡»è·³è½¬"""
        selection = self.clip_tree.selection()
        if selection:
            # è·å–é€‰ä¸­é¡¹çš„ç´¢å¼•
            index = self.clip_tree.index(selection[0])
            if 0 <= index < len(self.clips):
                clip = self.clips[index]
                # è·³è½¬åˆ°ç‰‡æ®µå¼€å§‹ä½ç½®
                self.seek_to_frame(clip['start_frame'])
                self.update_status(f"è·³è½¬åˆ°ç‰‡æ®µ: {clip['name']}")
    
    def on_zoom_change(self, event):
        """ç¼©æ”¾æ”¹å˜äº‹ä»¶"""
        zoom = self.zoom_var.get()
        self.update_status(f"é¢„è§ˆç¼©æ”¾: {zoom}")
    
    def timeline_zoom_in(self):
        """æ—¶é—´è½´æ”¾å¤§"""
        self.timeline_scale *= 1.5
        self.update_timeline()
    
    def timeline_zoom_out(self):
        """æ—¶é—´è½´ç¼©å°"""
        self.timeline_scale /= 1.5
        self.update_timeline()
    
    def timeline_fit(self):
        """æ—¶é—´è½´é€‚åº”çª—å£"""
        if self.video_info:
            duration = self.video_info.get('duration', 100)
            width = self.timeline_canvas.winfo_width()
            if width > 0:
                self.timeline_scale = width / duration
                self.update_timeline()

    def start_timeline_thumbnail_generation(self):
        """å¼€å§‹ç”Ÿæˆæ—¶é—´è½´ç¼©ç•¥å›¾"""
        if not HAS_CV2 or not HAS_PIL:
            return
            
        # åœæ­¢ä¹‹å‰çš„çº¿ç¨‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        # Pythonçº¿ç¨‹éš¾ä»¥å¼ºåˆ¶åœæ­¢ï¼Œè¿™é‡Œæˆ‘ä»¬é€šè¿‡æ£€æŸ¥ video_path æ˜¯å¦ä¸€è‡´æ¥æ§åˆ¶é€€å‡º
        
        self.timeline_thumbnails = {}
        
        # å¯åŠ¨æ–°çº¿ç¨‹
        self.thumbnail_thread = threading.Thread(
            target=self._generate_timeline_thumbnails_worker,
            args=(self.video_path,),
            daemon=True
        )
        self.thumbnail_thread.start()
        
    def _generate_timeline_thumbnails_worker(self, current_video_path):
        """ç”Ÿæˆæ—¶é—´è½´ç¼©ç•¥å›¾çš„å·¥ä½œçº¿ç¨‹"""
        try:
            cap = cv2.VideoCapture(current_video_path)
            if not cap.isOpened():
                return
                
            duration = self.video_info.get('duration', 0)
            if duration <= 0:
                return

            # æ ¹æ®æ—¶é•¿å†³å®šé‡‡æ ·é—´éš”
            # ç›®æ ‡æ˜¯ç”Ÿæˆé€‚é‡çš„ç¼©ç•¥å›¾ï¼Œæ—¢ä¸å½±å“æ€§èƒ½åˆèƒ½è¦†ç›–å…¨é•¿
            # ä¾‹å¦‚æ¯éš”ä¸€å®šåƒç´ ç”Ÿæˆä¸€ä¸ªç¼©ç•¥å›¾
            # å‡è®¾ç¼©ç•¥å›¾å®½åº¦ä¸º 60px
            # ä½†æˆ‘ä»¬åœ¨åå°ç”Ÿæˆï¼Œä¸çŸ¥é“å½“å‰çš„ timeline_scale
            # æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å›ºå®šç”Ÿæˆä¸€å®šæ•°é‡ï¼Œæˆ–è€…æŒ‰æ—¶é—´é—´éš”
            
            # ç­–ç•¥ï¼šæ¯éš” 5-30 ç§’ç”Ÿæˆä¸€å¼ ï¼Œå–å†³äºæ€»æ—¶é•¿
            # å¦‚æœè§†é¢‘çŸ­äº 1 åˆ†é’Ÿï¼Œæ¯ 1 ç§’ä¸€å¼ 
            # å¦‚æœè§†é¢‘é•¿äº 1 å°æ—¶ï¼Œæ¯ 30 ç§’ä¸€å¼ 
            
            if duration < 60:
                interval = 1.0
            elif duration < 600: # 10åˆ†é’Ÿ
                interval = 5.0
            elif duration < 3600: # 1å°æ—¶
                interval = 10.0
            else:
                interval = 30.0
            
            fps = self.video_info.get('fps', 30.0)
            current_time = 0.0
            
            count = 0
            batch_size = 5 # æ¯ç”Ÿæˆ5å¼ åˆ·æ–°ä¸€æ¬¡ç•Œé¢
            
            while current_time < duration:
                # æ£€æŸ¥æ˜¯å¦åˆ‡æ¢äº†è§†é¢‘
                if self.video_path != current_video_path:
                    break
                    
                frame_pos = int(current_time * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
                ret, frame = cap.read()
                
                if ret:
                    # è°ƒæ•´å¤§å°
                    h, w = frame.shape[:2]
                    target_h = 40 # è½¨é“é«˜åº¦
                    target_w = int(w * (target_h / h))
                    
                    frame_resized = cv2.resize(frame, (target_w, target_h))
                    
                    # è½¬æ¢ä¸º RGB
                    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                    image = Image.fromarray(frame_rgb)
                    photo = ImageTk.PhotoImage(image)
                    
                    # å­˜å‚¨ (éœ€è¦åœ¨ä¸»çº¿ç¨‹ä½¿ç”¨ï¼Œä½† ImageTk å¯¹è±¡å¿…é¡»åœ¨åˆ›å»ºå®ƒçš„çº¿ç¨‹ä½¿ç”¨? ä¸ï¼ŒTkinterå¯¹è±¡é€šå¸¸çº¿ç¨‹ä¸å®‰å…¨)
                    # ImageTk.PhotoImage å¯ä»¥åœ¨ä»»ä½•çº¿ç¨‹åˆ›å»ºå—ï¼Ÿ
                    # æ–‡æ¡£å»ºè®®åœ¨ä¸»çº¿ç¨‹åˆ›å»º Tkinter å¯¹è±¡ã€‚
                    # ä½† Image å¯¹è±¡å¯ä»¥åœ¨çº¿ç¨‹ä¸­åˆ›å»ºã€‚
                    # æˆ‘ä»¬å¯ä»¥åªå­˜å‚¨ Image å¯¹è±¡ï¼Œåœ¨ä¸»çº¿ç¨‹è½¬æ¢ä¸º PhotoImageã€‚
                    # æˆ–è€…ä½¿ç”¨ after å°†åˆ›å»ºæ“ä½œè°ƒåº¦åˆ°ä¸»çº¿ç¨‹ã€‚
                    
                    # ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬å°† Image å¯¹è±¡ä¼ ç»™ä¸»çº¿ç¨‹
                    count += 1
                    should_refresh = (count % batch_size == 0)
                    self.root.after(0, self._add_thumbnail_to_timeline, current_time, image, should_refresh)
                
                current_time += interval
                time.sleep(0.01) # é¿å…å ç”¨è¿‡å¤šCPU
                
            cap.release()
            # æœ€åç¡®ä¿åˆ·æ–°ä¸€æ¬¡
            self.root.after(0, lambda: self.draw_timeline_tracks())
            
        except Exception as e:
            print(f"ç”Ÿæˆç¼©ç•¥å›¾å‡ºé”™: {e}")

    def _add_thumbnail_to_timeline(self, time_sec, pil_image, refresh=True):
        """åœ¨ä¸»çº¿ç¨‹æ·»åŠ ç¼©ç•¥å›¾å¹¶åˆ·æ–°"""
        if not HAS_PIL:
            return
            
        try:
            photo = ImageTk.PhotoImage(pil_image)
            self.timeline_thumbnails[time_sec] = photo
            
            # åˆ·æ–°æ˜¾ç¤º
            # ä¸è¦åœ¨æ¯æ¬¡æ·»åŠ éƒ½å®Œå…¨é‡ç»˜ï¼Œå¯ä»¥åˆ†æ‰¹æˆ–è€…ç›´æ¥ç»˜åˆ¶è¿™ä¸ª
            # ä½†ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬è°ƒç”¨ draw_timeline_tracks
            # ä¸ºäº†é¿å…è¿‡äºé¢‘ç¹ï¼Œå¯ä»¥æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç»˜
            if refresh:
                self.draw_timeline_tracks()
        except Exception as e:
            print(f"æ·»åŠ ç¼©ç•¥å›¾å‡ºé”™: {e}")

    
    def update_timeline(self):
        """æ›´æ–°æ—¶é—´è½´æ˜¾ç¤º"""
        self.init_timeline()
    
    def generate_thumbnail(self):
        """ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾"""
        if not HAS_CV2 or self.cap is None:
            return
            
        # è§†é¢‘ç¼©ç•¥å›¾åŠŸèƒ½å·²ç¦ç”¨
        return
        
        try:
            # è·å–è§†é¢‘ä¸­é—´ä½ç½®çš„å¸§ä½œä¸ºç¼©ç•¥å›¾
            middle_frame = max(0, self.total_frames // 2)
            
            # ä¿å­˜å½“å‰ä½ç½®
            original_pos = self.current_frame_pos
            
            # å°è¯•è·³è½¬åˆ°ä¸­é—´å¸§
            success = self.cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame)
            if not success:
                # å¦‚æœè·³è½¬å¤±è´¥ï¼Œå°è¯•ä»å¼€å¤´è¯»å–
                self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                # è·³è¿‡ä¸€äº›å¸§åˆ°è¾¾ä¸­é—´ä½ç½®
                for _ in range(middle_frame):
                    ret, _ = self.cap.read()
                    if not ret:
                        break
            
            ret, frame = self.cap.read()
            
            if ret and frame is not None:
                # è°ƒæ•´å¸§å¤§å°ä»¥é€‚åº”ç¼©ç•¥å›¾æ˜¾ç¤ºåŒºåŸŸ
                canvas_width = self.thumbnail_canvas.winfo_width()
                canvas_height = self.thumbnail_canvas.winfo_height()
                
                if canvas_width > 1 and canvas_height > 1:  # ç¡®ä¿ç”»å¸ƒå·²ç»æ˜¾ç¤º
                    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒå®½é«˜æ¯”
                    frame_height, frame_width = frame.shape[:2]
                    scale = min(canvas_width / frame_width, canvas_height / frame_height)
                    
                    new_width = int(frame_width * scale)
                    new_height = int(frame_height * scale)
                    
                    # è°ƒæ•´å¸§å¤§å°
                    resized_frame = cv2.resize(frame, (new_width, new_height))
                    
                    # è½¬æ¢é¢œè‰²æ ¼å¼
                    rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
                    
                    # åˆ›å»ºPILå›¾åƒ
                    if HAS_PIL:
                        pil_image = Image.fromarray(rgb_frame)
                        self.thumbnail_image = ImageTk.PhotoImage(pil_image)
                        
                        # æ¸…ç©ºç”»å¸ƒå¹¶æ˜¾ç¤ºå›¾åƒ
                        self.thumbnail_canvas.delete("all")
                        x = (canvas_width - new_width) // 2
                        y = (canvas_height - new_height) // 2
                        self.thumbnail_canvas.create_image(x, y, anchor=tk.NW, image=self.thumbnail_image)
                    
        except Exception as e:
            print(f"ç”Ÿæˆç¼©ç•¥å›¾å¤±è´¥: {e}")
        finally:
            # æ¢å¤åŸå§‹å¸§ä½ç½®
            if self.cap is not None:
                try:
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.current_frame_pos)
                except:
                    # å¦‚æœæ¢å¤å¤±è´¥ï¼Œè‡³å°‘å°è¯•å›åˆ°å¼€å¤´
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    
    # ============ å¸®åŠ©åŠŸèƒ½ ============
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©"""
        help_window = tk.Toplevel(self.root)
        help_window.title("ä½¿ç”¨è¯´æ˜")
        help_window.geometry("700x500")
        
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(help_window)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        notebook = ttk.Notebook(main_frame)
        notebook.pack(fill=tk.BOTH, expand=True)
        
        # åŸºæœ¬æ“ä½œæ ‡ç­¾é¡µ
        basic_frame = ttk.Frame(notebook)
        notebook.add(basic_frame, text="åŸºæœ¬æ“ä½œ")
        
        basic_text = tk.Text(basic_frame, wrap=tk.WORD, font=default_font, padx=10, pady=10)
        basic_text.pack(fill=tk.BOTH, expand=True)
        
        basic_content = """è§†é¢‘ç¼–è¾‘å™¨åŸºæœ¬æ“ä½œè¯´æ˜

1. æ–‡ä»¶æ“ä½œ:
   â€¢ æ–‡ä»¶ -> æ‰“å¼€è§†é¢‘: åŠ è½½è§†é¢‘æ–‡ä»¶ (Ctrl+O)
   â€¢ æ–‡ä»¶ -> å¯¼å…¥è§†é¢‘: æ·»åŠ æ›´å¤šè§†é¢‘åˆ°é¡¹ç›®
   â€¢ æ–‡ä»¶ -> ä¿å­˜é¡¹ç›®: ä¿å­˜å½“å‰ç¼–è¾‘è¿›åº¦ (Ctrl+S)
   â€¢ æ–‡ä»¶ -> å¯¼å‡ºè§†é¢‘: å¯¼å‡ºæœ€ç»ˆè§†é¢‘ (Ctrl+E)

2. æ’­æ”¾æ§åˆ¶:
   â€¢ æ’­æ”¾/æš‚åœ: ç©ºæ ¼é”®æˆ–æ’­æ”¾æŒ‰é’®
   â€¢ åœæ­¢: Ké”®æˆ–åœæ­¢æŒ‰é’®
   â€¢ ä¸Šä¸€å¸§: â† é”®
   â€¢ ä¸‹ä¸€å¸§: â†’ é”®
   â€¢ åé€€5ç§’: Shift+â† æˆ– âª æŒ‰é’®
   â€¢ å‰è¿›5ç§’: Shift+â†’ æˆ– â© æŒ‰é’®
   â€¢ è·³è½¬åˆ°å¼€å§‹: Home é”®æˆ– â® æŒ‰é’®
   â€¢ è·³è½¬åˆ°ç»“æŸ: End é”®æˆ– â­ æŒ‰é’®

3. éŸ³é‡æ§åˆ¶:
   â€¢ é™éŸ³åˆ‡æ¢: ç‚¹å‡»éŸ³é‡å›¾æ ‡
   â€¢ éŸ³é‡è°ƒèŠ‚: æ‹–åŠ¨éŸ³é‡æ»‘å—

4. æ’­æ”¾é€Ÿåº¦:
   â€¢ é€Ÿåº¦è°ƒèŠ‚: é€‰æ‹©æ’­æ”¾é€Ÿåº¦ (0.25x - 2.0x)
   â€¢ å¾ªç¯æ’­æ”¾: åœ¨æ’­æ”¾èœå•ä¸­å¼€å¯/å…³é—­"""
        
        basic_text.insert(1.0, basic_content)
        basic_text.config(state=tk.DISABLED)
        
        # å¿«æ·é”®æ ‡ç­¾é¡µ
        shortcut_frame = ttk.Frame(notebook)
        notebook.add(shortcut_frame, text="å¿«æ·é”®")
        
        shortcut_text = tk.Text(shortcut_frame, wrap=tk.WORD, font=default_font, padx=10, pady=10)
        shortcut_text.pack(fill=tk.BOTH, expand=True)
        
        shortcut_content = """è§†é¢‘ç¼–è¾‘å™¨å¿«æ·é”®å¤§å…¨

æ–‡ä»¶æ“ä½œ:
â€¢ Ctrl+O: æ‰“å¼€è§†é¢‘æ–‡ä»¶
â€¢ Ctrl+S: ä¿å­˜é¡¹ç›®
â€¢ Ctrl+Shift+O: æ‰“å¼€é¡¹ç›®
â€¢ Ctrl+E: å¯¼å‡ºè§†é¢‘
â€¢ Ctrl+Q: é€€å‡ºç¨‹åº

æ’­æ”¾æ§åˆ¶:
â€¢ ç©ºæ ¼é”®: æ’­æ”¾/æš‚åœ
â€¢ K: åœæ­¢æ’­æ”¾
â€¢ â†: ä¸Šä¸€å¸§
â€¢ â†’: ä¸‹ä¸€å¸§
â€¢ Shift+â†: åé€€5ç§’
â€¢ Shift+â†’: å‰è¿›5ç§’
â€¢ Home: è·³è½¬åˆ°å¼€å§‹
â€¢ End: è·³è½¬åˆ°ç»“æŸ

å‰ªè¾‘æ“ä½œ:
â€¢ S: åˆ†å‰²ç‰‡æ®µ
â€¢ M: åˆå¹¶ç‰‡æ®µ
â€¢ Del: åˆ é™¤é€‰ä¸­ç‰‡æ®µ
â€¢ I: è®¾ç½®å…¥ç‚¹
â€¢ O: è®¾ç½®å‡ºç‚¹

ç¼–è¾‘æ“ä½œ:
â€¢ Ctrl+Z: æ’¤é”€ (å¾…å®ç°)
â€¢ Ctrl+Y: é‡åš (å¾…å®ç°)
â€¢ Ctrl+X: å‰ªåˆ‡
â€¢ Ctrl+C: å¤åˆ¶
â€¢ Ctrl+V: ç²˜è´´"""
        
        shortcut_text.insert(1.0, shortcut_content)
        shortcut_text.config(state=tk.DISABLED)
        
        # å‰ªè¾‘åŠŸèƒ½æ ‡ç­¾é¡µ
        clip_frame = ttk.Frame(notebook)
        notebook.add(clip_frame, text="å‰ªè¾‘åŠŸèƒ½")
        
        clip_text = tk.Text(clip_frame, wrap=tk.WORD, font=default_font, padx=10, pady=10)
        clip_text.pack(fill=tk.BOTH, expand=True)
        
        clip_content = """è§†é¢‘ç¼–è¾‘å™¨å‰ªè¾‘åŠŸèƒ½è¯´æ˜

1. åˆ†å‰²ç‰‡æ®µ:
   â€¢ åœ¨æ—¶é—´è½´ä¸Šé€‰æ‹©åˆ†å‰²ä½ç½®
   â€¢ ç‚¹å‡»"åˆ†å‰²"æŒ‰é’®æˆ–æŒ‰Sé”®
   â€¢ è§†é¢‘å°†åœ¨å½“å‰ä½ç½®åˆ†å‰²æˆä¸¤ä¸ªç‰‡æ®µ

2. åˆå¹¶ç‰‡æ®µ:
   â€¢ é€‰æ‹©å¤šä¸ªç›¸é‚»çš„ç‰‡æ®µ
   â€¢ ç‚¹å‡»"åˆå¹¶"æŒ‰é’®æˆ–æŒ‰Mé”®
   â€¢ é€‰ä¸­çš„ç‰‡æ®µå°†åˆå¹¶ä¸ºä¸€ä¸ªç‰‡æ®µ

3. åˆ é™¤ç‰‡æ®µ:
   â€¢ åœ¨æ—¶é—´è½´æˆ–ç‰‡æ®µåˆ—è¡¨ä¸­é€‰æ‹©è¦åˆ é™¤çš„ç‰‡æ®µ
   â€¢ ç‚¹å‡»"åˆ é™¤"æŒ‰é’®æˆ–æŒ‰Delé”®
   â€¢ é€‰ä¸­çš„ç‰‡æ®µå°†è¢«åˆ é™¤

4. è®¾ç½®å…¥ç‚¹/å‡ºç‚¹:
   â€¢ æ’­æ”¾è§†é¢‘åˆ°æƒ³è¦è®¾ç½®å…¥ç‚¹çš„ä½ç½®
   â€¢ æŒ‰Ié”®è®¾ç½®å…¥ç‚¹
   â€¢ æ’­æ”¾è§†é¢‘åˆ°æƒ³è¦è®¾ç½®å‡ºç‚¹çš„ä½ç½®
   â€¢ æŒ‰Oé”®è®¾ç½®å‡ºç‚¹
   â€¢ å¯ä»¥åŸºäºå…¥ç‚¹å’Œå‡ºç‚¹åˆ›å»ºæ–°ç‰‡æ®µ

5. æ—¶é—´è½´æ“ä½œ:
   â€¢ æ”¾å¤§/ç¼©å°: ä½¿ç”¨æ—¶é—´è½´æ§åˆ¶æŒ‰é’®
   â€¢ é€‚åº”çª—å£: è‡ªåŠ¨è°ƒæ•´æ—¶é—´è½´æ˜¾ç¤º
   â€¢ æ‹–åŠ¨ç‰‡æ®µ: åœ¨æ—¶é—´è½´ä¸Šæ‹–åŠ¨ç‰‡æ®µè°ƒæ•´ä½ç½®"""
        
        clip_text.insert(1.0, clip_content)
        clip_text.config(state=tk.DISABLED)
    
    def show_about(self):
        """æ˜¾ç¤ºå…³äº"""
        about_text = """è§†é¢‘ç¼–è¾‘å™¨ v1.0

åŸºäºPythonå’ŒTkinterå¼€å‘çš„è§†é¢‘ç¼–è¾‘è½¯ä»¶

åŠŸèƒ½:
- è§†é¢‘åŠ è½½å’Œé¢„è§ˆ
- åŸºæœ¬å‰ªè¾‘æ“ä½œ
- æ—¶é—´è½´ç¼–è¾‘
- è§†é¢‘å¯¼å‡º

å¼€å‘ä¸­..."""
        messagebox.showinfo("å…³äº", about_text)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢æ’­æ”¾
        self.playing = False
        self.stop_audio_playback()
        
        # ç­‰å¾…æ’­æ”¾çº¿ç¨‹ç»“æŸ
        if self.play_thread is not None and self.play_thread.is_alive():
            time.sleep(0.1)  # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©çº¿ç¨‹ç»“æŸ
        
        # é‡Šæ”¾è§†é¢‘èµ„æº
        if self.cap is not None:
            self.cap.release()
            self.cap = None
    
    def on_closing(self):
        """çª—å£å…³é—­äº‹ä»¶"""
        self.cleanup()
        self.root.destroy()


def main():
    """ä¸»å‡½æ•°"""
    try:
        root = tk.Tk()
        app = VideoEditorApp(root)
        root.mainloop()
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²åœæ­¢ (KeyboardInterrupt)")
        # å°è¯•æ¸…ç†èµ„æº
        try:
            # è·å– app å®ä¾‹å¹¶æ¸…ç† (å¦‚æœå­˜åœ¨)
            # ç”±äº app æ˜¯å±€éƒ¨å˜é‡ï¼Œè¿™é‡Œå¯èƒ½æ— æ³•ç›´æ¥è®¿é—®ï¼Œ
            # ä½†é€šå¸¸ Tkinter åº”ç”¨ä¼šåœ¨çª—å£å…³é—­æ—¶è°ƒç”¨ cleanup
            pass
        except:
            pass
        
        # ç¡®ä¿é€€å‡º
        import sys
        sys.exit(0)


if __name__ == "__main__":
    main()
